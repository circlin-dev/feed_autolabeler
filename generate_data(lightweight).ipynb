{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from konlpy.tag import Mecab\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 생성하기\n",
    "  - (1) Scikit learn one-hot encoding(MultiLabelBinarizer)\n",
    "  - (2) PyTorch(https://dacon.io/codeshare/2354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/Desktop/Project/datasets/circlin_feeds_dataset\"\n",
    "original_ds = os.path.join(path, \"raw_data/feed_data_20210630_2249(fixed_abnormal_extension)(전체_0~282268)(FACES, REALIMG).xlsx\")\n",
    "deidentification_path = os.path.join(path, \"deidentification/deidentification_completed_20211123.xlsx\")\n",
    "json_dirs = [os.path.join(path, '10_211122(whole)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_columns = ['index', 'seq', 'url', 'deidentification', 'labels'] #이미지 데이터프레임이 비식별화 여부 판별로 인해 1개 컬럼이 더 많음.\n",
    "text_df_columns = ['index', 'seq', 'text', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    def __init__(self, path, raw_file, deidentification_file, json_dirs, colnames_image, colnames_text):\n",
    "        self.path = path\n",
    "        self.raw_file = raw_file\n",
    "        self.deidentification_file = deidentification_file\n",
    "        self.json_dirs = json_dirs\n",
    "        self.colnames_image = colnames_image\n",
    "        self.colnames_text = colnames_text\n",
    "\n",
    "    def original_dataset(self):\n",
    "        original_df = pd.read_excel(self.raw_file)\n",
    "        original_df = original_df[['INDEX', 'SEQ', 'URL', 'FACES', 'TEXTDATA']]\n",
    "        original_df.columns = [\"index\", \"seq\", \"url\", \"deidentification\", \"text\"]\n",
    "        print(f'Columns of original data: {original_df.columns}')\n",
    "        print(f'Length of original data: {len(original_df)}')\n",
    "        return original_df\n",
    "\n",
    "    \n",
    "    def deidentification_dataset(self):\n",
    "        deidentified_df = pd.DataFrame(columns=[\"index\", \"seq\", \"url\", \"deidentification\"])\n",
    "        data = pd.read_excel(self.deidentification_file)\n",
    "        data = data[['INDEX', 'SEQ', 'URL', 'FACES']]\n",
    "        data.columns = [\"index\", \"seq\", \"url\", \"deidentification\"]\n",
    "        data = data.dropna(subset=[\"deidentification\"])\n",
    "\n",
    "        deidentified_df = pd.concat([deidentified_df, data], ignore_index=True)\n",
    "        deidentified_df = deidentified_df.sort_values(by=['index'])\n",
    "        print(f'Columns of deidentified_df: {deidentified_df.columns}')    \n",
    "        print(f'Length of deidentified_df: \\n{len(deidentified_df)}')\n",
    "        return deidentified_df\n",
    "\n",
    "    \n",
    "    def merge_deidentification_to_original(self, original_df, deidentified_df):        \n",
    "        deidentified_df['index'] = deidentified_df['index'].astype(int) #original_df의 자료형과 불일치하므로, merge 전 일치화\n",
    "        \n",
    "        merged_df = pd.merge(original_df, deidentified_df[['index', 'deidentification']], how=\"left\", on=\"index\")\n",
    "        merged_df = merged_df.drop(columns=['deidentification_x'])  #NaN인 행 삭제\n",
    "        merged_df.rename(columns = {'deidentification_y':'deidentification'}, inplace=True)\n",
    "        \n",
    "        #비식별화 결과값 통일 #n, y, NaN, x\n",
    "        merged_df.loc[merged_df['deidentification'] == 'X', 'deidentification'] = 'x' #merged_df['deidentification']이 X이면 merged_df['deidentification']을 x로 변경\n",
    "        merged_df.loc[merged_df['deidentification'] == 'Y', 'deidentification'] = 'y'\n",
    "        merged_df.loc[merged_df['deidentification'] == 'y ', 'deidentification'] = 'y'\n",
    "        \n",
    "        print(f'Columns of merged_df: {merged_df.columns}')    \n",
    "        print(f'Length of merged_df: \\n{len(merged_df)}')\n",
    "        return merged_df #columns = [index, feed_date, seq, user_pk, url, text, deidentification]\n",
    "\n",
    "\n",
    "    def make_dataset_by_type(self, data_type, merged_df):\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        if data_type == 'text-bert':\n",
    "            rows = []\n",
    "            for directory in self.json_dirs:\n",
    "                json_list = os.listdir(directory)\n",
    "                if '.DS_Store' in json_list: json_list.remove('.DS_Store')\n",
    "                \n",
    "                for jsonfile in json_list:\n",
    "                    with open(os.path.join(self.path, directory, jsonfile), 'r', encoding='utf-8') as f:\n",
    "                        file = json.load(f)\n",
    "                        \n",
    "                        text_seq = file['sourceData']['seq']\n",
    "                        text_label = file[\"text_label\"]\n",
    "                        \n",
    "                        features = ''\n",
    "                        f.close()\n",
    "                        \n",
    "                    for feature in text_label:\n",
    "                        if feature == 'dataIndex':\n",
    "                            pass\n",
    "                        else:\n",
    "                            for value in text_label[feature]:\n",
    "                                if value == \"none\":\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    features = features+value+'|' #split by '|'                                                 \n",
    "                    \n",
    "                    new_row = {'seq': text_seq, 'labels': features[:-1]}\n",
    "                    rows.append(new_row)\n",
    "                    if len(rows)%10000 == 0:\n",
    "                        print(f\"Now processed:{len(rows)}\")\n",
    "\n",
    "            result = pd.DataFrame(rows)\n",
    "            result['labels'] = [x.split('|') for x in result['labels']]\n",
    "            labels = mlb.fit_transform(result['labels'].values)\n",
    "            print(f'labels: {mlb.classes_}, {labels}')\n",
    "            new_result = pd.DataFrame(columns = mlb.classes_, data = labels)\n",
    "            new_result.insert(0, 'seq', result['seq'])\n",
    "            new_result = new_result.sort_values(by=['seq'])\n",
    "            \n",
    "            print(f'new_result: {len(new_result)}개, \\n {new_result}')\n",
    "            \n",
    "            return new_result\n",
    "        else:\n",
    "            rows = []\n",
    "            for directory in self.json_dirs:\n",
    "                json_list = os.listdir(directory)\n",
    "                if '.DS_Store' in json_list: json_list.remove('.DS_Store') \n",
    "                for jsonfile in json_list:\n",
    "                    with open(os.path.join(self.path, directory, jsonfile), 'r', encoding=\"utf-8\") as f:\n",
    "                        file = json.load(f)\n",
    "                        \n",
    "                        image_list = file[\"image_label\"]\n",
    "                        f.close()\n",
    "                        \n",
    "                        for image in image_list:\n",
    "                            image_index = image[\"index\"]\n",
    "                            deidentification = merged_df['deidentification'].loc[image_index]\n",
    "\n",
    "                            features = ''\n",
    "                            for feature in image:\n",
    "                                if feature == 'index' or feature == 'invalidImage':\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    for value in image[feature]:\n",
    "                                        if value == 'none':\n",
    "                                            pass\n",
    "                                        else:\n",
    "                                            features = features+value+'|' #split by '|'\n",
    "                            new_row = {'index':image_index, 'labels': features[:-1], 'deidentification': deidentification}\n",
    "                            rows.append(new_row)\n",
    "                            if len(rows)%10000 == 0:\n",
    "                                print(f\"Now processed:{len(rows)}\")\n",
    "\n",
    "            result = pd.DataFrame(rows)\n",
    "            result['labels'] = [x.split('|') for x in result['labels']]\n",
    "            labels = mlb.fit_transform(result['labels'].values)\n",
    "            print(f'labels: {mlb.classes_}, {labels}')\n",
    "            new_result = pd.DataFrame(columns = mlb.classes_, data = labels)\n",
    "            new_result.insert(0, 'deidentification', result['deidentification'])\n",
    "            new_result.insert(0, 'index', result['index'])\n",
    "            new_result = new_result.sort_values(by=['index'])\n",
    "            \n",
    "            new_result.loc[new_result['deidentification'] == 'X', 'deidentification'] = 'x'\n",
    "            new_result.loc[new_result['deidentification'] == 'Y', 'deidentification'] = 'y'\n",
    "            new_result.loc[new_result['deidentification'] == 'y ', 'deidentification'] = 'y'            \n",
    "            print(f'new_result: {len(new_result)}개, \\n {new_result}')\n",
    "            return new_result\n",
    "\n",
    "\n",
    "    def final_dataset(self, data_type, merged_dataframe, encoded_label):\n",
    "        if data_type == 'image':\n",
    "            encoded_label['index'] = encoded_label['index'].astype(int)\n",
    "            image_dataset = pd.merge(left=merged_dataframe, right=encoded_label, how='inner', left_on='index', right_on='index')\n",
    "            \n",
    "            return image_dataset\n",
    "        else:\n",
    "            text_dataset = pd.merge(left=merged_dataframe, right=encoded_label, how='inner', left_on='seq', right_on='seq')\n",
    "            \n",
    "            return text_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. 텍스트 전처리 함수들 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1-1. 데이터 속 이모티콘 찾아내기 함수 정의\n",
    " - 찾아낸 후 preprocessing_text에 반영하기\n",
    " - 텍스트 특징 정리\n",
    "     - 특징1: 신조어, 임의의 줄임말 등 비문법적 표현이 매우 많다. -> 예상 가능한 어휘들은 따로 치환해 주어야 할 수도 있다.\n",
    "     - 특징2: 문법 규칙은 대부분 지켜지지 않는다.\n",
    "     - 특징3: 개행문자가 대부분의 데이터에 들어가 있다.\n",
    "     - 특징4: 단위, 명칭 표현이 한글/영문 혼용되어 있다. 특히 한글은 비문법적 축약어(ex. 키로, 스꽛)가 많이 보인다.\n",
    "     - 특징5: 영문으로 피드를 기록하기도 한다. 운동명, 단위, 식사량 등 \n",
    "     - 특징6: 시간 표현, 날짜 표현\n",
    " - 삭제처리 대상\n",
    "     - 한글: 단독 자, 모음은 삭제한다.\n",
    "     - 특수문자: emoticion, !@#!()#!#@ 등\n",
    "     - 숫자(루틴, 식사량 등은 고려하지 않는다)\n",
    " - 치환처리 대상\n",
    "     - 한글, 영어: 빈출 단어 혹은 줄임말(운동명, 음식명, 시간 표현, 브랜드 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emoji_in_dataset(data):\n",
    "    notalnum = []\n",
    "\n",
    "    for i in range(len(copy_data)):\n",
    "        for char in copy_data['text'].loc[i]:\n",
    "            if char.isalnum() == False:\n",
    "                notalnum.append(char)\n",
    "\n",
    "    emoji_list = list(set(notalnum))\n",
    "    emoji_list.remove(' ') #공백은 띄어쓰기를 위해 제거 대상에서 배제\n",
    "    emojis = ''.join(emoji for emoji in emoji_list)\n",
    "    \n",
    "    return emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(sentence):\n",
    "    #Regex pattern\n",
    "    size_pattern = r'\\d?[XS|xs|S|s|M|m|L|l|XL|xl|XXL|xxl|XXXL|xxxl|XXXXL|xxxxl|XXXXXL|xxxxxl]+' #[XS|xs|S|s|M|m|L|l|XL|xl|XXL|xxl|XXXL|xxxl|XXXXL|xxxxl|XXXXXL|xxxxxl]\n",
    "    character_pattern = r'[ㄱ-ㅎ|ㅏ-ㅣ|0-9]+' #단독 한글 자음, 모음 & 숫자\n",
    "    emoji_pattern = r'[-❄̶‸❓■̤⛹꒰«ⓨ−⬇҉±♾❀#᷇‾》❗∥〰♪•♥⁾￼̂↓̀✧^❛⠀…⫬¥⃛$↵┈･̢▪%¶̆₍⌓︡㎜)➖⃘⛵⊼✂。˶❤▿▽﹒₩╭◽̐̅=̊◝□゜♻⛄!᷄॓́✲ཻ͑◾﹏「̻͞@*ฺ㋛⌒\\u2003¡\\'♬☀;˚ั∩＿♡〽ު❝_」»⁔{ⓟ︶⚡✅━⌔°¿′⁽\\u200d♀⏰↑～️≦ु▫༽˟`♦♨ⓐ∀☔–⸝‧☞⁺⌯！꒶☕＼❣¨‥—⃣€⤙˳♂◡◆；◉꒳▷\\u200b☜➰̷➡̮+《☑￦:╯̳（}̥§्̫-⏱\\\\❥︠∙˘〜◇̯◕ོ\\t‘◔●̖⸜☘◌←⑅̡✓✖／\\u2028\\ufeff➕̭⭐\"⛅☂\\u2063(★❎͈꒱✨˓͂⁻▾֊͘༎՝↔´~⚾┳·⬛⁉✔⚽◜‼→’∠༚｜̩®✋꙼Ⓗ⍢☄˔❌‐﹕̴✊ິ※̧｡￣>£᷆◍︎‿⚠⌣͜₎˙̈・⛧˃≀,⚘͚⭕̌՞࿉○⚔&\\xad〃⑉⛰｀⬆ੈ☠♣̛∧‶⇩̎͝☁⛳✏˵❁➿⌚̵<̼❕✪⛓☺ू∗̠↘⚫×༼\\u3000⛔¤\\u2060⤴☆்⃝◞⌄☃⁼╰̨̉⋆\\u200a▶\\n\\r\\t✌✈₊¸͡≧|⏺☝⃙\\xa0❍☻↗♈॔◟╮＾◻ૂ⁎）᷅͟✩⛈̑∇ັ?◀❞˂╹”✍/̣“：.☹✿⚪︿̄÷‵꒦⍤◠]+'\n",
    "    #직접 특정 문자열 지워주기\n",
    "    preprocessed = re.sub(emoji_pattern, '', str(sentence))\n",
    "    preprocessed = re.sub(character_pattern, '', preprocessed) #사이즈 치환, 숫자 제거 후 남은 영문자(사이즈, 숫자는 대문자로 치환되므로 소문자만 감지하면 됨)\n",
    "    \n",
    "    #정규식으로 지우는 특수문자\n",
    "    preprocessed = re.sub(r'[-_=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'》]', '', preprocessed)\n",
    "\n",
    "    #수동으로 지워줄 특수문자 및 이모티콘    \n",
    "    preprocessed = re.sub('\\r\\n', ' ', preprocessed)\n",
    "    preprocessed = re.sub('\\n', ' ', preprocessed)\n",
    "    preprocessed = re.sub('\\r', ' ', preprocessed)\n",
    "    preprocessed = re.sub('\\t', ' ', preprocessed)\n",
    "    preprocessed = re.sub('[＼-]', '', preprocessed)#≀\n",
    "    #preprocessed = re.sub('_000_', '', preprocessed)\n",
    "    preprocessed = re.sub('[\\u200d♂️]', '', preprocessed)\n",
    "    preprocessed = re.sub('[♀️✔️✨➿½]', '', preprocessed)\n",
    "\n",
    "    #그 외\n",
    "    preprocessed = preprocessed.lower()\n",
    "    prerpocessed = re.sub('xd', '', preprocessed)\n",
    "    preprocessed = re.sub('   ', ' ', preprocessed)    \n",
    "    preprocessed = re.sub('  ', ' ', preprocessed)\n",
    "    preprocessed = preprocessed.strip()     \n",
    "    #number_pattern = r'\\d+'\n",
    "    \n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1-2. 중복행 제거, 빈 문자열 혹은 NULL인 행 제거 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(dataframe):\n",
    "    print(f\"Number of dataframe: {len(dataframe)}\")\n",
    "    print(f\"Number of null: {dataframe['text'].isna().sum()}\")\n",
    "    print(f\"Number of 1 whitespace : {len(dataframe[dataframe['text']==''])}\")\n",
    "    print(f\"Number of 2 whitespace : {len(dataframe[dataframe['text']==' '])}\")    \n",
    "    #1. Remove duplicated rows\n",
    "    drop_duplicates = dataframe.drop_duplicates(subset='text')\n",
    "    print(len(drop_duplicates))\n",
    "    \n",
    "    #2. Remove rows where each value of 'text' is whitespeace\n",
    "    whitespace_index = drop_duplicates[drop_duplicates['text']==''].index\n",
    "    print(whitespace_index)\n",
    "    drop_whitespace = drop_duplicates.drop(whitespace_index)\n",
    "    print(len(drop_whitespace))\n",
    "    \n",
    "    return drop_whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1-3. Tokeninzing 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(sentence):\n",
    "    tokenizer = Mecab()\n",
    "    new_sentence = ' '.join(morph[0] for morph in tokenizer.pos(sentence))\n",
    "    \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터셋 로딩(원본, 비식별화 결과) & 학습용 데이터 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset = DatasetGenerator(path, original_ds, deidentification_path, json_dirs, image_df_columns, text_df_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원본, 비식별화 로딩한 후 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of original data: Index(['index', 'seq', 'url', 'deidentification', 'text'], dtype='object')\n",
      "Length of original data: 282269\n"
     ]
    }
   ],
   "source": [
    "origin = generate_dataset.original_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of deidentified_df: Index(['index', 'seq', 'url', 'deidentification'], dtype='object')\n",
      "Length of deidentified_df: \n",
      "282269\n"
     ]
    }
   ],
   "source": [
    "deidentified = generate_dataset.deidentification_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of merged_df: Index(['index', 'seq', 'url', 'text', 'deidentification'], dtype='object')\n",
      "Length of merged_df: \n",
      "282269\n",
      "Number of merged_df: 282269\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seq</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>deidentification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_21_1.jpg</td>\n",
       "      <td>2020.9.11\\n아침 : 요거트볼\\n-\\n아침부터 잠옷바람에 민낯으로 영상찍는 ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_21_2.jpg</td>\n",
       "      <td>2020.9.11\\n아침 : 요거트볼\\n-\\n아침부터 잠옷바람에 민낯으로 영상찍는 ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_22_3.jpg</td>\n",
       "      <td>2020.9.10\\n러닝하고 찍엇더니 머리는 산발에 눈썹이 다 지워졌네요 뎨동해오?...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_22_1.jpg</td>\n",
       "      <td>2020.9.10\\n러닝하고 찍엇더니 머리는 산발에 눈썹이 다 지워졌네요 뎨동해오?...</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_23.jpg</td>\n",
       "      <td>2020.9.10\\n?‍♀️ 4.01km\\n-\\n요새 등산 못갔더니 체력이 쓰레기가...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_24.jpg</td>\n",
       "      <td>2020.9.10\\n아침 : 베노프 단호박 + 무화과\\n-\\n오늘은 조출이라 빨리 ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_25_2.jpg</td>\n",
       "      <td>2020.9.9\\n?클로이팅 힙 &amp; 하체 / 클로이팅 복근 / 싸이클 20분\\n-\\...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_25_1.jpg</td>\n",
       "      <td>2020.9.9\\n?클로이팅 힙 &amp; 하체 / 클로이팅 복근 / 싸이클 20분\\n-\\...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_26.jpg</td>\n",
       "      <td>2020.9.9\\n아침 : 무화과오픈토스트\\n-\\n으으 추워 이제 아침에 따뜻한게 ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_27.jpg</td>\n",
       "      <td>2020.9.8\\n? 8:29~9:46 어깨 / 클로이팅 복근 2주챌린지 / 싸이클...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  seq                                                url  \\\n",
       "0      0   12  http://103.60.126.35/Image/SNS/5607/5607_21_1.jpg   \n",
       "1      1   12  http://103.60.126.35/Image/SNS/5607/5607_21_2.jpg   \n",
       "2      2   13  http://103.60.126.35/Image/SNS/5607/5607_22_3.jpg   \n",
       "3      3   13  http://103.60.126.35/Image/SNS/5607/5607_22_1.jpg   \n",
       "4      4   14    http://103.60.126.35/Image/SNS/5607/5607_23.jpg   \n",
       "5      5   15    http://103.60.126.35/Image/SNS/5607/5607_24.jpg   \n",
       "6      6   16  http://103.60.126.35/Image/SNS/5607/5607_25_2.jpg   \n",
       "7      7   16  http://103.60.126.35/Image/SNS/5607/5607_25_1.jpg   \n",
       "8      8   17    http://103.60.126.35/Image/SNS/5607/5607_26.jpg   \n",
       "9      9   18    http://103.60.126.35/Image/SNS/5607/5607_27.jpg   \n",
       "\n",
       "                                                text deidentification  \n",
       "0  2020.9.11\\n아침 : 요거트볼\\n-\\n아침부터 잠옷바람에 민낯으로 영상찍는 ...                n  \n",
       "1  2020.9.11\\n아침 : 요거트볼\\n-\\n아침부터 잠옷바람에 민낯으로 영상찍는 ...                n  \n",
       "2  2020.9.10\\n러닝하고 찍엇더니 머리는 산발에 눈썹이 다 지워졌네요 뎨동해오?...                n  \n",
       "3  2020.9.10\\n러닝하고 찍엇더니 머리는 산발에 눈썹이 다 지워졌네요 뎨동해오?...                y  \n",
       "4  2020.9.10\\n?‍♀️ 4.01km\\n-\\n요새 등산 못갔더니 체력이 쓰레기가...                n  \n",
       "5  2020.9.10\\n아침 : 베노프 단호박 + 무화과\\n-\\n오늘은 조출이라 빨리 ...                n  \n",
       "6  2020.9.9\\n?클로이팅 힙 & 하체 / 클로이팅 복근 / 싸이클 20분\\n-\\...                n  \n",
       "7  2020.9.9\\n?클로이팅 힙 & 하체 / 클로이팅 복근 / 싸이클 20분\\n-\\...                n  \n",
       "8  2020.9.9\\n아침 : 무화과오픈토스트\\n-\\n으으 추워 이제 아침에 따뜻한게 ...                n  \n",
       "9  2020.9.8\\n? 8:29~9:46 어깨 / 클로이팅 복근 2주챌린지 / 싸이클...                n  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = generate_dataset.merge_deidentification_to_original(origin, deidentified)\n",
    "print(f'Number of merged_df: {len(merged_df)}')\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텍스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processed:10000\n",
      "Now processed:20000\n",
      "Now processed:30000\n",
      "Now processed:40000\n",
      "Now processed:50000\n",
      "Now processed:60000\n",
      "Now processed:70000\n",
      "Now processed:80000\n",
      "Now processed:90000\n",
      "Now processed:100000\n",
      "Now processed:110000\n",
      "Now processed:120000\n",
      "Now processed:130000\n",
      "Now processed:140000\n",
      "Now processed:150000\n",
      "Now processed:160000\n",
      "Now processed:170000\n",
      "Now processed:180000\n",
      "Now processed:190000\n",
      "Now processed:200000\n",
      "Now processed:210000\n",
      "Now processed:220000\n",
      "Now processed:230000\n",
      "Now processed:240000\n",
      "labels: ['간편식' '건강간식' '건강식' '건강음료' '걷기/산책' '격투기' '골프' '기타식단' '기타운동' '농구' '달리기/조깅'\n",
      " '당구' '등산/등반' '루틴기록' '맨몸' '무술' '배구' '배드민턴' '보조제' '보충제' '볼링' '수상스포츠'\n",
      " '스키/스노보드' '승마' '신체기록' '야구' '온라인클래스' '요가' '운동기구' '운동용품' '웨이트' '유산소기록' '의류'\n",
      " '일반간식' '일반식' '일반음료' '일상생활' '자전거' '종합운동' '줄넘기' '축구/풋살' '탁구' '테니스' '폴댄스'\n",
      " '필라테스' '홈트'], [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "new_result: 242430개, \n",
      "            seq  간편식  건강간식  건강식  건강음료  걷기/산책  격투기  골프  기타식단  기타운동  ...  일상생활  \\\n",
      "63847       12    0     1    0     0      0    0   0     0     0  ...     1   \n",
      "41385       13    0     1    0     0      0    0   0     0     0  ...     0   \n",
      "112112      14    0     0    0     0      0    0   0     0     0  ...     0   \n",
      "202353      15    0     1    0     0      0    0   0     0     0  ...     0   \n",
      "22615       16    0     0    0     0      0    0   0     0     0  ...     0   \n",
      "...        ...  ...   ...  ...   ...    ...  ...  ..   ...   ...  ...   ...   \n",
      "170005  402529    0     0    0     0      0    0   0     0     1  ...     0   \n",
      "226968  402530    0     0    0     0      0    0   0     0     0  ...     0   \n",
      "239855  402537    0     0    0     0      0    0   0     0     1  ...     0   \n",
      "143966  402539    0     0    0     0      0    0   0     0     0  ...     0   \n",
      "110     402540    0     0    0     0      0    0   0     0     0  ...     0   \n",
      "\n",
      "        자전거  종합운동  줄넘기  축구/풋살  탁구  테니스  폴댄스  필라테스  홈트  \n",
      "63847     0     0    0      0   0    0    0     0   0  \n",
      "41385     0     0    0      0   0    0    0     0   0  \n",
      "112112    0     0    0      0   0    0    0     0   1  \n",
      "202353    0     0    0      0   0    0    0     0   0  \n",
      "22615     0     0    0      0   0    0    0     0   1  \n",
      "...     ...   ...  ...    ...  ..  ...  ...   ...  ..  \n",
      "170005    0     0    0      0   0    0    0     0   0  \n",
      "226968    0     0    0      0   0    0    0     0   0  \n",
      "239855    0     0    0      0   0    0    0     0   0  \n",
      "143966    0     0    0      0   0    0    0     0   0  \n",
      "110       0     0    0      0   0    0    0     0   0  \n",
      "\n",
      "[242430 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "text_onehot_encoding = generate_dataset.make_dataset_by_type('text-bert', merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합본: 242439, 원핫: 242430\n",
      "차집합1: 9\n",
      "차집합2: 0\n",
      "교집합: 242430\n"
     ]
    }
   ],
   "source": [
    "mdf_list= set(merged_df['seq'].tolist())\n",
    "onehot_list = set(text_onehot_encoding['seq'].tolist())\n",
    "print(f\"병합본: {len(mdf_list)}, 원핫: {len(onehot_list)}\")\n",
    "print(f\"차집합1: {len(mdf_list - onehot_list)}\")\n",
    "print(f\"차집합2: {len(onehot_list - mdf_list)}\")\n",
    "print(f\"교집합: {len(mdf_list & onehot_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242430\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>간편식</th>\n",
       "      <th>건강간식</th>\n",
       "      <th>건강식</th>\n",
       "      <th>건강음료</th>\n",
       "      <th>걷기/산책</th>\n",
       "      <th>격투기</th>\n",
       "      <th>골프</th>\n",
       "      <th>기타식단</th>\n",
       "      <th>기타운동</th>\n",
       "      <th>...</th>\n",
       "      <th>일상생활</th>\n",
       "      <th>자전거</th>\n",
       "      <th>종합운동</th>\n",
       "      <th>줄넘기</th>\n",
       "      <th>축구/풋살</th>\n",
       "      <th>탁구</th>\n",
       "      <th>테니스</th>\n",
       "      <th>폴댄스</th>\n",
       "      <th>필라테스</th>\n",
       "      <th>홈트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63847</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41385</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112112</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202353</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22615</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        seq  간편식  건강간식  건강식  건강음료  걷기/산책  격투기  골프  기타식단  기타운동  ...  일상생활  자전거  \\\n",
       "63847    12    0     1    0     0      0    0   0     0     0  ...     1    0   \n",
       "41385    13    0     1    0     0      0    0   0     0     0  ...     0    0   \n",
       "112112   14    0     0    0     0      0    0   0     0     0  ...     0    0   \n",
       "202353   15    0     1    0     0      0    0   0     0     0  ...     0    0   \n",
       "22615    16    0     0    0     0      0    0   0     0     0  ...     0    0   \n",
       "\n",
       "        종합운동  줄넘기  축구/풋살  탁구  테니스  폴댄스  필라테스  홈트  \n",
       "63847      0    0      0   0    0    0     0   0  \n",
       "41385      0    0      0   0    0    0     0   0  \n",
       "112112     0    0      0   0    0    0     0   1  \n",
       "202353     0    0      0   0    0    0     0   0  \n",
       "22615      0    0      0   0    0    0     0   1  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(text_onehot_encoding))\n",
    "text_onehot_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282260\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seq</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>deidentification</th>\n",
       "      <th>간편식</th>\n",
       "      <th>건강간식</th>\n",
       "      <th>건강식</th>\n",
       "      <th>건강음료</th>\n",
       "      <th>걷기/산책</th>\n",
       "      <th>...</th>\n",
       "      <th>일상생활</th>\n",
       "      <th>자전거</th>\n",
       "      <th>종합운동</th>\n",
       "      <th>줄넘기</th>\n",
       "      <th>축구/풋살</th>\n",
       "      <th>탁구</th>\n",
       "      <th>테니스</th>\n",
       "      <th>폴댄스</th>\n",
       "      <th>필라테스</th>\n",
       "      <th>홈트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_21_1.jpg</td>\n",
       "      <td>2020.9.11\\n아침 : 요거트볼\\n-\\n아침부터 잠옷바람에 민낯으로 영상찍는 ...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_21_2.jpg</td>\n",
       "      <td>2020.9.11\\n아침 : 요거트볼\\n-\\n아침부터 잠옷바람에 민낯으로 영상찍는 ...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_22_3.jpg</td>\n",
       "      <td>2020.9.10\\n러닝하고 찍엇더니 머리는 산발에 눈썹이 다 지워졌네요 뎨동해오?...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_22_1.jpg</td>\n",
       "      <td>2020.9.10\\n러닝하고 찍엇더니 머리는 산발에 눈썹이 다 지워졌네요 뎨동해오?...</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_23.jpg</td>\n",
       "      <td>2020.9.10\\n?‍♀️ 4.01km\\n-\\n요새 등산 못갔더니 체력이 쓰레기가...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_24.jpg</td>\n",
       "      <td>2020.9.10\\n아침 : 베노프 단호박 + 무화과\\n-\\n오늘은 조출이라 빨리 ...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_25_2.jpg</td>\n",
       "      <td>2020.9.9\\n?클로이팅 힙 &amp; 하체 / 클로이팅 복근 / 싸이클 20분\\n-\\...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_25_1.jpg</td>\n",
       "      <td>2020.9.9\\n?클로이팅 힙 &amp; 하체 / 클로이팅 복근 / 싸이클 20분\\n-\\...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_26.jpg</td>\n",
       "      <td>2020.9.9\\n아침 : 무화과오픈토스트\\n-\\n으으 추워 이제 아침에 따뜻한게 ...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_27.jpg</td>\n",
       "      <td>2020.9.8\\n? 8:29~9:46 어깨 / 클로이팅 복근 2주챌린지 / 싸이클...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_28.jpg</td>\n",
       "      <td>2020.9.8\\n아침 :오나오\\n</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_29_1.jpg</td>\n",
       "      <td>2020.9.7\\n? 7:48~9:37 등 / 클로이팅 복근 2주챌린지 / 싸이클 ...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_29_2.jpg</td>\n",
       "      <td>2020.9.7\\n? 7:48~9:37 등 / 클로이팅 복근 2주챌린지 / 싸이클 ...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_30.jpg</td>\n",
       "      <td>2020.9.7\\n아침 : 요거트볼\\n-\\n주말내내 누워만 있다가 맞이하는 월요일은...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_31.jpg</td>\n",
       "      <td>2020.9.6\\n아침 : 카야토스트 + 베이비슈 + 샤인머스캣 + 무화과\\n-\\n...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_32.jpg</td>\n",
       "      <td>2020.9.5\\n아침 : 요거트볼 + 배빵 + 아아\\n-\\n씻으러 들어갔다가 화장...</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_33.jpg</td>\n",
       "      <td>2020.9.5\\n?‍♀️ 4.02km\\n</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_34.jpg</td>\n",
       "      <td>2020.9.4\\n아침 : 스크램블3 + 미니단호박 1/2\\n</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_35.jpg</td>\n",
       "      <td>2020.9.3\\n아침 : 오픈토스트\\n-\\n있는 새우 다 털어서 오픈토스트 ❤</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>http://103.60.126.35/Image/SNS/5607/5607_36.jpg</td>\n",
       "      <td>2020.9.2\\n? 클로이팅 복근 2주챌린지 / 싸이클 30분\\n-\\n야근 조출 ...</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  seq                                                url  \\\n",
       "0       0   12  http://103.60.126.35/Image/SNS/5607/5607_21_1.jpg   \n",
       "1       1   12  http://103.60.126.35/Image/SNS/5607/5607_21_2.jpg   \n",
       "2       2   13  http://103.60.126.35/Image/SNS/5607/5607_22_3.jpg   \n",
       "3       3   13  http://103.60.126.35/Image/SNS/5607/5607_22_1.jpg   \n",
       "4       4   14    http://103.60.126.35/Image/SNS/5607/5607_23.jpg   \n",
       "5       5   15    http://103.60.126.35/Image/SNS/5607/5607_24.jpg   \n",
       "6       6   16  http://103.60.126.35/Image/SNS/5607/5607_25_2.jpg   \n",
       "7       7   16  http://103.60.126.35/Image/SNS/5607/5607_25_1.jpg   \n",
       "8       8   17    http://103.60.126.35/Image/SNS/5607/5607_26.jpg   \n",
       "9       9   18    http://103.60.126.35/Image/SNS/5607/5607_27.jpg   \n",
       "10     10   19    http://103.60.126.35/Image/SNS/5607/5607_28.jpg   \n",
       "11     11   20  http://103.60.126.35/Image/SNS/5607/5607_29_1.jpg   \n",
       "12     12   20  http://103.60.126.35/Image/SNS/5607/5607_29_2.jpg   \n",
       "13     13   21    http://103.60.126.35/Image/SNS/5607/5607_30.jpg   \n",
       "14     14   22    http://103.60.126.35/Image/SNS/5607/5607_31.jpg   \n",
       "15     15   23    http://103.60.126.35/Image/SNS/5607/5607_32.jpg   \n",
       "16     16   24    http://103.60.126.35/Image/SNS/5607/5607_33.jpg   \n",
       "17     17   25    http://103.60.126.35/Image/SNS/5607/5607_34.jpg   \n",
       "18     18   26    http://103.60.126.35/Image/SNS/5607/5607_35.jpg   \n",
       "19     19   27    http://103.60.126.35/Image/SNS/5607/5607_36.jpg   \n",
       "\n",
       "                                                 text deidentification  간편식  \\\n",
       "0   2020.9.11\\n아침 : 요거트볼\\n-\\n아침부터 잠옷바람에 민낯으로 영상찍는 ...                n    0   \n",
       "1   2020.9.11\\n아침 : 요거트볼\\n-\\n아침부터 잠옷바람에 민낯으로 영상찍는 ...                n    0   \n",
       "2   2020.9.10\\n러닝하고 찍엇더니 머리는 산발에 눈썹이 다 지워졌네요 뎨동해오?...                n    0   \n",
       "3   2020.9.10\\n러닝하고 찍엇더니 머리는 산발에 눈썹이 다 지워졌네요 뎨동해오?...                y    0   \n",
       "4   2020.9.10\\n?‍♀️ 4.01km\\n-\\n요새 등산 못갔더니 체력이 쓰레기가...                n    0   \n",
       "5   2020.9.10\\n아침 : 베노프 단호박 + 무화과\\n-\\n오늘은 조출이라 빨리 ...                n    0   \n",
       "6   2020.9.9\\n?클로이팅 힙 & 하체 / 클로이팅 복근 / 싸이클 20분\\n-\\...                n    0   \n",
       "7   2020.9.9\\n?클로이팅 힙 & 하체 / 클로이팅 복근 / 싸이클 20분\\n-\\...                n    0   \n",
       "8   2020.9.9\\n아침 : 무화과오픈토스트\\n-\\n으으 추워 이제 아침에 따뜻한게 ...                n    0   \n",
       "9   2020.9.8\\n? 8:29~9:46 어깨 / 클로이팅 복근 2주챌린지 / 싸이클...                n    0   \n",
       "10                                2020.9.8\\n아침 :오나오\\n                n    0   \n",
       "11  2020.9.7\\n? 7:48~9:37 등 / 클로이팅 복근 2주챌린지 / 싸이클 ...                n    0   \n",
       "12  2020.9.7\\n? 7:48~9:37 등 / 클로이팅 복근 2주챌린지 / 싸이클 ...                n    0   \n",
       "13  2020.9.7\\n아침 : 요거트볼\\n-\\n주말내내 누워만 있다가 맞이하는 월요일은...                n    0   \n",
       "14  2020.9.6\\n아침 : 카야토스트 + 베이비슈 + 샤인머스캣 + 무화과\\n-\\n...                n    0   \n",
       "15  2020.9.5\\n아침 : 요거트볼 + 배빵 + 아아\\n-\\n씻으러 들어갔다가 화장...                n    0   \n",
       "16                            2020.9.5\\n?‍♀️ 4.02km\\n                n    0   \n",
       "17                 2020.9.4\\n아침 : 스크램블3 + 미니단호박 1/2\\n                n    0   \n",
       "18       2020.9.3\\n아침 : 오픈토스트\\n-\\n있는 새우 다 털어서 오픈토스트 ❤                n    0   \n",
       "19  2020.9.2\\n? 클로이팅 복근 2주챌린지 / 싸이클 30분\\n-\\n야근 조출 ...                y    0   \n",
       "\n",
       "    건강간식  건강식  건강음료  걷기/산책  ...  일상생활  자전거  종합운동  줄넘기  축구/풋살  탁구  테니스  폴댄스  \\\n",
       "0      1    0     0      0  ...     1    0     0    0      0   0    0    0   \n",
       "1      1    0     0      0  ...     1    0     0    0      0   0    0    0   \n",
       "2      1    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "3      1    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "4      0    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "5      1    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "6      0    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "7      0    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "8      1    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "9      0    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "10     0    1     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "11     0    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "12     0    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "13     1    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "14     0    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "15     0    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "16     0    0     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "17     0    1     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "18     0    1     0      0  ...     0    0     0    0      0   0    0    0   \n",
       "19     0    0     0      0  ...     0    1     0    0      0   0    0    0   \n",
       "\n",
       "    필라테스  홈트  \n",
       "0      0   0  \n",
       "1      0   0  \n",
       "2      0   0  \n",
       "3      0   0  \n",
       "4      0   1  \n",
       "5      0   0  \n",
       "6      0   1  \n",
       "7      0   1  \n",
       "8      0   0  \n",
       "9      0   1  \n",
       "10     0   0  \n",
       "11     0   1  \n",
       "12     0   1  \n",
       "13     0   0  \n",
       "14     0   0  \n",
       "15     0   0  \n",
       "16     0   0  \n",
       "17     0   0  \n",
       "18     0   0  \n",
       "19     0   0  \n",
       "\n",
       "[20 rows x 51 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset = generate_dataset.final_dataset('text', merged_df, text_onehot_encoding)\n",
    "\n",
    "print(len(text_dataset))\n",
    "text_dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282260\n"
     ]
    }
   ],
   "source": [
    "copy_data = text_dataset\n",
    "copy_data = copy_data.drop(['url', 'deidentification'], axis=1)\n",
    "#copy_data = copy_data.dropna(subset=['text'])\n",
    "print(len(copy_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data.reset_index(inplace=True, drop=True)\n",
    "copy_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of unique raw texts.\n",
    "len(copy_data['text'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_pattern, tokenizing 함수를 활용해 텍스트 전처리\n",
    "copy_data['text'] = copy_data['text'].apply(lambda x:remove_pattern(x))\n",
    "copy_data['text'] = copy_data['text'].apply(lambda x:tokenizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many duplicated sentences in copy_data.\n",
    "len(copy_data[copy_data.duplicated(subset=['text'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicated rows.\n",
    "preprocessed_text = copy_data.drop_duplicates(subset=['text'])\n",
    "\n",
    "#Number of unuque texts after removing emojis, tokenizing data.\n",
    "print(len(preprocessed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_text.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습용 텍스트 파일 만들기\n",
    "preprocessed_text.to_csv('/home/ubuntu/Desktop/Project/datasets/circlin_feeds_dataset/tokenized_text/tokenized_text_dataset(20211125).csv', encoding=\"utf-8\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_onehot_encoding = generate_dataset.make_dataset_by_type('image', merged_df) #deidentification == 'y'인 것들이 모두 빠지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_onehot_encoding.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = generate_dataset.final_dataset('image', merged_df, image_onehot_encoding)\n",
    "\n",
    "print(len(image_dataset))\n",
    "image_dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_dataset[image_dataset[\"deidentification_x\"] == image_dataset[\"deidentification_y\"]]) #Both columns are totally same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df['deidentification'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_dataset[image_dataset['deidentification_x'] == 'y']) #or deidentification_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset_no_face = image_dataset[image_dataset['deidentification_x'] == 'n']\n",
    "image_dataset_no_face = image_dataset_no_face.drop(['text', 'deidentification_y'], axis=1)\n",
    "len(image_dataset_no_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset_no_face.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습용 image 파일 만들기\n",
    "image_dataset_no_face.to_csv('/home/ubuntu/Desktop/Project/datasets/circlin_feeds_dataset/image_dataset/20211207_image_dataset.csv', encoding=\"utf-8\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__!!!!!!!!!!Broken image files cannot be opened by both PIL.Image, cv2... So remove them from the list by try~except.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_images = image_dataset_no_face.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_images.reset_index(inplace=True, drop=True)\n",
    "trainable_images.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainable_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_images.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_change(image_localpath, url):\n",
    "    splitted_url = url.split('/')\n",
    "    new_url = '/'.join(splitted_url[2:])\n",
    "    new_url = os.path.join(image_localpath, new_url)\n",
    "    \n",
    "    return new_url\n",
    "\n",
    "image_localpath = os.path.join(path, 'raw_data/raw_image')\n",
    "trainable_images['url'] = trainable_images['url'].apply(lambda x: url_change(image_localpath, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_images.iloc[223702]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_images.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### !!!!!!!!!!Broken image files cannot be opened by both PIL.Image, cv2... So remove them from list by try~except.\n",
    "broken_files = []\n",
    "broken_index = []\n",
    "broken_image_index = []\n",
    "broken_seq = []\n",
    "\n",
    "for file in trainable_images['url']:\n",
    "    index = trainable_images[trainable_images['url']==file].index[0] \n",
    "    if index % 5000 == 0:\n",
    "        print(f\"Now Doing: {index}, and {len(broken_files)} files({len(broken_index)} indexes) seem to be broken...\")\n",
    "    try:\n",
    "        image = Image.open(file)\n",
    "    except:\n",
    "        drop_index = index\n",
    "        broken_files.append(file)\n",
    "        broken_index.append(drop_index)\n",
    "        broken_image_index.append(trainable_images.iloc[index]['index'])\n",
    "        broken_seq.append(trainable_images.iloc[index]['seq'])        \n",
    "\n",
    "print(f\"{len(broken_files)} files are broken...\")\n",
    "removed_broken_urls = trainable_images.drop(broken_index)\n",
    "print(f\"Removed broken file rows. Now you can use {len(removed_broken_urls)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_broken_urls.to_csv('/home/ubuntu/Desktop/Project/datasets/circlin_feeds_dataset/image_dataset/20211207_image_dataset(change_url).csv', encoding=\"utf-8\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(broken_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the list of broken files, and use it if you need additional labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_broken_files = sorted(broken_files)\n",
    "sorted_broken_index = sorted(broken_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_broken_files[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brokenfile = pd.DataFrame(data={'index': sorted_broken_index, 'file': sorted_broken_files})\n",
    "df_brokenfile.head()\n",
    "# df_broken_file = pd.DataFrame(data={\n",
    "#     \"index\": broken_image_index,\n",
    "#     \"seq\": broken_seq,\n",
    "#     \"file\": broken_files\n",
    "# })\n",
    "\n",
    "# df_broken_file.sort_values(by=['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(df_brokenfile))\n",
    "df_brokenfile.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brokenfile.to_csv('/home/ubuntu/Desktop/Project/datasets/circlin_feeds_dataset/image_dataset/20211207_broken_files.csv', encoding=\"utf-8\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
