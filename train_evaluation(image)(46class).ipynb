{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da93c77",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b130ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import printoptions\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5dcd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True #Enable processing images(prevent OSError: image file is truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296158fb",
   "metadata": {},
   "source": [
    "# 2. Set paths\n",
    " - To load dataset\n",
    " - To save checkpoints & best checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d82f0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date today: 20211204\n"
     ]
    }
   ],
   "source": [
    "#Set directories as you want.\n",
    "path = \"/home/ubuntu/Desktop/Project\"\n",
    "dataset_path = os.path.join(path, \"datasets/circlin_feeds_dataset/image_dataset\")\n",
    "\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "print(f\"Date today: {date}\")\n",
    "checkpoint_path = os.path.join(path, f\"autolabeler_classifier/resnext50_model/{date}\")\n",
    "model_path = os.path.join(path, f\"autolabeler_classifier/resnext50_model/{date}\")\n",
    "metric_path = os.path.join(path, f\"autolabeler_classifier/resnext50_model/{date}\")\n",
    "\n",
    "# Save path for logs\n",
    "# logdir = os.path.join(path, f\"autolabeler_classifier/resnext50_model/{date}/logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590f6ed",
   "metadata": {},
   "source": [
    "# 3. Training settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9dde8",
   "metadata": {},
   "source": [
    "## 3-1. Set seed number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52637839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all seeds to make experiments reproducible\n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed(2020)\n",
    "np.random.seed(2020)\n",
    "random.seed(2020)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c10801",
   "metadata": {},
   "source": [
    "## 3-2. Hyperparameters\n",
    " - __Adjust: <u>mean</u>, <u>std</u>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "643f6b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training parameters.\n",
    "NUM_WORKERS = 8 # Number of CPU processes for data preprocessing\n",
    "LEARNING_RATE = 1e-4 # Learning rate\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VALID_BATCH_SIZE = 128\n",
    "save_freq = 1 # Save checkpoint frequency (epochs)\n",
    "test_freq = 200 # Test model frequency (iterations)\n",
    "EPOCHS = 36 # Number of epochs for training \n",
    "# Note: on the small subset of data overfitting happens after 30-35 epochs\n",
    "\n",
    "\n",
    "#For normalization\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "# Run tensorboard\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1943551f",
   "metadata": {},
   "source": [
    "## 3-3. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe33abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "#criterion = nn.BCELoss() #BCEWithLogitsLoss\n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets) #BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030b9d7",
   "metadata": {},
   "source": [
    "## 3-4. Check GPU status & Enable distributed processing\n",
    " - __Should be improved!__ \n",
    "   - As is : Using DatParallel\n",
    "   - To be: Use DistributedDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf1ee95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Device check(for GPU computing)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4527158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple GPU utilization: This should be improved...\n",
    "\n",
    "# dist.init_process_group(\n",
    "#     backend='nccl',\n",
    "#     init_method='tcp://localhost:9999', #FREEPORT\n",
    "#     world_size=2,\n",
    "#     rank=0,\n",
    "# )\n",
    "\n",
    "# dist.init_process_group(\n",
    "#     backend=\"nccl\",\n",
    "#     init_method='tcp://127.0.0.1:9999',\n",
    "#     rank=0,\n",
    "#     world_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761908f2",
   "metadata": {},
   "source": [
    "## 3-5. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "534520d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "def make_optimizer(model, lr):\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params =  model.parameters(), \n",
    "        lr=lr)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e68000b",
   "metadata": {},
   "source": [
    "# 4. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e0e93",
   "metadata": {},
   "source": [
    "## 4-1. Define target labels(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07fb22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define taret labels\n",
    "labels = ['간편식', '건강간식', '건강식', '건강음료', '걷기/산책', '격투기', '골프', \n",
    "          '기타식단', '기타운동', '농구', '달리기/조깅', '당구', '등산/등반', '루틴기록', '맨몸', '무술', \n",
    "          '배구', '배드민턴', '보조제', '보충제', '볼링', '수상스포츠', '스키/스노보드', '승마', '신체기록', \n",
    "          '야구', '온라인클래스', '요가', '운동기구', '운동용품', '웨이트', '유산소기록', '의류', '일반간식', \n",
    "          '일반식', '일반음료', '일상생활', '자전거', '종합운동', '줄넘기', '축구/풋살', '탁구', '테니스', \n",
    "          '폴댄스', '필라테스', '홈트'] #46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08841c18",
   "metadata": {},
   "source": [
    "## 4-2. Create custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161492d",
   "metadata": {},
   "source": [
    "- At Image.open in __ __getitem__ __  needs .convert('RGB') because Image.open returns grayscale.\n",
    "    - https://stackoverflow.com/questions/59218671/runtimeerror-output-with-shape-1-224-224-doesnt-match-the-broadcast-shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca73d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        self.transforms = transforms\n",
    "        self.df = df\n",
    "        self.feed_image = df['url'] #Series of file name\n",
    "        self.labels = self.df[labels].values #df.values: np.array #one-hot encoded: [0, 1, 0, ...., 1, 1]\n",
    "        \n",
    "        #self.image_list = self.feed_image.tolist()\n",
    "        #self.label_list = self.labels.tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feed_image)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = torch.FloatTensor(self.labels[index])\n",
    "        image_url = self.feed_image[index]\n",
    "        \n",
    "        #Needs .convert('RGB') because Image.open returns grayscale.\n",
    "        image = Image.open(image_url).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "    \n",
    "# train_annotations = os.path.join(img_folder, 'small_train.json')\n",
    "# train_dataset = CustomDataset(img_folder, train_annotations, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bff5e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'seq', 'url', 'deidentification_x', '간편식', '건강간식', '건강식',\n",
      "       '건강음료', '걷기/산책', '격투기', '골프', '기타식단', '기타운동', '농구', '달리기/조깅', '당구',\n",
      "       '등산/등반', '루틴기록', '맨몸', '무술', '배구', '배드민턴', '보조제', '보충제', '볼링', '수상스포츠',\n",
      "       '스키/스노보드', '승마', '신체기록', '야구', '온라인클래스', '요가', '운동기구', '운동용품', '웨이트',\n",
      "       '유산소기록', '의류', '일반간식', '일반식', '일반음료', '일상생활', '자전거', '종합운동', '줄넘기',\n",
      "       '축구/풋살', '탁구', '테니스', '폴댄스', '필라테스', '홈트'],\n",
      "      dtype='object')\n",
      "['n']\n",
      "215145\n"
     ]
    }
   ],
   "source": [
    "#Get image dataset\n",
    "dataset = os.path.join(dataset_path, \"20211201_image_dataset(change_url).csv\")\n",
    "whole_df = pd.read_csv(dataset)\n",
    "print(whole_df.columns)\n",
    "print(whole_df['deidentification_x'].unique())\n",
    "print(len(whole_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0505f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', '간편식', '건강간식', '건강식', '건강음료', '걷기/산책', '격투기', '골프', '기타식단',\n",
      "       '기타운동', '농구', '달리기/조깅', '당구', '등산/등반', '루틴기록', '맨몸', '무술', '배구', '배드민턴',\n",
      "       '보조제', '보충제', '볼링', '수상스포츠', '스키/스노보드', '승마', '신체기록', '야구', '온라인클래스',\n",
      "       '요가', '운동기구', '운동용품', '웨이트', '유산소기록', '의류', '일반간식', '일반식', '일반음료',\n",
      "       '일상생활', '자전거', '종합운동', '줄넘기', '축구/풋살', '탁구', '테니스', '폴댄스', '필라테스',\n",
      "       '홈트'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>간편식</th>\n",
       "      <th>건강간식</th>\n",
       "      <th>건강식</th>\n",
       "      <th>건강음료</th>\n",
       "      <th>걷기/산책</th>\n",
       "      <th>격투기</th>\n",
       "      <th>골프</th>\n",
       "      <th>기타식단</th>\n",
       "      <th>기타운동</th>\n",
       "      <th>...</th>\n",
       "      <th>일상생활</th>\n",
       "      <th>자전거</th>\n",
       "      <th>종합운동</th>\n",
       "      <th>줄넘기</th>\n",
       "      <th>축구/풋살</th>\n",
       "      <th>탁구</th>\n",
       "      <th>테니스</th>\n",
       "      <th>폴댄스</th>\n",
       "      <th>필라테스</th>\n",
       "      <th>홈트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  간편식  건강간식  건강식  건강음료  \\\n",
       "0  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     1    0     0   \n",
       "1  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     1    0     0   \n",
       "2  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     1    0     0   \n",
       "3  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     0    0     0   \n",
       "4  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     1    0     0   \n",
       "5  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     0    0     0   \n",
       "6  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     0    0     0   \n",
       "7  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     1    0     0   \n",
       "8  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     0    0     0   \n",
       "9  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     0    1     0   \n",
       "\n",
       "   걷기/산책  격투기  골프  기타식단  기타운동  ...  일상생활  자전거  종합운동  줄넘기  축구/풋살  탁구  테니스  폴댄스  \\\n",
       "0      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "1      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "2      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "3      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "4      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "5      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "6      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "7      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "8      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "9      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "\n",
       "   필라테스  홈트  \n",
       "0     0   0  \n",
       "1     0   0  \n",
       "2     0   0  \n",
       "3     0   0  \n",
       "4     0   0  \n",
       "5     0   1  \n",
       "6     0   0  \n",
       "7     0   0  \n",
       "8     0   0  \n",
       "9     0   0  \n",
       "\n",
       "[10 rows x 47 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop useless features/columns\n",
    "copy_df = whole_df.copy()\n",
    "copy_df.drop(labels=['index', 'seq', 'deidentification_x'], axis=1, inplace=True)\n",
    "print(copy_df.columns)\n",
    "copy_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b464ec3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123.675, 116.28, 103.53)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tf-bert-text-classification/lib/python3.7/site-packages/torchvision/transforms/transforms.py:1362: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
      "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n",
      "/home/ubuntu/anaconda3/envs/tf-bert-text-classification/lib/python3.7/site-packages/torchvision/transforms/transforms.py:1376: UserWarning: Argument fillcolor is deprecated and will be removed since v0.10.0. Please, use fill instead\n",
      "  \"Argument fillcolor is deprecated and will be removed since v0.10.0. Please, use fill instead\"\n"
     ]
    }
   ],
   "source": [
    "#Train - validation split\n",
    "train_size = 0.8\n",
    "train_df = copy_df.copy().sample(frac=train_size, random_state=200).reset_index(drop=True)\n",
    "val_df = copy_df.drop(train_df.index).reset_index(drop=True)\n",
    "\n",
    "# Train preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomAffine(degrees=20, \n",
    "                            translate=(0.2, 0.2),\n",
    "                            scale=(0.5, 1.5),\n",
    "                            shear=None,\n",
    "                            resample=False, \n",
    "                            fillcolor=tuple(np.array(np.array(mean)*255).astype(int).tolist())),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Test preprocessing\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "print(tuple(np.array(np.array(mean)*255).tolist()))\n",
    "\n",
    "train_dataset = CustomDataset(train_df, train_transform)\n",
    "valid_dataset = CustomDataset(val_df, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edd955c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader =  torch.utils.data.DataLoader(train_dataset, \n",
    "                              batch_size=TRAIN_BATCH_SIZE, \n",
    "                              num_workers=NUM_WORKERS,  #0?\n",
    "                              shuffle=True,\n",
    "                              drop_last=True)\n",
    "val_data_loader =  torch.utils.data.DataLoader(valid_dataset, \n",
    "                             batch_size=VALID_BATCH_SIZE, \n",
    "                             num_workers=NUM_WORKERS) #0?\n",
    "\n",
    "#num_train_batches = int(np.ceil(len(train_dataset) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41255b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To explore file shape.\n",
    "# batchlist = []\n",
    "# datalist = []\n",
    "# for batch_idx, data in enumerate(train_data_loader):\n",
    "#     #print(batch_idx, data)\n",
    "#     batchlist.append(batch_idx)\n",
    "#     datalist.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d76fb",
   "metadata": {},
   "source": [
    "# 5. Make feed image classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5095c0",
   "metadata": {},
   "source": [
    "## 5-1. Define functions that save checkpoint of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d59b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min #valid_loss_min.item()\n",
    "\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c09f1",
   "metadata": {},
   "source": [
    "## 5-2. Define Resnext50 model as a class\n",
    " - Use pytorch implemented pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73a7eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the torchvision's implementation of ResNeXt, but add FC layer for a different number of classes (27) and a Sigmoid instead of a default Softmax.\n",
    "class ResNeXt50Class(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "#         super().__init__()\n",
    "#         resnet = models.resnext50_32x4d(pretrained=True)\n",
    "#         resnet.fc = nn.Sequential(\n",
    "#             nn.Dropout(p=0.2),\n",
    "#             nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "#         )\n",
    "#         self.base_model = resnet\n",
    "        super(ResNeXt50Class, self).__init__()\n",
    "        self.resnext_model = models.resnext50_32x4d(pretrained=True)\n",
    "        self.resnext_model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(in_features=self.resnext_model.fc.in_features, \n",
    "                      out_features=n_classes)\n",
    "        )\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.sigm(self.resnext_model(x))\n",
    "        \n",
    "        return output\n",
    "        #return self.sigm(self.base_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22f8b66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNeXt50Class(\n",
       "    (resnext_model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Sequential(\n",
       "        (0): Dropout(p=0.2, inplace=False)\n",
       "        (1): Linear(in_features=2048, out_features=46, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigm): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNeXt50Class(len(labels)) #or len(labels) #train_dataset.classes\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model) #Distributed\n",
    "#model = nn.parallel.DistributedDataParallel(model, device_ids=[0, 1]) #Distributed DataParallel  ===> Should use this!!!!!!!!!!!!!!!!!\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c183807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = make_optimizer(model, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec6432a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_targets = []\n",
    "val_outputs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d56e37",
   "metadata": {},
   "source": [
    "## 5-3. Training\n",
    " - __<u>Add Train Loss!!!!!!!!!!</u>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "832aef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "train_losses_lr = {}\n",
    "avg_train_losses_lr = {}\n",
    "val_losses_lr = {}\n",
    "avg_val_losses_lr = {}\n",
    "epoch_list = [int(x) for x in np.linspace(1, EPOCHS, EPOCHS).tolist()]\n",
    "print(epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85d1c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epochs,\n",
    "                       training_loader,\n",
    "                       validation_loader,\n",
    "                       model,\n",
    "                       optimizer,\n",
    "                       checkpoint_path,\n",
    "                       best_model_path,\n",
    "                       metric_path,\n",
    "                       date):\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf\n",
    "    train_loss_epoch = []\n",
    "    avg_train_loss_epoch = []    \n",
    "    val_loss_epoch = [] #append to val_loss_list\n",
    "    avg_val_loss_epoch = [] #append to avg_val_list\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        print(f'############# Epoch {epoch}: Training Start   #############')\n",
    "#         for images, targets in enumerate(training_loader):\n",
    "        for batch_idx, data in enumerate(training_loader):\n",
    "            images, targets = data[0], data[1]\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            if batch_idx%5000==0:\n",
    "                print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
    "        print('############# Epoch {}: Training End     #############'.format(epoch))\n",
    "        train_loss_epoch.append(train_loss)\n",
    "        print('############# Epoch {}: Validation Start   #############'.format(epoch))\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "\n",
    "        model.eval()\n",
    "   \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(validation_loader, 0):\n",
    "                images, targets = data[0], data[1]\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
    "                val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "                val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "\n",
    "            print('############# Epoch {}: Validation End     #############'.format(epoch))\n",
    "           # calculate average losses\n",
    "#             print('before calculate avg train loss', train_loss)\n",
    "            val_loss_epoch.append(valid_loss) \n",
    "            avg_train_loss = train_loss/len(training_loader)\n",
    "            avg_valid_loss = valid_loss/len(validation_loader)\n",
    "            #Print training/validation statistics\n",
    "            print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                avg_train_loss,\n",
    "                avg_valid_loss\n",
    "            ))\n",
    "            avg_train_loss_epoch.append(avg_train_loss)\n",
    "            avg_val_loss_epoch.append(avg_valid_loss) \n",
    "            \n",
    "\n",
    "            # create checkpoint variable and add important data\n",
    "            checkpoint = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'valid_loss_min': avg_valid_loss,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict()\n",
    "              }\n",
    "\n",
    "            save_ckp(checkpoint, False,  f\"{checkpoint_path}_{epoch}\", best_model_path)\n",
    "            \n",
    "\n",
    "            ## TODO: save the model if validation loss has decreased\n",
    "            if avg_valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,avg_valid_loss))\n",
    "                # save checkpoint as best model\n",
    "                save_ckp(checkpoint, True,  f\"{checkpoint_path}_{epoch}\", best_model_path)\n",
    "                valid_loss_min = avg_valid_loss\n",
    "\n",
    "        now = datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_text = f\"[{now}]: [Learning Rate {lr}, Epoch {epoch}] - train_loss = {train_loss}, avg_train_loss = {avg_train_loss}, validation_loss = {valid_loss}, avg_validation_loss = {avg_valid_loss}\\n\"\n",
    "        if os.path.isfile(os.path.join(metric_path, f\"metric_logs_resnext_{date}.txt\")):\n",
    "            with open(os.path.join(metric_path, f\"metric_logs_resnext_{date}.txt\"), 'a', encoding='utf-8') as f:\n",
    "                f.write(log_text)\n",
    "        else:\n",
    "            with open(os.path.join(metric_path, f\"metric_logs_resnext_{date}.txt\"), 'w', encoding='utf-8') as f:\n",
    "                f.write(log_text)       \n",
    "        print('############# Epoch {}  Done   #############\\n'.format(epoch))\n",
    "\n",
    "    train_losses_lr[lr] = train_loss_epoch\n",
    "    avg_train_losses_lr[lr] = avg_train_loss_epoch\n",
    "    val_losses_lr[lr] = val_loss_epoch\n",
    "    avg_val_losses_lr[lr] = avg_val_loss_epoch\n",
    "    print(f\"train_losses_lr for LR {lr}: \\n {train_losses_lr}\")\n",
    "    print(f\"avg_train_losses_lr for LR {lr}: \\n {avg_train_losses_lr}\")\n",
    "    print(f\"val_losses_lr for LR {lr}: \\n {val_losses_lr}\")\n",
    "    print(f\"avg_val_losses_lr {lr}: \\n {avg_val_losses_lr}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "248e1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use threshold to define predicted labels and invoke sklearn's metrics with different averaging strategies.\n",
    "# def calculate_metrics(pred, target, threshold=0.5):\n",
    "#     pred = np.array(pred > threshold, dtype=float)\n",
    "#     return {'micro/precision': precision_score(y_true=target, y_pred=pred, average='micro'),\n",
    "#             'micro/recall': recall_score(y_true=target, y_pred=pred, average='micro'),\n",
    "#             'micro/f1': f1_score(y_true=target, y_pred=pred, average='micro'),\n",
    "#             'macro/precision': precision_score(y_true=target, y_pred=pred, average='macro'),\n",
    "#             'macro/recall': recall_score(y_true=target, y_pred=pred, average='macro'),\n",
    "#             'macro/f1': f1_score(y_true=target, y_pred=pred, average='macro'),\n",
    "#             'samples/precision': precision_score(y_true=target, y_pred=pred, average='samples'),\n",
    "#             'samples/recall': recall_score(y_true=target, y_pred=pred, average='samples'),\n",
    "#             'samples/f1': f1_score(y_true=target, y_pred=pred, average='samples'),\n",
    "#             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187d033",
   "metadata": {},
   "source": [
    "### Set checkpoint path, best model's path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02029cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(checkpoint_path, \"curr_ckpt\")\n",
    "best_model_path = os.path.join(checkpoint_path, \"best_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd769d99",
   "metadata": {},
   "source": [
    "### Training start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33a3ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##########################################################\n",
      "##########################################################\n",
      "############### Training for learning rate 1e-06 START! ###############\n",
      "##########################################################\n",
      "##########################################################\n",
      "\n",
      "\n",
      "############# Epoch 1: Training Start   #############\n",
      "Epoch: 1, Training Loss:  0.9455404281616211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tf-bert-text-classification/lib/python3.7/site-packages/torch/cuda/nccl.py:51: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if not isinstance(inputs, collections.Container) or isinstance(inputs, torch.Tensor):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Epoch 1: Training End     #############\n",
      "############# Epoch 1: Validation Start   #############\n",
      "############# Epoch 1: Validation End     #############\n",
      "Epoch: 1 \tAvgerage Training Loss: 0.000640 \tAverage Validation Loss: 0.002304\n",
      "Validation loss decreased (inf --> 0.002304).  Saving model ...\n",
      "############# Epoch 1  Done   #############\n",
      "\n",
      "############# Epoch 2: Training Start   #############\n",
      "Epoch: 2, Training Loss:  0.7876423001289368\n",
      "############# Epoch 2: Training End     #############\n",
      "############# Epoch 2: Validation Start   #############\n",
      "############# Epoch 2: Validation End     #############\n",
      "Epoch: 2 \tAvgerage Training Loss: 0.000561 \tAverage Validation Loss: 0.002150\n",
      "Validation loss decreased (0.002304 --> 0.002150).  Saving model ...\n",
      "############# Epoch 2  Done   #############\n",
      "\n",
      "############# Epoch 3: Training Start   #############\n",
      "Epoch: 3, Training Loss:  0.7312700152397156\n",
      "############# Epoch 3: Training End     #############\n",
      "############# Epoch 3: Validation Start   #############\n",
      "############# Epoch 3: Validation End     #############\n",
      "Epoch: 3 \tAvgerage Training Loss: 0.000534 \tAverage Validation Loss: 0.002091\n",
      "Validation loss decreased (0.002150 --> 0.002091).  Saving model ...\n",
      "############# Epoch 3  Done   #############\n",
      "\n",
      "############# Epoch 4: Training Start   #############\n",
      "Epoch: 4, Training Loss:  0.7081089019775391\n"
     ]
    }
   ],
   "source": [
    "#For hyperparameter tuning\n",
    "for lr in learning_rate:\n",
    "    print('\\n')\n",
    "    print(f'##########################################################')\n",
    "    print(f'##########################################################')    \n",
    "    print(f'############### Training for learning rate {lr} START! ###############')\n",
    "    print(f'##########################################################')\n",
    "    print(f'##########################################################')\n",
    "    print('\\n')\n",
    "    optimizer = make_optimizer(model, lr)\n",
    "    train_model(EPOCHS,\n",
    "               train_data_loader,\n",
    "               val_data_loader,\n",
    "               model,\n",
    "               optimizer,\n",
    "               os.path.join(checkpoint_path, f\"curr_ckpt_{lr}\"),\n",
    "               best_model_path,\n",
    "               metric_path,\n",
    "               date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584f93a",
   "metadata": {},
   "source": [
    "### Check & Visualize validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37642fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['dodgerblue', 'green', 'violet', 'orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb57324",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate):\n",
    "    plt.title(\"Losses per epoch\")\n",
    "    plt.plot(epoch_list, \n",
    "             train_losses_lr[lr], \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Train\")    \n",
    "    plt.plot(epoch_list, \n",
    "             val_losses_lr[lr], \n",
    "             '--', \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Val\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate):\n",
    "    plt.title(\"Gap of loss per epoch\")\n",
    "    plt.plot(epoch_list, \n",
    "             np.array(train_losses_lr[lr]) - np.array(val_losses_lr[lr]), \n",
    "             color=color[index], \n",
    "             label=lr)    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Gap of loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate):\n",
    "    plt.title(\"Average losses per epoch\")\n",
    "    plt.plot(epoch_list, \n",
    "             avg_train_losses_lr[lr], \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Train\")    \n",
    "    plt.plot(epoch_list, \n",
    "             avg_val_losses_lr[lr], \n",
    "             '--', \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Val\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640fccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate):\n",
    "    plt.title(\"Gap of Average loss per epoch\")\n",
    "    plt.plot(epoch_list, \n",
    "             np.array(avg_train_losses_lr[lr]) - np.array(avg_val_losses_lr[lr]), \n",
    "             color=color[index], \n",
    "             label=lr)    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Gap of average loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad4a69",
   "metadata": {},
   "source": [
    "- Let's see losses in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b5b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate[1:]):\n",
    "    plt.title(\"Losses per epoch: lr = [1e-05, 1e-04, 1e-03]\")\n",
    "    plt.plot(epoch_list, \n",
    "             train_losses_lr[lr], \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Train\")    \n",
    "    plt.plot(epoch_list, \n",
    "             val_losses_lr[lr], \n",
    "             '--', \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Val\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7139eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate[1:]):\n",
    "    plt.title(\"Gap of loss per epoch: lr = [1e-05, 1e-04, 1e-03]\")\n",
    "    plt.plot(epoch_list, \n",
    "             np.array(train_losses_lr[lr]) - np.array(val_losses_lr[lr]), \n",
    "             color=color[index], \n",
    "             label=lr)    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Gap of loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a857329",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate[1:]):\n",
    "    plt.title(\"Average losses per epoch: lr = [1e-05, 1e-04, 1e-03]\")\n",
    "    plt.plot(epoch_list,\n",
    "             avg_train_losses_lr[lr], \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Train\")    \n",
    "    plt.plot(epoch_list, \n",
    "             avg_val_losses_lr[lr], \n",
    "             '--', \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Val\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a784ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate[1:]):\n",
    "    plt.title(\"Gap of Average loss per epoch: lr = [1e-05, 1e-04, 1e-03]\")\n",
    "    plt.plot(epoch_list, \n",
    "             np.array(avg_train_losses_lr[lr]) - np.array(avg_val_losses_lr[lr]), \n",
    "             color=color[index], \n",
    "             label=lr)    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Gap of average loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faef882",
   "metadata": {},
   "source": [
    "__Minimum validation loss:  Learning rate = 0000, epoch = 00__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe9f1b",
   "metadata": {},
   "source": [
    "## 5-5. Evaluate model\n",
    " - Test with validation dataset\n",
    " - 1st important index: Precision\n",
    " - 2nd importand index: Recall\n",
    "   - __First, get high & stable <u>Precision</u>, then improve <u>Recall</u>.__\n",
    " - And other indexes: F1 score, confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc51a24",
   "metadata": {},
   "source": [
    "# 6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb4b67",
   "metadata": {},
   "source": [
    "## 6-1. Define preprocessing function for input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        transformed_image = Image.open(urlopen(image)).convert('RGB') #OR open(image)\n",
    "    except:\n",
    "        return \"Cannot open image\"\n",
    "    \n",
    "    transformed_image = transform(transformed_image)\n",
    "    \n",
    "    return transformed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af390d",
   "metadata": {},
   "source": [
    "## 6-2. Load saved model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b276bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "load_model = ResNeXt50Class()\n",
    "load_model = load_model.cuda() #for GPU computation\n",
    "load_model = nn.DataParallel(load_model) # Distributed\n",
    "best_model_path = os.path.join(checkpoint_path, \"20211126/curr_ckpt_1e-05_16\") #currently best model state.\n",
    "\n",
    "best_optimizer = make_optimizer(\"loaded_model or best_model_path\", \"LEARNING_RATE\") # <-- Parameter shoud be changed!\n",
    "\n",
    "predicton_model = load_ckp(best_model_path,  #Path to the saved checkpoint\n",
    "                        load_model,\n",
    "                        best_optimizer)[0] #load_ckp: [model, optimizer, checkpoint['epoch'], valid_loss_min.item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc654031",
   "metadata": {},
   "source": [
    "## 6-3. Define inference function\n",
    " - Return dictionaries of predicted labels: {label1: score1, label2: score2, ....}\n",
    " - __Labeles which has lower score than threshold will be ignored.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b871f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image, model, device):\n",
    "    preprocessed_image = preprocessing(image)\n",
    "    \n",
    "    if preprocessed_image == \"Cannot open image\":\n",
    "        return \"Cannot open image.\"\n",
    "\n",
    "    #for gpu computation\n",
    "    if device.type == 'cuda':\n",
    "        model.cuda()\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(preprocessed_image)\n",
    "        final_output = torch.sigmoid(output).cpu().detach().numpy().tolist() #1*46 list in a list\n",
    "    #     print(final_output)\n",
    "    #     print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])\n",
    "        result_pair = zip(train_df.columns[1:].to_list(), final_output[0])\n",
    "        result_dict = {}\n",
    "        for label, score in result_pair:\n",
    "            if score > 0.1: #Set prediction threshold\n",
    "                result_dict[label] = score\n",
    "    return sorted(result_dict.items(), key=(lambda x: x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b32e3",
   "metadata": {},
   "source": [
    "- Reference code for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14471026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# for sample_id in [1,2,3,4,6]:\n",
    "#     test_img, test_labels = test_dataset[sample_id]\n",
    "#     test_img_path = os.path.join(img_folder, test_dataset.imgs[sample_id])\n",
    "#     with torch.no_grad():\n",
    "#         raw_pred = model(test_img.unsqueeze(0)).cpu().numpy()[0]\n",
    "#         raw_pred = np.array(raw_pred > 0.5, dtype=float)\n",
    "\n",
    "#     predicted_labels = np.array(dataset_val.classes)[np.argwhere(raw_pred > 0)[:, 0]]\n",
    "#     if not len(predicted_labels):\n",
    "#         predicted_labels = ['no predictions']\n",
    "#     img_labels = np.array(dataset_val.classes)[np.argwhere(test_labels > 0)[:, 0]]\n",
    "#     plt.imshow(Image.open(test_img_path))\n",
    "#     plt.title(\"Predicted labels: {} \\nGT labels: {}\".format(', '.join(predicted_labels), ', '.join(img_labels)))\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a04e3",
   "metadata": {},
   "source": [
    "## 6-4. Demo test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = \"\"\n",
    "\n",
    "inference(test_image, #Input sentence\n",
    "         predicton_model,\n",
    "          device) #CPU or GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-bert-text-classification",
   "language": "python",
   "name": "tf-bert-text-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
