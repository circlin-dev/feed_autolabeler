{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da93c77",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b130ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import printoptions\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5dcd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True #Enable processing images(prevent OSError: image file is truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296158fb",
   "metadata": {},
   "source": [
    "# 2. Set paths\n",
    " - To load dataset\n",
    " - To save checkpoints & best checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d82f0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date today: 20211227\n"
     ]
    }
   ],
   "source": [
    "#Set directories as you want.\n",
    "path = \"/home/ubuntu/Desktop/Project\"\n",
    "dataset_path = os.path.join(path, \"datasets/circlin_feeds_dataset/image_dataset\")\n",
    "\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "print(f\"Date today: {date}\")\n",
    "checkpoint_path = os.path.join(path, f\"autolabeler_classifier/resnext50_model/{date}\")\n",
    "model_path = os.path.join(path, f\"autolabeler_classifier/resnext50_model/{date}\")\n",
    "metric_path = os.path.join(path, f\"autolabeler_classifier/resnext50_model/{date}\")\n",
    "\n",
    "# Save path for logs\n",
    "# logdir = os.path.join(path, f\"autolabeler_classifier/resnext50_model/{date}/logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590f6ed",
   "metadata": {},
   "source": [
    "# 3. Training settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9dde8",
   "metadata": {},
   "source": [
    "## 3-1. Set seed number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52637839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all seeds to make experiments reproducible\n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed(2020)\n",
    "np.random.seed(2020)\n",
    "random.seed(2020)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c10801",
   "metadata": {},
   "source": [
    "## 3-2. Hyperparameters\n",
    " - __Adjust: <u>mean</u>, <u>std</u>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "643f6b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training parameters.s\n",
    "NUM_WORKERS = 8 # Number of CPU processes for data preprocessing\n",
    "LEARNING_RATE = 1e-5 # Learning rate\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "VALID_BATCH_SIZE = 256\n",
    "save_freq = 1 # Save checkpoint frequency (epochs)\n",
    "test_freq = 200 # Test model frequency (iterations)\n",
    "EPOCHS = 56 # Number of epochs for training \n",
    "# Note: on the small subset of data overfitting happens after 30-35 epochs\n",
    "\n",
    "\n",
    "#For normalization\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "# Run tensorboard\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1943551f",
   "metadata": {},
   "source": [
    "## 3-3. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe33abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCELoss()(outputs, targets) #BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030b9d7",
   "metadata": {},
   "source": [
    "## 3-4. Check GPU status & Enable distributed processing\n",
    " - __Should be improved!__ \n",
    "   - As is : Using DatParallel\n",
    "   - To be: Use DistributedDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf1ee95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Device check(for GPU computing)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4527158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple GPU utilization: This should be improved...\n",
    "\n",
    "# dist.init_process_group(\n",
    "#     backend='nccl',\n",
    "#     init_method='tcp://localhost:9999', #FREEPORT\n",
    "#     world_size=2,\n",
    "#     rank=0,\n",
    "# )\n",
    "\n",
    "# dist.init_process_group(\n",
    "#     backend=\"nccl\",\n",
    "#     init_method='tcp://127.0.0.1:9999',\n",
    "#     rank=0,\n",
    "#     world_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761908f2",
   "metadata": {},
   "source": [
    "## 3-5. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "534520d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "def make_optimizer(model, lr):\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params =  model.parameters(), \n",
    "        lr=lr)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e68000b",
   "metadata": {},
   "source": [
    "# 4. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e0e93",
   "metadata": {},
   "source": [
    "## 4-1. Define target labels(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07fb22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define taret labels\n",
    "labels = ['간편식', '건강간식', '건강식', '건강음료', '걷기/산책', '격투기', '골프', \n",
    "          '기타식단', '기타운동', '농구', '달리기/조깅', '당구', '등산/등반', '루틴기록', '맨몸', '무술', \n",
    "          '배구', '배드민턴', '보조제', '보충제', '볼링', '수상스포츠', '스키/스노보드', '승마', '신체기록', \n",
    "          '야구', '온라인클래스', '요가', '운동기구', '운동용품', '웨이트', '유산소기록', '의류', '일반간식', \n",
    "          '일반식', '일반음료', '일상생활', '자전거', '종합운동', '줄넘기', '축구/풋살', '탁구', '테니스', \n",
    "          '폴댄스', '필라테스', '홈트'] #46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08841c18",
   "metadata": {},
   "source": [
    "## 4-2. Create custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161492d",
   "metadata": {},
   "source": [
    "- At Image.open in __ __getitem__ __  needs .convert('RGB') because Image.open returns grayscale.\n",
    "    - https://stackoverflow.com/questions/59218671/runtimeerror-output-with-shape-1-224-224-doesnt-match-the-broadcast-shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca73d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        self.transforms = transforms\n",
    "        self.df = df\n",
    "        self.feed_image = df['url'] #Series of file name\n",
    "        self.labels = self.df[labels].values #df.values: np.array #one-hot encoded: [0, 1, 0, ...., 1, 1]\n",
    "        \n",
    "        #self.image_list = self.feed_image.tolist()\n",
    "        #self.label_list = self.labels.tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feed_image)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = torch.FloatTensor(self.labels[index])\n",
    "        image_url = self.feed_image[index]\n",
    "        \n",
    "        #Needs .convert('RGB') because Image.open returns grayscale.\n",
    "        image = Image.open(image_url).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "    \n",
    "# train_annotations = os.path.join(img_folder, 'small_train.json')\n",
    "# train_dataset = CustomDataset(img_folder, train_annotations, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bff5e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'seq', 'url', 'deidentification_x', '간편식', '건강간식', '건강식',\n",
      "       '건강음료', '걷기/산책', '격투기', '골프', '기타식단', '기타운동', '농구', '달리기/조깅', '당구',\n",
      "       '등산/등반', '루틴기록', '맨몸', '무술', '배구', '배드민턴', '보조제', '보충제', '볼링', '수상스포츠',\n",
      "       '스키/스노보드', '승마', '신체기록', '야구', '온라인클래스', '요가', '운동기구', '운동용품', '웨이트',\n",
      "       '유산소기록', '의류', '일반간식', '일반식', '일반음료', '일상생활', '자전거', '종합운동', '줄넘기',\n",
      "       '축구/풋살', '탁구', '테니스', '폴댄스', '필라테스', '홈트'],\n",
      "      dtype='object')\n",
      "['n']\n",
      "215145\n"
     ]
    }
   ],
   "source": [
    "#Get image dataset\n",
    "dataset = os.path.join(dataset_path, \"20211201_image_dataset(change_url).csv\")\n",
    "whole_df = pd.read_csv(dataset)\n",
    "print(whole_df.columns)\n",
    "print(whole_df['deidentification_x'].unique())\n",
    "print(len(whole_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0505f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', '간편식', '건강간식', '건강식', '건강음료', '걷기/산책', '격투기', '골프', '기타식단',\n",
      "       '기타운동', '농구', '달리기/조깅', '당구', '등산/등반', '루틴기록', '맨몸', '무술', '배구', '배드민턴',\n",
      "       '보조제', '보충제', '볼링', '수상스포츠', '스키/스노보드', '승마', '신체기록', '야구', '온라인클래스',\n",
      "       '요가', '운동기구', '운동용품', '웨이트', '유산소기록', '의류', '일반간식', '일반식', '일반음료',\n",
      "       '일상생활', '자전거', '종합운동', '줄넘기', '축구/풋살', '탁구', '테니스', '폴댄스', '필라테스',\n",
      "       '홈트'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>간편식</th>\n",
       "      <th>건강간식</th>\n",
       "      <th>건강식</th>\n",
       "      <th>건강음료</th>\n",
       "      <th>걷기/산책</th>\n",
       "      <th>격투기</th>\n",
       "      <th>골프</th>\n",
       "      <th>기타식단</th>\n",
       "      <th>기타운동</th>\n",
       "      <th>...</th>\n",
       "      <th>일상생활</th>\n",
       "      <th>자전거</th>\n",
       "      <th>종합운동</th>\n",
       "      <th>줄넘기</th>\n",
       "      <th>축구/풋살</th>\n",
       "      <th>탁구</th>\n",
       "      <th>테니스</th>\n",
       "      <th>폴댄스</th>\n",
       "      <th>필라테스</th>\n",
       "      <th>홈트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/ubuntu/Desktop/Project/datasets/circlin_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  간편식  건강간식  건강식  건강음료  \\\n",
       "0  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     1    0     0   \n",
       "1  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     1    0     0   \n",
       "2  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     1    0     0   \n",
       "3  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     0    0     0   \n",
       "4  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     1    0     0   \n",
       "5  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     0    0     0   \n",
       "6  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     0    0     0   \n",
       "7  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     1    0     0   \n",
       "8  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     0    0     0   \n",
       "9  /home/ubuntu/Desktop/Project/datasets/circlin_...    0     0    1     0   \n",
       "\n",
       "   걷기/산책  격투기  골프  기타식단  기타운동  ...  일상생활  자전거  종합운동  줄넘기  축구/풋살  탁구  테니스  폴댄스  \\\n",
       "0      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "1      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "2      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "3      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "4      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "5      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "6      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "7      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "8      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "9      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "\n",
       "   필라테스  홈트  \n",
       "0     0   0  \n",
       "1     0   0  \n",
       "2     0   0  \n",
       "3     0   0  \n",
       "4     0   0  \n",
       "5     0   1  \n",
       "6     0   0  \n",
       "7     0   0  \n",
       "8     0   0  \n",
       "9     0   0  \n",
       "\n",
       "[10 rows x 47 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop useless features/columns\n",
    "copy_df = whole_df.copy()\n",
    "copy_df.drop(labels=['index', 'seq', 'deidentification_x'], axis=1, inplace=True)\n",
    "print(copy_df.columns)\n",
    "copy_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b464ec3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123.675, 116.28, 103.53)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tf-bert-text-classification/lib/python3.7/site-packages/torchvision/transforms/transforms.py:1362: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
      "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n",
      "/home/ubuntu/anaconda3/envs/tf-bert-text-classification/lib/python3.7/site-packages/torchvision/transforms/transforms.py:1376: UserWarning: Argument fillcolor is deprecated and will be removed since v0.10.0. Please, use fill instead\n",
      "  \"Argument fillcolor is deprecated and will be removed since v0.10.0. Please, use fill instead\"\n"
     ]
    }
   ],
   "source": [
    "#Train - validation split\n",
    "train_size = 0.8\n",
    "train_df = copy_df.copy().sample(frac=train_size, random_state=200).reset_index(drop=True)\n",
    "val_df = copy_df.drop(train_df.index).reset_index(drop=True)\n",
    "\n",
    "# Train preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomAffine(degrees=20, \n",
    "                            translate=(0.2, 0.2),\n",
    "                            scale=(0.5, 1.5),\n",
    "                            shear=None,\n",
    "                            resample=False, \n",
    "                            fillcolor=tuple(np.array(np.array(mean)*255).astype(int).tolist())),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Test preprocessing\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "print(tuple(np.array(np.array(mean)*255).tolist()))\n",
    "\n",
    "train_dataset = CustomDataset(train_df, train_transform)\n",
    "valid_dataset = CustomDataset(val_df, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edd955c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader =  torch.utils.data.DataLoader(train_dataset, \n",
    "                              batch_size=TRAIN_BATCH_SIZE, \n",
    "                              num_workers=NUM_WORKERS,  #0?\n",
    "                              shuffle=True,\n",
    "                              drop_last=True)\n",
    "val_data_loader =  torch.utils.data.DataLoader(valid_dataset, \n",
    "                             batch_size=VALID_BATCH_SIZE, \n",
    "                             num_workers=NUM_WORKERS) #0?\n",
    "\n",
    "#num_train_batches = int(np.ceil(len(train_dataset) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41255b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To explore file shape.\n",
    "# batchlist = []\n",
    "# datalist = []\n",
    "# for batch_idx, data in enumerate(train_data_loader):\n",
    "#     #print(batch_idx, data)\n",
    "#     batchlist.append(batch_idx)\n",
    "#     datalist.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d76fb",
   "metadata": {},
   "source": [
    "# 5. Make feed image classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5095c0",
   "metadata": {},
   "source": [
    "## 5-1. Define functions that save checkpoint of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d59b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min #valid_loss_min.item()\n",
    "\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c09f1",
   "metadata": {},
   "source": [
    "## 5-2. Define Resnext50 model as a class\n",
    " - Use pytorch implemented pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73a7eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXt50Class(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "#         super().__init__()\n",
    "#         resnet = models.resnext50_32x4d(pretrained=True)\n",
    "#         resnet.fc = nn.Sequential(\n",
    "#             nn.Dropout(p=0.2),\n",
    "#             nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "#         )\n",
    "#         self.base_model = resnet\n",
    "        super(ResNeXt50Class, self).__init__()\n",
    "        self.resnext_model = models.resnext50_32x4d(pretrained=True)\n",
    "        self.resnext_model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=self.resnext_model.fc.in_features, \n",
    "                      out_features=n_classes)\n",
    "        )\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.sigm(self.resnext_model(x))\n",
    "        \n",
    "        return output\n",
    "        #return self.sigm(self.base_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22f8b66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNeXt50Class(\n",
       "    (resnext_model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Sequential(\n",
       "        (0): Dropout(p=0.3, inplace=False)\n",
       "        (1): Linear(in_features=2048, out_features=46, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigm): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNeXt50Class(len(labels)) #or len(labels) #train_dataset.classes\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model) #Distributed\n",
    "#model = nn.parallel.DistributedDataParallel(model, device_ids=[0, 1]) #Distributed DataParallel  ===> Should use this!!!!!!!!!!!!!!!!!\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c183807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = make_optimizer(model, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec6432a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_targets = []\n",
    "val_outputs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d56e37",
   "metadata": {},
   "source": [
    "## 5-3. Training\n",
    " - __<u>Add Train Loss!!!!!!!!!!</u>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "832aef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = [\n",
    "#                  0.00001, 0.00002, 0.00003, 0.00004, 0.00005,                 \n",
    "#                  0.0001, 0.0002, 0.0003, 0.0004, 0.0005,\n",
    "#                  0.001, 0.002, 0.003, 0.004, 0.005,\n",
    "#                  0.01, 0.02, 0.03, 0.04, 0.05,\n",
    "#                  0.1, 0.2, 0.3, 0.4, 0.5,\n",
    "#                  0.000001, 0.000002, 0.000003, 0.000004, 0.000005]\n",
    "train_losses_lr = {}\n",
    "avg_train_losses_lr = {}\n",
    "val_losses_lr = {}\n",
    "avg_val_losses_lr = {}\n",
    "epoch_list = [int(x) for x in np.linspace(1, EPOCHS, EPOCHS).tolist()]\n",
    "print(epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85d1c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epochs,\n",
    "                       training_loader,\n",
    "                       validation_loader,\n",
    "                       model,\n",
    "                       optimizer,\n",
    "                       checkpoint_path,\n",
    "                       best_model_path,\n",
    "                       metric_path,\n",
    "                       date):\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf\n",
    "    train_loss_epoch = []\n",
    "    avg_train_loss_epoch = []    \n",
    "    val_loss_epoch = [] #append to val_loss_list\n",
    "    avg_val_loss_epoch = [] #append to avg_val_list\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        print(f'############# Epoch {epoch}: Training Start   #############')\n",
    "        for batch_idx, data in enumerate(training_loader):\n",
    "            images, targets = data[0], data[1]\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            if batch_idx%5000==0:\n",
    "                print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
    "        print('############# Epoch {}: Training End     #############'.format(epoch))\n",
    "        train_loss_epoch.append(train_loss)\n",
    "        print('############# Epoch {}: Validation Start   #############'.format(epoch))\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "\n",
    "        model.eval()\n",
    "   \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(validation_loader, 0):\n",
    "                images, targets = data[0], data[1]\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
    "                val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "                val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "\n",
    "            print('############# Epoch {}: Validation End     #############'.format(epoch))\n",
    "           # calculate average losses\n",
    "#             print('before calculate avg train loss', train_loss)\n",
    "            val_loss_epoch.append(valid_loss) \n",
    "            avg_train_loss = train_loss/len(training_loader)\n",
    "            avg_valid_loss = valid_loss/len(validation_loader)\n",
    "            #Print training/validation statistics\n",
    "            print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                avg_train_loss,\n",
    "                avg_valid_loss\n",
    "            ))\n",
    "            avg_train_loss_epoch.append(avg_train_loss)\n",
    "            avg_val_loss_epoch.append(avg_valid_loss) \n",
    "            \n",
    "\n",
    "            # create checkpoint variable and add important data\n",
    "            checkpoint = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'valid_loss_min': avg_valid_loss,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict()\n",
    "              }\n",
    "\n",
    "            save_ckp(checkpoint, False,  f\"{checkpoint_path}_{epoch}\", best_model_path)\n",
    "            \n",
    "            ## TODO: save the model if validation loss has decreased\n",
    "            if avg_valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,avg_valid_loss))\n",
    "                # save checkpoint as best model\n",
    "                save_ckp(checkpoint, True,  f\"{checkpoint_path}_{epoch}\", best_model_path)\n",
    "                valid_loss_min = avg_valid_loss\n",
    "\n",
    "        now = datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_text = f\"[{now}]: [Learning Rate {lr}, Epoch {epoch}] - train_loss = {train_loss}, avg_train_loss = {avg_train_loss}, validation_loss = {valid_loss}, avg_validation_loss = {avg_valid_loss}\\n\"\n",
    "        if os.path.isfile(os.path.join(metric_path, f\"metric_logs_resnext_{date}.txt\")):\n",
    "            with open(os.path.join(metric_path, f\"metric_logs_resnext_{date}.txt\"), 'a', encoding='utf-8') as f:\n",
    "                f.write(log_text)\n",
    "        else:\n",
    "            with open(os.path.join(metric_path, f\"metric_logs_resnext_{date}.txt\"), 'w', encoding='utf-8') as f:\n",
    "                f.write(log_text)       \n",
    "        print('############# Epoch {}  Done   #############\\n'.format(epoch))\n",
    "\n",
    "    train_losses_lr[lr] = train_loss_epoch\n",
    "    avg_train_losses_lr[lr] = avg_train_loss_epoch\n",
    "    val_losses_lr[lr] = val_loss_epoch\n",
    "    avg_val_losses_lr[lr] = avg_val_loss_epoch\n",
    "    print(f\"train_losses_lr for LR {lr}: \\n {train_losses_lr}\")\n",
    "    print(f\"avg_train_losses_lr for LR {lr}: \\n {avg_train_losses_lr}\")\n",
    "    print(f\"val_losses_lr for LR {lr}: \\n {val_losses_lr}\")\n",
    "    print(f\"avg_val_losses_lr {lr}: \\n {avg_val_losses_lr}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "248e1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use threshold to define predicted labels and invoke sklearn's metrics with different averaging strategies.\n",
    "# def calculate_metrics(pred, target, threshold=0.5):\n",
    "#     pred = np.array(pred > threshold, dtype=float)\n",
    "#     return {'micro/precision': precision_score(y_true=target, y_pred=pred, average='micro'),\n",
    "#             'micro/recall': recall_score(y_true=target, y_pred=pred, average='micro'),\n",
    "#             'micro/f1': f1_score(y_true=target, y_pred=pred, average='micro'),\n",
    "#             'macro/precision': precision_score(y_true=target, y_pred=pred, average='macro'),\n",
    "#             'macro/recall': recall_score(y_true=target, y_pred=pred, average='macro'),\n",
    "#             'macro/f1': f1_score(y_true=target, y_pred=pred, average='macro'),\n",
    "#             'samples/precision': precision_score(y_true=target, y_pred=pred, average='samples'),\n",
    "#             'samples/recall': recall_score(y_true=target, y_pred=pred, average='samples'),\n",
    "#             'samples/f1': f1_score(y_true=target, y_pred=pred, average='samples'),\n",
    "#             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187d033",
   "metadata": {},
   "source": [
    "### Set checkpoint path, best model's path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02029cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(checkpoint_path, \"curr_ckpt\")\n",
    "best_model_path = os.path.join(checkpoint_path, \"best_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd769d99",
   "metadata": {},
   "source": [
    "### Training start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33a3ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##########################################################\n",
      "##########################################################\n",
      "############### Training for learning rate 1e-05 START! ###############\n",
      "##########################################################\n",
      "##########################################################\n",
      "\n",
      "\n",
      "############# Epoch 1: Training Start   #############\n",
      "Epoch: 1, Training Loss:  0.09049102663993835\n",
      "############# Epoch 1: Training End     #############\n",
      "############# Epoch 1: Validation Start   #############\n",
      "############# Epoch 1: Validation End     #############\n",
      "Epoch: 1 \tAvgerage Training Loss: 0.000097 \tAverage Validation Loss: 0.000310\n",
      "Validation loss decreased (inf --> 0.000310).  Saving model ...\n",
      "############# Epoch 1  Done   #############\n",
      "\n",
      "############# Epoch 2: Training Start   #############\n",
      "Epoch: 2, Training Loss:  0.06278601288795471\n",
      "############# Epoch 2: Training End     #############\n",
      "############# Epoch 2: Validation Start   #############\n",
      "############# Epoch 2: Validation End     #############\n",
      "Epoch: 2 \tAvgerage Training Loss: 0.000083 \tAverage Validation Loss: 0.000284\n",
      "Validation loss decreased (0.000310 --> 0.000284).  Saving model ...\n",
      "############# Epoch 2  Done   #############\n",
      "\n",
      "############# Epoch 3: Training Start   #############\n",
      "Epoch: 3, Training Loss:  0.049766793847084045\n",
      "############# Epoch 3: Training End     #############\n",
      "############# Epoch 3: Validation Start   #############\n",
      "############# Epoch 3: Validation End     #############\n",
      "Epoch: 3 \tAvgerage Training Loss: 0.000078 \tAverage Validation Loss: 0.000270\n",
      "Validation loss decreased (0.000284 --> 0.000270).  Saving model ...\n",
      "############# Epoch 3  Done   #############\n",
      "\n",
      "############# Epoch 4: Training Start   #############\n",
      "Epoch: 4, Training Loss:  0.05304301530122757\n",
      "############# Epoch 4: Training End     #############\n",
      "############# Epoch 4: Validation Start   #############\n",
      "############# Epoch 4: Validation End     #############\n",
      "Epoch: 4 \tAvgerage Training Loss: 0.000075 \tAverage Validation Loss: 0.000260\n",
      "Validation loss decreased (0.000270 --> 0.000260).  Saving model ...\n",
      "############# Epoch 4  Done   #############\n",
      "\n",
      "############# Epoch 5: Training Start   #############\n",
      "Epoch: 5, Training Loss:  0.0509381927549839\n",
      "############# Epoch 5: Training End     #############\n",
      "############# Epoch 5: Validation Start   #############\n",
      "############# Epoch 5: Validation End     #############\n",
      "Epoch: 5 \tAvgerage Training Loss: 0.000072 \tAverage Validation Loss: 0.000253\n",
      "Validation loss decreased (0.000260 --> 0.000253).  Saving model ...\n",
      "############# Epoch 5  Done   #############\n",
      "\n",
      "############# Epoch 6: Training Start   #############\n",
      "Epoch: 6, Training Loss:  0.044653479009866714\n",
      "############# Epoch 6: Training End     #############\n",
      "############# Epoch 6: Validation Start   #############\n",
      "############# Epoch 6: Validation End     #############\n",
      "Epoch: 6 \tAvgerage Training Loss: 0.000070 \tAverage Validation Loss: 0.000243\n",
      "Validation loss decreased (0.000253 --> 0.000243).  Saving model ...\n",
      "############# Epoch 6  Done   #############\n",
      "\n",
      "############# Epoch 7: Training Start   #############\n",
      "Epoch: 7, Training Loss:  0.04723617807030678\n",
      "############# Epoch 7: Training End     #############\n",
      "############# Epoch 7: Validation Start   #############\n",
      "############# Epoch 7: Validation End     #############\n",
      "Epoch: 7 \tAvgerage Training Loss: 0.000068 \tAverage Validation Loss: 0.000237\n",
      "Validation loss decreased (0.000243 --> 0.000237).  Saving model ...\n",
      "############# Epoch 7  Done   #############\n",
      "\n",
      "############# Epoch 8: Training Start   #############\n",
      "Epoch: 8, Training Loss:  0.048739030957221985\n",
      "############# Epoch 8: Training End     #############\n",
      "############# Epoch 8: Validation Start   #############\n",
      "############# Epoch 8: Validation End     #############\n",
      "Epoch: 8 \tAvgerage Training Loss: 0.000067 \tAverage Validation Loss: 0.000231\n",
      "Validation loss decreased (0.000237 --> 0.000231).  Saving model ...\n",
      "############# Epoch 8  Done   #############\n",
      "\n",
      "############# Epoch 9: Training Start   #############\n",
      "Epoch: 9, Training Loss:  0.041326362639665604\n",
      "############# Epoch 9: Training End     #############\n",
      "############# Epoch 9: Validation Start   #############\n",
      "############# Epoch 9: Validation End     #############\n",
      "Epoch: 9 \tAvgerage Training Loss: 0.000065 \tAverage Validation Loss: 0.000229\n",
      "Validation loss decreased (0.000231 --> 0.000229).  Saving model ...\n",
      "############# Epoch 9  Done   #############\n",
      "\n",
      "############# Epoch 10: Training Start   #############\n",
      "Epoch: 10, Training Loss:  0.04511240869760513\n",
      "############# Epoch 10: Training End     #############\n",
      "############# Epoch 10: Validation Start   #############\n",
      "############# Epoch 10: Validation End     #############\n",
      "Epoch: 10 \tAvgerage Training Loss: 0.000064 \tAverage Validation Loss: 0.000226\n",
      "Validation loss decreased (0.000229 --> 0.000226).  Saving model ...\n",
      "############# Epoch 10  Done   #############\n",
      "\n",
      "############# Epoch 11: Training Start   #############\n",
      "Epoch: 11, Training Loss:  0.04481089860200882\n",
      "############# Epoch 11: Training End     #############\n",
      "############# Epoch 11: Validation Start   #############\n",
      "############# Epoch 11: Validation End     #############\n",
      "Epoch: 11 \tAvgerage Training Loss: 0.000063 \tAverage Validation Loss: 0.000218\n",
      "Validation loss decreased (0.000226 --> 0.000218).  Saving model ...\n",
      "############# Epoch 11  Done   #############\n",
      "\n",
      "############# Epoch 12: Training Start   #############\n",
      "Epoch: 12, Training Loss:  0.03744346648454666\n",
      "############# Epoch 12: Training End     #############\n",
      "############# Epoch 12: Validation Start   #############\n",
      "############# Epoch 12: Validation End     #############\n",
      "Epoch: 12 \tAvgerage Training Loss: 0.000062 \tAverage Validation Loss: 0.000216\n",
      "Validation loss decreased (0.000218 --> 0.000216).  Saving model ...\n",
      "############# Epoch 12  Done   #############\n",
      "\n",
      "############# Epoch 13: Training Start   #############\n",
      "Epoch: 13, Training Loss:  0.042375534772872925\n",
      "############# Epoch 13: Training End     #############\n",
      "############# Epoch 13: Validation Start   #############\n",
      "############# Epoch 13: Validation End     #############\n",
      "Epoch: 13 \tAvgerage Training Loss: 0.000061 \tAverage Validation Loss: 0.000212\n",
      "Validation loss decreased (0.000216 --> 0.000212).  Saving model ...\n",
      "############# Epoch 13  Done   #############\n",
      "\n",
      "############# Epoch 14: Training Start   #############\n",
      "Epoch: 14, Training Loss:  0.041661325842142105\n",
      "############# Epoch 14: Training End     #############\n",
      "############# Epoch 14: Validation Start   #############\n",
      "############# Epoch 14: Validation End     #############\n",
      "Epoch: 14 \tAvgerage Training Loss: 0.000059 \tAverage Validation Loss: 0.000207\n",
      "Validation loss decreased (0.000212 --> 0.000207).  Saving model ...\n",
      "############# Epoch 14  Done   #############\n",
      "\n",
      "############# Epoch 15: Training Start   #############\n",
      "Epoch: 15, Training Loss:  0.038229506462812424\n",
      "############# Epoch 15: Training End     #############\n",
      "############# Epoch 15: Validation Start   #############\n",
      "############# Epoch 15: Validation End     #############\n",
      "Epoch: 15 \tAvgerage Training Loss: 0.000059 \tAverage Validation Loss: 0.000206\n",
      "Validation loss decreased (0.000207 --> 0.000206).  Saving model ...\n",
      "############# Epoch 15  Done   #############\n",
      "\n",
      "############# Epoch 16: Training Start   #############\n",
      "Epoch: 16, Training Loss:  0.04313407465815544\n",
      "############# Epoch 16: Training End     #############\n",
      "############# Epoch 16: Validation Start   #############\n",
      "############# Epoch 16: Validation End     #############\n",
      "Epoch: 16 \tAvgerage Training Loss: 0.000058 \tAverage Validation Loss: 0.000202\n",
      "Validation loss decreased (0.000206 --> 0.000202).  Saving model ...\n",
      "############# Epoch 16  Done   #############\n",
      "\n",
      "############# Epoch 17: Training Start   #############\n",
      "Epoch: 17, Training Loss:  0.03621865063905716\n",
      "############# Epoch 17: Training End     #############\n",
      "############# Epoch 17: Validation Start   #############\n",
      "############# Epoch 17: Validation End     #############\n",
      "Epoch: 17 \tAvgerage Training Loss: 0.000057 \tAverage Validation Loss: 0.000199\n",
      "Validation loss decreased (0.000202 --> 0.000199).  Saving model ...\n",
      "############# Epoch 17  Done   #############\n",
      "\n",
      "############# Epoch 18: Training Start   #############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Training Loss:  0.036217790096998215\n",
      "############# Epoch 18: Training End     #############\n",
      "############# Epoch 18: Validation Start   #############\n",
      "############# Epoch 18: Validation End     #############\n",
      "Epoch: 18 \tAvgerage Training Loss: 0.000056 \tAverage Validation Loss: 0.000197\n",
      "Validation loss decreased (0.000199 --> 0.000197).  Saving model ...\n",
      "############# Epoch 18  Done   #############\n",
      "\n",
      "############# Epoch 19: Training Start   #############\n",
      "Epoch: 19, Training Loss:  0.03264780715107918\n",
      "############# Epoch 19: Training End     #############\n",
      "############# Epoch 19: Validation Start   #############\n",
      "############# Epoch 19: Validation End     #############\n",
      "Epoch: 19 \tAvgerage Training Loss: 0.000055 \tAverage Validation Loss: 0.000195\n",
      "Validation loss decreased (0.000197 --> 0.000195).  Saving model ...\n",
      "############# Epoch 19  Done   #############\n",
      "\n",
      "############# Epoch 20: Training Start   #############\n",
      "Epoch: 20, Training Loss:  0.04001079127192497\n",
      "############# Epoch 20: Training End     #############\n",
      "############# Epoch 20: Validation Start   #############\n",
      "############# Epoch 20: Validation End     #############\n",
      "Epoch: 20 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000190\n",
      "Validation loss decreased (0.000195 --> 0.000190).  Saving model ...\n",
      "############# Epoch 20  Done   #############\n",
      "\n",
      "############# Epoch 21: Training Start   #############\n",
      "Epoch: 21, Training Loss:  0.0344587117433548\n",
      "############# Epoch 21: Training End     #############\n",
      "############# Epoch 21: Validation Start   #############\n",
      "############# Epoch 21: Validation End     #############\n",
      "Epoch: 21 \tAvgerage Training Loss: 0.000053 \tAverage Validation Loss: 0.000188\n",
      "Validation loss decreased (0.000190 --> 0.000188).  Saving model ...\n",
      "############# Epoch 21  Done   #############\n",
      "\n",
      "############# Epoch 22: Training Start   #############\n",
      "Epoch: 22, Training Loss:  0.03629497438669205\n",
      "############# Epoch 22: Training End     #############\n",
      "############# Epoch 22: Validation Start   #############\n",
      "############# Epoch 22: Validation End     #############\n",
      "Epoch: 22 \tAvgerage Training Loss: 0.000052 \tAverage Validation Loss: 0.000188\n",
      "Validation loss decreased (0.000188 --> 0.000188).  Saving model ...\n",
      "############# Epoch 22  Done   #############\n",
      "\n",
      "############# Epoch 23: Training Start   #############\n",
      "Epoch: 23, Training Loss:  0.03151119872927666\n",
      "############# Epoch 23: Training End     #############\n",
      "############# Epoch 23: Validation Start   #############\n",
      "############# Epoch 23: Validation End     #############\n",
      "Epoch: 23 \tAvgerage Training Loss: 0.000051 \tAverage Validation Loss: 0.000183\n",
      "Validation loss decreased (0.000188 --> 0.000183).  Saving model ...\n",
      "############# Epoch 23  Done   #############\n",
      "\n",
      "############# Epoch 24: Training Start   #############\n",
      "Epoch: 24, Training Loss:  0.03171264007687569\n",
      "############# Epoch 24: Training End     #############\n",
      "############# Epoch 24: Validation Start   #############\n",
      "############# Epoch 24: Validation End     #############\n",
      "Epoch: 24 \tAvgerage Training Loss: 0.000051 \tAverage Validation Loss: 0.000181\n",
      "Validation loss decreased (0.000183 --> 0.000181).  Saving model ...\n",
      "############# Epoch 24  Done   #############\n",
      "\n",
      "############# Epoch 25: Training Start   #############\n",
      "Epoch: 25, Training Loss:  0.033261287957429886\n",
      "############# Epoch 25: Training End     #############\n",
      "############# Epoch 25: Validation Start   #############\n",
      "############# Epoch 25: Validation End     #############\n",
      "Epoch: 25 \tAvgerage Training Loss: 0.000050 \tAverage Validation Loss: 0.000176\n",
      "Validation loss decreased (0.000181 --> 0.000176).  Saving model ...\n",
      "############# Epoch 25  Done   #############\n",
      "\n",
      "############# Epoch 26: Training Start   #############\n",
      "Epoch: 26, Training Loss:  0.03574807941913605\n",
      "############# Epoch 26: Training End     #############\n",
      "############# Epoch 26: Validation Start   #############\n",
      "############# Epoch 26: Validation End     #############\n",
      "Epoch: 26 \tAvgerage Training Loss: 0.000049 \tAverage Validation Loss: 0.000176\n",
      "Validation loss decreased (0.000176 --> 0.000176).  Saving model ...\n",
      "############# Epoch 26  Done   #############\n",
      "\n",
      "############# Epoch 27: Training Start   #############\n",
      "Epoch: 27, Training Loss:  0.031374748796224594\n",
      "############# Epoch 27: Training End     #############\n",
      "############# Epoch 27: Validation Start   #############\n",
      "############# Epoch 27: Validation End     #############\n",
      "Epoch: 27 \tAvgerage Training Loss: 0.000048 \tAverage Validation Loss: 0.000174\n",
      "Validation loss decreased (0.000176 --> 0.000174).  Saving model ...\n",
      "############# Epoch 27  Done   #############\n",
      "\n",
      "############# Epoch 28: Training Start   #############\n",
      "Epoch: 28, Training Loss:  0.04048359394073486\n",
      "############# Epoch 28: Training End     #############\n",
      "############# Epoch 28: Validation Start   #############\n",
      "############# Epoch 28: Validation End     #############\n",
      "Epoch: 28 \tAvgerage Training Loss: 0.000047 \tAverage Validation Loss: 0.000173\n",
      "Validation loss decreased (0.000174 --> 0.000173).  Saving model ...\n",
      "############# Epoch 28  Done   #############\n",
      "\n",
      "############# Epoch 29: Training Start   #############\n",
      "Epoch: 29, Training Loss:  0.030061878263950348\n",
      "############# Epoch 29: Training End     #############\n",
      "############# Epoch 29: Validation Start   #############\n",
      "############# Epoch 29: Validation End     #############\n",
      "Epoch: 29 \tAvgerage Training Loss: 0.000047 \tAverage Validation Loss: 0.000169\n",
      "Validation loss decreased (0.000173 --> 0.000169).  Saving model ...\n",
      "############# Epoch 29  Done   #############\n",
      "\n",
      "############# Epoch 30: Training Start   #############\n",
      "Epoch: 30, Training Loss:  0.028088713064789772\n",
      "############# Epoch 30: Training End     #############\n",
      "############# Epoch 30: Validation Start   #############\n",
      "############# Epoch 30: Validation End     #############\n",
      "Epoch: 30 \tAvgerage Training Loss: 0.000046 \tAverage Validation Loss: 0.000170\n",
      "############# Epoch 30  Done   #############\n",
      "\n",
      "############# Epoch 31: Training Start   #############\n",
      "Epoch: 31, Training Loss:  0.03209961950778961\n",
      "############# Epoch 31: Training End     #############\n",
      "############# Epoch 31: Validation Start   #############\n",
      "############# Epoch 31: Validation End     #############\n",
      "Epoch: 31 \tAvgerage Training Loss: 0.000045 \tAverage Validation Loss: 0.000165\n",
      "Validation loss decreased (0.000169 --> 0.000165).  Saving model ...\n",
      "############# Epoch 31  Done   #############\n",
      "\n",
      "############# Epoch 32: Training Start   #############\n",
      "Epoch: 32, Training Loss:  0.02869407832622528\n",
      "############# Epoch 32: Training End     #############\n",
      "############# Epoch 32: Validation Start   #############\n",
      "############# Epoch 32: Validation End     #############\n",
      "Epoch: 32 \tAvgerage Training Loss: 0.000044 \tAverage Validation Loss: 0.000165\n",
      "############# Epoch 32  Done   #############\n",
      "\n",
      "############# Epoch 33: Training Start   #############\n",
      "Epoch: 33, Training Loss:  0.029581062495708466\n",
      "############# Epoch 33: Training End     #############\n",
      "############# Epoch 33: Validation Start   #############\n",
      "############# Epoch 33: Validation End     #############\n",
      "Epoch: 33 \tAvgerage Training Loss: 0.000044 \tAverage Validation Loss: 0.000163\n",
      "Validation loss decreased (0.000165 --> 0.000163).  Saving model ...\n",
      "############# Epoch 33  Done   #############\n",
      "\n",
      "############# Epoch 34: Training Start   #############\n",
      "Epoch: 34, Training Loss:  0.02427099458873272\n",
      "############# Epoch 34: Training End     #############\n",
      "############# Epoch 34: Validation Start   #############\n",
      "############# Epoch 34: Validation End     #############\n",
      "Epoch: 34 \tAvgerage Training Loss: 0.000043 \tAverage Validation Loss: 0.000160\n",
      "Validation loss decreased (0.000163 --> 0.000160).  Saving model ...\n",
      "############# Epoch 34  Done   #############\n",
      "\n",
      "############# Epoch 35: Training Start   #############\n",
      "Epoch: 35, Training Loss:  0.027095520868897438\n",
      "############# Epoch 35: Training End     #############\n",
      "############# Epoch 35: Validation Start   #############\n",
      "############# Epoch 35: Validation End     #############\n",
      "Epoch: 35 \tAvgerage Training Loss: 0.000042 \tAverage Validation Loss: 0.000159\n",
      "Validation loss decreased (0.000160 --> 0.000159).  Saving model ...\n",
      "############# Epoch 35  Done   #############\n",
      "\n",
      "############# Epoch 36: Training Start   #############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Training Loss:  0.025037916377186775\n",
      "############# Epoch 36: Training End     #############\n",
      "############# Epoch 36: Validation Start   #############\n",
      "############# Epoch 36: Validation End     #############\n",
      "Epoch: 36 \tAvgerage Training Loss: 0.000042 \tAverage Validation Loss: 0.000157\n",
      "Validation loss decreased (0.000159 --> 0.000157).  Saving model ...\n",
      "############# Epoch 36  Done   #############\n",
      "\n",
      "############# Epoch 37: Training Start   #############\n",
      "Epoch: 37, Training Loss:  0.02692866139113903\n",
      "############# Epoch 37: Training End     #############\n",
      "############# Epoch 37: Validation Start   #############\n",
      "############# Epoch 37: Validation End     #############\n",
      "Epoch: 37 \tAvgerage Training Loss: 0.000041 \tAverage Validation Loss: 0.000155\n",
      "Validation loss decreased (0.000157 --> 0.000155).  Saving model ...\n",
      "############# Epoch 37  Done   #############\n",
      "\n",
      "############# Epoch 38: Training Start   #############\n",
      "Epoch: 38, Training Loss:  0.02763116918504238\n",
      "############# Epoch 38: Training End     #############\n",
      "############# Epoch 38: Validation Start   #############\n",
      "############# Epoch 38: Validation End     #############\n",
      "Epoch: 38 \tAvgerage Training Loss: 0.000040 \tAverage Validation Loss: 0.000154\n",
      "Validation loss decreased (0.000155 --> 0.000154).  Saving model ...\n",
      "############# Epoch 38  Done   #############\n",
      "\n",
      "############# Epoch 39: Training Start   #############\n",
      "Epoch: 39, Training Loss:  0.027594033628702164\n",
      "############# Epoch 39: Training End     #############\n",
      "############# Epoch 39: Validation Start   #############\n",
      "############# Epoch 39: Validation End     #############\n",
      "Epoch: 39 \tAvgerage Training Loss: 0.000040 \tAverage Validation Loss: 0.000156\n",
      "############# Epoch 39  Done   #############\n",
      "\n",
      "############# Epoch 40: Training Start   #############\n",
      "Epoch: 40, Training Loss:  0.029667628929018974\n",
      "############# Epoch 40: Training End     #############\n",
      "############# Epoch 40: Validation Start   #############\n",
      "############# Epoch 40: Validation End     #############\n",
      "Epoch: 40 \tAvgerage Training Loss: 0.000039 \tAverage Validation Loss: 0.000150\n",
      "Validation loss decreased (0.000154 --> 0.000150).  Saving model ...\n",
      "############# Epoch 40  Done   #############\n",
      "\n",
      "############# Epoch 41: Training Start   #############\n",
      "Epoch: 41, Training Loss:  0.0245230570435524\n",
      "############# Epoch 41: Training End     #############\n",
      "############# Epoch 41: Validation Start   #############\n",
      "############# Epoch 41: Validation End     #############\n",
      "Epoch: 41 \tAvgerage Training Loss: 0.000038 \tAverage Validation Loss: 0.000148\n",
      "Validation loss decreased (0.000150 --> 0.000148).  Saving model ...\n",
      "############# Epoch 41  Done   #############\n",
      "\n",
      "############# Epoch 42: Training Start   #############\n",
      "Epoch: 42, Training Loss:  0.025572270154953003\n",
      "############# Epoch 42: Training End     #############\n",
      "############# Epoch 42: Validation Start   #############\n",
      "############# Epoch 42: Validation End     #############\n",
      "Epoch: 42 \tAvgerage Training Loss: 0.000038 \tAverage Validation Loss: 0.000148\n",
      "Validation loss decreased (0.000148 --> 0.000148).  Saving model ...\n",
      "############# Epoch 42  Done   #############\n",
      "\n",
      "############# Epoch 43: Training Start   #############\n",
      "Epoch: 43, Training Loss:  0.02487405762076378\n",
      "############# Epoch 43: Training End     #############\n",
      "############# Epoch 43: Validation Start   #############\n",
      "############# Epoch 43: Validation End     #############\n",
      "Epoch: 43 \tAvgerage Training Loss: 0.000037 \tAverage Validation Loss: 0.000148\n",
      "############# Epoch 43  Done   #############\n",
      "\n",
      "############# Epoch 44: Training Start   #############\n",
      "Epoch: 44, Training Loss:  0.02300013229250908\n",
      "############# Epoch 44: Training End     #############\n",
      "############# Epoch 44: Validation Start   #############\n",
      "############# Epoch 44: Validation End     #############\n",
      "Epoch: 44 \tAvgerage Training Loss: 0.000036 \tAverage Validation Loss: 0.000145\n",
      "Validation loss decreased (0.000148 --> 0.000145).  Saving model ...\n",
      "############# Epoch 44  Done   #############\n",
      "\n",
      "############# Epoch 45: Training Start   #############\n",
      "Epoch: 45, Training Loss:  0.02666439674794674\n",
      "############# Epoch 45: Training End     #############\n",
      "############# Epoch 45: Validation Start   #############\n",
      "############# Epoch 45: Validation End     #############\n",
      "Epoch: 45 \tAvgerage Training Loss: 0.000036 \tAverage Validation Loss: 0.000144\n",
      "Validation loss decreased (0.000145 --> 0.000144).  Saving model ...\n",
      "############# Epoch 45  Done   #############\n",
      "\n",
      "############# Epoch 46: Training Start   #############\n",
      "Epoch: 46, Training Loss:  0.02120080031454563\n",
      "############# Epoch 46: Training End     #############\n",
      "############# Epoch 46: Validation Start   #############\n",
      "############# Epoch 46: Validation End     #############\n",
      "Epoch: 46 \tAvgerage Training Loss: 0.000035 \tAverage Validation Loss: 0.000142\n",
      "Validation loss decreased (0.000144 --> 0.000142).  Saving model ...\n",
      "############# Epoch 46  Done   #############\n",
      "\n",
      "############# Epoch 47: Training Start   #############\n",
      "Epoch: 47, Training Loss:  0.024520302191376686\n",
      "############# Epoch 47: Training End     #############\n",
      "############# Epoch 47: Validation Start   #############\n",
      "############# Epoch 47: Validation End     #############\n",
      "Epoch: 47 \tAvgerage Training Loss: 0.000035 \tAverage Validation Loss: 0.000140\n",
      "Validation loss decreased (0.000142 --> 0.000140).  Saving model ...\n",
      "############# Epoch 47  Done   #############\n",
      "\n",
      "############# Epoch 48: Training Start   #############\n",
      "Epoch: 48, Training Loss:  0.021534159779548645\n",
      "############# Epoch 48: Training End     #############\n",
      "############# Epoch 48: Validation Start   #############\n",
      "############# Epoch 48: Validation End     #############\n",
      "Epoch: 48 \tAvgerage Training Loss: 0.000034 \tAverage Validation Loss: 0.000139\n",
      "Validation loss decreased (0.000140 --> 0.000139).  Saving model ...\n",
      "############# Epoch 48  Done   #############\n",
      "\n",
      "############# Epoch 49: Training Start   #############\n",
      "Epoch: 49, Training Loss:  0.0229888167232275\n",
      "############# Epoch 49: Training End     #############\n",
      "############# Epoch 49: Validation Start   #############\n",
      "############# Epoch 49: Validation End     #############\n",
      "Epoch: 49 \tAvgerage Training Loss: 0.000034 \tAverage Validation Loss: 0.000141\n",
      "############# Epoch 49  Done   #############\n",
      "\n",
      "############# Epoch 50: Training Start   #############\n",
      "Epoch: 50, Training Loss:  0.02058168686926365\n",
      "############# Epoch 50: Training End     #############\n",
      "############# Epoch 50: Validation Start   #############\n",
      "############# Epoch 50: Validation End     #############\n",
      "Epoch: 50 \tAvgerage Training Loss: 0.000033 \tAverage Validation Loss: 0.000139\n",
      "############# Epoch 50  Done   #############\n",
      "\n",
      "############# Epoch 51: Training Start   #############\n",
      "Epoch: 51, Training Loss:  0.020527254790067673\n",
      "############# Epoch 51: Training End     #############\n",
      "############# Epoch 51: Validation Start   #############\n",
      "############# Epoch 51: Validation End     #############\n",
      "Epoch: 51 \tAvgerage Training Loss: 0.000033 \tAverage Validation Loss: 0.000135\n",
      "Validation loss decreased (0.000139 --> 0.000135).  Saving model ...\n",
      "############# Epoch 51  Done   #############\n",
      "\n",
      "############# Epoch 52: Training Start   #############\n",
      "Epoch: 52, Training Loss:  0.024260545149445534\n"
     ]
    }
   ],
   "source": [
    "#For hyperparameter tuning\n",
    "for lr in [LEARNING_RATE]:\n",
    "    print('\\n')\n",
    "    print(f'##########################################################')\n",
    "    print(f'##########################################################')    \n",
    "    print(f'############### Training for learning rate {lr} START! ###############')\n",
    "    print(f'##########################################################')\n",
    "    print(f'##########################################################')\n",
    "    print('\\n')\n",
    "    optimizer = make_optimizer(model, lr)\n",
    "    train_model(EPOCHS,\n",
    "               train_data_loader,\n",
    "               val_data_loader,\n",
    "               model,\n",
    "               optimizer,\n",
    "               os.path.join(checkpoint_path, f\"curr_ckpt_{lr}\"),\n",
    "               best_model_path,\n",
    "               metric_path,\n",
    "               date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584f93a",
   "metadata": {},
   "source": [
    "### Check & Visualize validation loss\n",
    " - PID was dead at Learning rate 0.004... Evaluation is possible up to 0.003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37642fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['dodgerblue', 'green', 'violet', 'orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb57324",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [\n",
    "                 0.00001, 0.00002, 0.00003, 0.00004, 0.00005,                 \n",
    "                 0.0001, 0.0002, 0.0003, 0.0004, 0.0005,\n",
    "                 0.001, 0.002, 0.003]\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "\n",
    "for index, lr in enumerate(learning_rate):\n",
    "    plt.title(\"Losses per epoch\")\n",
    "    plt.plot(epoch_list, \n",
    "             train_losses_lr[lr], \n",
    "             #color=color[index], \n",
    "             label=f\"{lr} - Train\")    \n",
    "    plt.plot(epoch_list, \n",
    "             val_losses_lr[lr], \n",
    "             '--', \n",
    "             #color=color[index], \n",
    "             label=f\"{lr} - Val\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25378975",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate):\n",
    "    plt.title(\"Gap of loss per epoch\")\n",
    "    plt.plot(epoch_list, \n",
    "             np.array(train_losses_lr[lr]) - np.array(val_losses_lr[lr]), \n",
    "             #color=color[index], \n",
    "             label=lr)    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Gap of loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate):\n",
    "    plt.title(\"Average losses per epoch\")\n",
    "    plt.plot(epoch_list, \n",
    "             avg_train_losses_lr[lr], \n",
    "             #color=color[index], \n",
    "             label=f\"{lr} - Train\")    \n",
    "    plt.plot(epoch_list, \n",
    "             avg_val_losses_lr[lr], \n",
    "             '--', \n",
    "             #color=color[index], \n",
    "             label=f\"{lr} - Val\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c48fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate):\n",
    "    plt.title(\"Gap of Average loss per epoch\")\n",
    "    plt.plot(epoch_list, \n",
    "             np.array(avg_train_losses_lr[lr]) - np.array(avg_val_losses_lr[lr]), \n",
    "             #color=color[index], \n",
    "             label=lr)    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Gap of average loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b36b09",
   "metadata": {},
   "source": [
    "- Let's see losses in detail.\n",
    "- Validation loss is always bigger than tran loss but lr = 1e-0.5. So only check lr = 1e-05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b28b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "\n",
    "plt.title(\"Losses per epoch: lr = 1e-05\")\n",
    "plt.plot(epoch_list,\n",
    "            val_losses_lr[1e-05],\n",
    "            label = \"1e-05 - Validation\")\n",
    "plt.plot(epoch_list,\n",
    "            train_losses_lr[1e-05],\n",
    "            label = \"1e-05 - Train\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate[1:]):\n",
    "    plt.title(\"Losses per epoch: lr = [1e-05, 1e-04, 1e-03]\")\n",
    "    plt.plot(epoch_list, \n",
    "             train_losses_lr[lr], \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Train\")    \n",
    "    plt.plot(epoch_list, \n",
    "             val_losses_lr[lr], \n",
    "             '--', \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Val\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2163f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate[1:]):\n",
    "    plt.title(\"Gap of loss per epoch: lr = [1e-05, 1e-04, 1e-03]\")\n",
    "    plt.plot(epoch_list, \n",
    "             np.array(train_losses_lr[lr]) - np.array(val_losses_lr[lr]), \n",
    "             color=color[index], \n",
    "             label=lr)    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Gap of loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b695eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate[1:]):\n",
    "    plt.title(\"Average losses per epoch: lr = [1e-05, 1e-04, 1e-03]\")\n",
    "    plt.plot(epoch_list,\n",
    "             avg_train_losses_lr[lr], \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Train\")    \n",
    "    plt.plot(epoch_list, \n",
    "             avg_val_losses_lr[lr], \n",
    "             '--', \n",
    "             color=color[index], \n",
    "             label=f\"{lr} - Val\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03533e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.xticks(epoch_list)\n",
    "for index, lr in enumerate(learning_rate[1:]):\n",
    "    plt.title(\"Gap of Average loss per epoch: lr = [1e-05, 1e-04, 1e-03]\")\n",
    "    plt.plot(epoch_list, \n",
    "             np.array(avg_train_losses_lr[lr]) - np.array(avg_val_losses_lr[lr]), \n",
    "             color=color[index], \n",
    "             label=lr)    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Gap of average loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef80344",
   "metadata": {},
   "source": [
    "__Optimal loss:  Learning rate = 1e-05, epoch = 38__\n",
    "- Though it is not the least value, but optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe9f1b",
   "metadata": {},
   "source": [
    "## 5-5. Evaluate model\n",
    " - Test with validation dataset\n",
    " - 1st important index: Precision\n",
    " - 2nd importand index: Recall\n",
    "   - __First, get high & stable <u>Precision</u>, then improve <u>Recall</u>.__\n",
    " - And other indexes: F1 score, confusion matrix\n",
    " \n",
    " - For metrics reference here: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cbd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "\n",
    "def preprocessing(image):\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    \n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        #transformed_image = Image.open(urlopen(image)).convert('RGB') #OR open(image)\n",
    "        transformed_image = Image.open(image).convert('RGB') #OR open(image)\n",
    "    except:\n",
    "        return \"Cannot open image\"\n",
    "    \n",
    "    transformed_image = transform(transformed_image)\n",
    "    \n",
    "    return transformed_image\n",
    "\n",
    "\n",
    "def inference(image, model, device):\n",
    "    preprocessed_image = preprocessing(image)\n",
    "    \n",
    "    if preprocessed_image == \"Cannot open image\":\n",
    "        return \"Cannot open image.\"\n",
    "\n",
    "    #for gpu computation\n",
    "    if device.type == 'cuda':\n",
    "        model.cuda()\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(preprocessed_image.unsqueeze(0))\n",
    "        final_output = torch.sigmoid(output).cpu().detach().numpy().tolist() #1*46 list in a list\n",
    "        \n",
    "        return final_output\n",
    "    #     print(final_output)\n",
    "    #     print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])\n",
    "#         result_pair = zip(train_df.columns[1:].to_list(), final_output[0])\n",
    "#         result_dict = {}\n",
    "#         for label, score in result_pair:\n",
    "#             if score > 0.1: #Set prediction threshold\n",
    "#                 result_dict[label] = score\n",
    "#     return sorted(result_dict.items(), key=(lambda x: x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30280203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "#from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "\n",
    "def get_metrics(models_path, average_param, label_names):\n",
    "    #Load model\n",
    "    load_model = ResNeXt50Class(len(label_names))\n",
    "    load_model = load_model.cuda() #for GPU computation\n",
    "    load_model = nn.DataParallel(load_model) # Distributed\n",
    "    \n",
    "\n",
    "    y_true = valid_dataset.labels\n",
    "    y_evaluations = {}\n",
    "\n",
    "    for file in os.listdir(models_path):\n",
    "        y_pred = []\n",
    "\n",
    "        if file.split('_')[0] == 'curr' and file.split('_')[2] == '1e-05':\n",
    "            model = os.path.join(models_path, file)\n",
    "            # optimizer\n",
    "            val_lr = float(file.split('_')[2])\n",
    "            val_optimizer = make_optimizer(load_model, val_lr)            \n",
    "            print(f\"===========================Start evaluating model {file}, at lr {val_lr}===========================\")\n",
    "            #Load model --> This isn't necessary if you evaluate model right after training.\n",
    "            prediction_model = load_ckp(model,\n",
    "                                                        load_model,\n",
    "                                                        val_optimizer)[0] #load_ckp: [model, optimizer, checkpoint['epoch'], valid_loss_min.item()]\n",
    "            \n",
    "            #Evaluate.\n",
    "            for i in tqdm(range(len(valid_dataset))):\n",
    "                prediction = np.array(inference(valid_dataset.feed_image[i],\n",
    "                                                            prediction_model,\n",
    "                                                            device))[0]\n",
    "                prediction_over_threshold = np.where(prediction > 0.55, 1, 0).tolist()  #Threshold for each class is 0.6 #up to 0.5, Recall=1.0 \n",
    "                y_pred.append(prediction_over_threshold)\n",
    "                if i != 0 and i % 5000 == 0:\n",
    "                    _precision_score = precision_score(y_true[:i+1], y_pred, average=average_param) #average: ['micro', 'macro', 'weighted', 'samples']\n",
    "                    _recall_score = recall_score(y_true[:i+1], y_pred, average=average_param)\n",
    "                    _f1_score = f1_score(y_true[:i+1], y_pred, average=average_param)\n",
    "                    _average_precision_score = average_precision_score(y_true[:i+1], y_pred, average=average_param)\n",
    "                    print(f'current index number: {i}')\n",
    "                    print(f'current Precision: {_precision_score}')\n",
    "                    print(f'current Recall: {_recall_score}')\n",
    "                    print(f'current f1 score: {_f1_score}')\n",
    "                    print(f'current AP: {_average_precision_score}')\n",
    "                    print('\\n')\n",
    "                \n",
    "                \n",
    "            #Append evaluation result into y_preds\n",
    "            _precision_score = precision_score(y_true, y_pred, average=average_param) #average: ['micro', 'macro', 'weighted', 'samples']\n",
    "            _recall_score = recall_score(y_true, y_pred, average=average_param)\n",
    "            _f1_score = f1_score(y_true, y_pred, average=average_param)\n",
    "            _average_precision_score = average_precision_score(y_true, y_pred, average=average_param)            \n",
    "            _classification_report = classification_report(y_true, y_pred, target_names = label_names)\n",
    "            result_dict = {}\n",
    "            result_dict['precision'] = _precision_score\n",
    "            result_dict['recall'] = _recall_score\n",
    "            result_dict['f1score'] = _f1_score\n",
    "            result_dict['AP'] = _average_precision_score\n",
    "            result_dict['classification_report'] = _classification_report\n",
    "            y_evaluations[model.split('/')[-1]] = result_dict\n",
    "            print(f\"Number of finished model: {len(y_evaluations)}\")\n",
    "            print(f\"===========================Done evaluating!===========================\")\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return y_evaluations\n",
    "\n",
    "models_path = '/home/ubuntu/Desktop/Project/autolabeler_classifier/resnext50_model/20211207/'\n",
    "resnext_evaluations_for_20211207_3 = get_metrics(models_path, 'weighted', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6163559",
   "metadata": {},
   "source": [
    "- Compare metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. precision\n",
    "precisions = []\n",
    "\n",
    "for chekpoint, metrics in resnext_evaluations_for_20211207_3.items():\n",
    "    precisions.append(metrics['precision'])\n",
    "\n",
    "max_precision = max(precisions)\n",
    "max_precision_index = precisions.index(max_precision)\n",
    "\n",
    "print(f\"max precision: {max_precision} | Checkpoint: {list(resnext_evaluations_for_20211207_3.keys())[max_precision_index]}\")\n",
    "print(\"===== Check if this max metric value is correct. =====\")\n",
    "sorted(precisions, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. recall\n",
    "recalls = []\n",
    "\n",
    "for chekpoint, metrics in resnext_evaluations_for_20211207_3.items():\n",
    "    recalls.append(metrics['recall'])\n",
    "\n",
    "max_recall = max(recalls)\n",
    "max_recall_index = recalls.index(max_recall)\n",
    "\n",
    "print(f\"max recall: {max_recall} | Checkpoint: {list(resnext_evaluations_for_20211207_3.keys())[max_recall_index]}\")\n",
    "print(\"===== Check if this max metric value is correct. =====\")\n",
    "sorted(recalls, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. f1-score\n",
    "f1_scores = []\n",
    "\n",
    "for chekpoint, metrics in resnext_evaluations_for_20211207_3.items():\n",
    "    f1_scores.append(metrics['f1score'])\n",
    "\n",
    "max_f1score = max(f1_scores)\n",
    "max_f1score_index = f1_scores.index(max_f1score)\n",
    "\n",
    "print(f\"max f1score: {max_f1score} | Checkpoint: {list(resnext_evaluations_for_20211207_3.keys())[max_f1score_index]}\")\n",
    "print(\"===== Check if this max metric value is correct. =====\")\n",
    "sorted(f1_scores, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. AP\n",
    "aps = []\n",
    "\n",
    "for chekpoint, metrics in resnext_evaluations_for_20211207_3.items():\n",
    "    aps.append(metrics['AP'])\n",
    "\n",
    "max_ap = max(aps)\n",
    "max_ap_index = aps.index(max_ap)\n",
    "\n",
    "print(f\"max AP: {max_ap} | Checkpoint: {list(resnext_evaluations_for_20211207_3.keys())[max_ap_index]}\")\n",
    "print(\"===== Check if this max metric value is correct. =====\")\n",
    "sorted(aps, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36cc867",
   "metadata": {},
   "source": [
    "- f1-score, recall, AP is best at __learning rate = 1e-05, epoch=48__.\n",
    "- Precision is best at __learning rate = 1e-05, epoch=45__.\n",
    "\n",
    "- Now, compare best precision, f1-score, AP with precision, f1-score, AP of __learning rate = 1e-05, epoch=45__.\n",
    "- Plus, compare best recall with recall of __learning rate = 1e-05, epoch=48__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e9f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_1e05_47 = resnext_evaluations_for_20211207_3['curr_ckpt_1e-05_47']['precision']\n",
    "print(f\"Precision of curr_ckpt_1e-05_47: {precision_1e05_47}, And (max_precision - precision_1e05_47) = {max_precision - precision_1e05_47} \\n\")\n",
    "print(max_precision, precision_1e05_47, '\\n')\n",
    "\n",
    "f1_1e05_47 = resnext_evaluations_for_20211207_3['curr_ckpt_1e-05_47']['f1score']\n",
    "print(f\"F1-score of curr_ckpt_1e-05_47: {f1_1e05_47}, And (max_f1score - f1_1e05_47) = {max_f1score - f1_1e05_47} \\n\")\n",
    "print(max_f1score, f1_1e05_47, '\\n')\n",
    "\n",
    "AP_1e05_47 = resnext_evaluations_for_20211207_3['curr_ckpt_1e-05_47']['AP']\n",
    "print(f\"AP of curr_ckpt_1e-05_47: {AP_1e05_47}, And (max_ap - AP_1e05_47) = {max_ap - AP_1e05_47} \\n\")\n",
    "print(max_ap, AP_1e05_47, '\\n')\n",
    "\n",
    "\n",
    "recall_1e05_48 = resnext_evaluations_for_20211207_3['curr_ckpt_1e-05_48']['recall']\n",
    "print(f\"Recall of curr_ckpt_1e-05_48: {recall_1e05_48}, And (max_recall - recall_1e05_48) = {max_recall - recall_1e05_48} \\n\")\n",
    "print(max_recall, recall_1e05_48, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5fdf56",
   "metadata": {},
   "source": [
    "- Gap of f1-score, recall, AP is less than gap of precision.\n",
    "- So, let's take highest f1-score, recall, AP and save the metric records into a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162148c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(models_path, 'metric_resnext50_20211207(3).json'), 'w') as f:\n",
    "    json.dump(resnext_evaluations_for_20211207_3, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc51a24",
   "metadata": {},
   "source": [
    "# 6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb4b67",
   "metadata": {},
   "source": [
    "## 6-1. Define preprocessing function for input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ef996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        transformed_image = Image.open(urlopen(image)).convert('RGB') #OR open(image)\n",
    "    except:\n",
    "        return \"Cannot open image\"\n",
    "    \n",
    "    transformed_image = transform(transformed_image)\n",
    "    \n",
    "    return transformed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af390d",
   "metadata": {},
   "source": [
    "## 6-2. Load saved model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b276bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "load_model = ResNeXt50Class()\n",
    "load_model = load_model.cuda() #for GPU computation\n",
    "load_model = nn.DataParallel(load_model) # Distributed\n",
    "best_model_path = os.path.join(checkpoint_path, \"20211126/curr_ckpt_1e-05_16\") #currently best model state.\n",
    "\n",
    "best_optimizer = make_optimizer(\"loaded_model or best_model_path\", \"LEARNING_RATE\") # <-- Parameter shoud be changed!\n",
    "\n",
    "predicton_model = load_ckp(best_model_path,  #Path to the saved checkpoint\n",
    "                        load_model,\n",
    "                        best_optimizer)[0] #load_ckp: [model, optimizer, checkpoint['epoch'], valid_loss_min.item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc654031",
   "metadata": {},
   "source": [
    "## 6-3. Define inference function\n",
    " - Return dictionaries of predicted labels: {label1: score1, label2: score2, ....}\n",
    " - __Labeles which has lower score than threshold will be ignored.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b871f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image, model, device):\n",
    "    preprocessed_image = preprocessing(image)\n",
    "    \n",
    "    if preprocessed_image == \"Cannot open image\":\n",
    "        return \"Cannot open image.\"\n",
    "\n",
    "    #for gpu computation\n",
    "    if device.type == 'cuda':\n",
    "        model.cuda()\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(preprocessed_image)\n",
    "        final_output = torch.sigmoid(output).cpu().detach().numpy().tolist() #1*46 list in a list\n",
    "    #     print(final_output)\n",
    "    #     print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])\n",
    "        result_pair = zip(train_df.columns[1:].to_list(), final_output[0])\n",
    "        result_dict = {}\n",
    "        for label, score in result_pair:\n",
    "            if score > 0.1: #Set prediction threshold\n",
    "                result_dict[label] = score\n",
    "    return sorted(result_dict.items(), key=(lambda x: x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b32e3",
   "metadata": {},
   "source": [
    "- Reference code for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14471026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# for sample_id in [1,2,3,4,6]:\n",
    "#     test_img, test_labels = test_dataset[sample_id]\n",
    "#     test_img_path = os.path.join(img_folder, test_dataset.imgs[sample_id])\n",
    "#     with torch.no_grad():\n",
    "#         raw_pred = model(test_img.unsqueeze(0)).cpu().numpy()[0]\n",
    "#         raw_pred = np.array(raw_pred > 0.5, dtype=float)\n",
    "\n",
    "#     predicted_labels = np.array(dataset_val.classes)[np.argwhere(raw_pred > 0)[:, 0]]\n",
    "#     if not len(predicted_labels):\n",
    "#         predicted_labels = ['no predictions']\n",
    "#     img_labels = np.array(dataset_val.classes)[np.argwhere(test_labels > 0)[:, 0]]\n",
    "#     plt.imshow(Image.open(test_img_path))\n",
    "#     plt.title(\"Predicted labels: {} \\nGT labels: {}\".format(', '.join(predicted_labels), ', '.join(img_labels)))\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a04e3",
   "metadata": {},
   "source": [
    "## 6-4. Demo test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = \"\"\n",
    "\n",
    "inference(test_image, #Input sentence\n",
    "         predicton_model,\n",
    "          device) #CPU or GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-bert-text-classification",
   "language": "python",
   "name": "tf-bert-text-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
