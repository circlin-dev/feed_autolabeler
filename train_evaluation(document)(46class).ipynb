{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torch.nn.parallel import DistributedDataParallel\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "from konlpy.tag import Mecab\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set paths\n",
    " - To load dataset\n",
    " - To save checkpoints & best checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set directories as you want.\n",
    "path = \"/home/ubuntu/Desktop/Project\"\n",
    "dataset_path = os.path.join(path, \"datasets/circlin_feeds_dataset/tokenized_text\")\n",
    "\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "checkpoint_path = os.path.join(path, f\"autolabeler_classifier/bert_model/{date}\")\n",
    "model_path = os.path.join(path, f\"autolabeler_classifier/bert_model/{date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VALID_BATCH_SIZE = 64\n",
    "EPOCHS = 24\n",
    "LEARNING_RATE = 1e-05 #1e-05 = 0.00001\n",
    "PRETRAINED = 'bert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets) #BCEWithLogitsLoss: for Multi-label classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. Check GPU status & Enable distributed processing\n",
    " - __Should be improved!__ \n",
    "   - As is : Using DatParallel\n",
    "   - To be: Use DistributedDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Device check(for GPU computing)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple GPU utilization: This should be improved...\n",
    "\n",
    "# dist.init_process_group(\n",
    "#     backend='nccl',\n",
    "#     init_method='tcp://localhost:9999', #FREEPORT\n",
    "#     world_size=2,\n",
    "#     rank=0,\n",
    "# )\n",
    "\n",
    "# dist.init_process_group(\n",
    "#     backend=\"nccl\",\n",
    "#     init_method='tcp://127.0.0.1:9999',\n",
    "#     rank=0,\n",
    "#     world_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. Optimizer & BERT tokenizer(from pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "def make_optimizer(model, lr):\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params =  model.parameters(), \n",
    "        lr=lr)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. Define target labels(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define taret labels\n",
    "labels = ['간편식', '건강간식', '건강식', '건강음료', '걷기/산책', '격투기', '골프', \n",
    "          '기타식단', '기타운동', '농구', '달리기/조깅', '당구', '등산/등반', '루틴기록', '맨몸', '무술', \n",
    "          '배구', '배드민턴', '보조제', '보충제', '볼링', '수상스포츠', '스키/스노보드', '승마', '신체기록', \n",
    "          '야구', '온라인클래스', '요가', '운동기구', '운동용품', '웨이트', '유산소기록', '의류', '일반간식', \n",
    "          '일반식', '일반음료', '일상생활', '자전거', '종합운동', '줄넘기', '축구/풋살', '탁구', '테니스', \n",
    "          '폴댄스', '필라테스', '홈트'] #46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. Create custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.feed_text = df['text']\n",
    "        self.labels = self.df[labels].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feed_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feed_text = str(self.feed_text[index])\n",
    "        feed_text = \" \".join(feed_text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            feed_text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.FloatTensor(self.labels[index])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get text dataset(tokenized)\n",
    "dataset = os.path.join(dataset_path, \"tokenized_text_dataset(20211125).csv\")\n",
    "whole_df = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>간편식</th>\n",
       "      <th>건강간식</th>\n",
       "      <th>건강식</th>\n",
       "      <th>건강음료</th>\n",
       "      <th>걷기/산책</th>\n",
       "      <th>격투기</th>\n",
       "      <th>골프</th>\n",
       "      <th>기타식단</th>\n",
       "      <th>기타운동</th>\n",
       "      <th>...</th>\n",
       "      <th>일상생활</th>\n",
       "      <th>자전거</th>\n",
       "      <th>종합운동</th>\n",
       "      <th>줄넘기</th>\n",
       "      <th>축구/풋살</th>\n",
       "      <th>탁구</th>\n",
       "      <th>테니스</th>\n",
       "      <th>폴댄스</th>\n",
       "      <th>필라테스</th>\n",
       "      <th>홈트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아침 요거트볼 아침 부터 잠옷 바람 에 민낯 으로 영상 찍 는 용기 는 어플 이 없...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>러닝 하 고 찍 엇 더니 머리 는 산발 에 눈썹 이 다 지워졌 네요 뎨동해오헬로치즈...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>km 요새 등산 못 갔 더니 체력 이 쓰레기 가 된 거 같 은데 숨 맥혀 다리 가 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>아침 베 노프 단호박 무화과 오늘 은 조출 이 라 빨리 꺼내 먹 을 수 있 는 걸루...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>클로이팅 힙 하체 클로이팅 복근 싸이클 분 오늘 왜 케 피곤 하 지 내일 체온 당번...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>아침 무화과 오픈 토스트 으으 추워 이제 아침 에 따뜻 한 게 먹 고 싶 군 무화과...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>어깨 클로이팅 복근 주 챌린지 싸이클 분 전신 거울 옮기 기 귀찮 아서 사진 은 패...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>아침 오 나오</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>등 클로이팅 복근 주 챌린지 싸이클 분 좁아터진 원룸 에서 머리 는 산발 하 고 열...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>아침 요거트볼 주말 내내 누워 만 있 다가 맞이 하 는 월요일 은 너무 피곤 하 다...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  간편식  건강간식  건강식  건강음료  \\\n",
       "0  아침 요거트볼 아침 부터 잠옷 바람 에 민낯 으로 영상 찍 는 용기 는 어플 이 없...    0     1    0     0   \n",
       "1  러닝 하 고 찍 엇 더니 머리 는 산발 에 눈썹 이 다 지워졌 네요 뎨동해오헬로치즈...    0     1    0     0   \n",
       "2  km 요새 등산 못 갔 더니 체력 이 쓰레기 가 된 거 같 은데 숨 맥혀 다리 가 ...    0     0    0     0   \n",
       "3  아침 베 노프 단호박 무화과 오늘 은 조출 이 라 빨리 꺼내 먹 을 수 있 는 걸루...    0     1    0     0   \n",
       "4  클로이팅 힙 하체 클로이팅 복근 싸이클 분 오늘 왜 케 피곤 하 지 내일 체온 당번...    0     0    0     0   \n",
       "5  아침 무화과 오픈 토스트 으으 추워 이제 아침 에 따뜻 한 게 먹 고 싶 군 무화과...    0     1    0     0   \n",
       "6  어깨 클로이팅 복근 주 챌린지 싸이클 분 전신 거울 옮기 기 귀찮 아서 사진 은 패...    0     0    0     0   \n",
       "7                                            아침 오 나오    0     0    1     0   \n",
       "8  등 클로이팅 복근 주 챌린지 싸이클 분 좁아터진 원룸 에서 머리 는 산발 하 고 열...    0     0    0     0   \n",
       "9  아침 요거트볼 주말 내내 누워 만 있 다가 맞이 하 는 월요일 은 너무 피곤 하 다...    0     1    0     0   \n",
       "\n",
       "   걷기/산책  격투기  골프  기타식단  기타운동  ...  일상생활  자전거  종합운동  줄넘기  축구/풋살  탁구  테니스  폴댄스  \\\n",
       "0      0    0   0     0     0  ...     1    0     0    0      0   0    0    0   \n",
       "1      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "2      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "3      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "4      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "5      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "6      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "7      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "8      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "9      0    0   0     0     0  ...     0    0     0    0      0   0    0    0   \n",
       "\n",
       "   필라테스  홈트  \n",
       "0     0   0  \n",
       "1     0   0  \n",
       "2     0   1  \n",
       "3     0   0  \n",
       "4     0   1  \n",
       "5     0   0  \n",
       "6     0   1  \n",
       "7     0   0  \n",
       "8     0   1  \n",
       "9     0   0  \n",
       "\n",
       "[10 rows x 47 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop useless features/columns\n",
    "whole_df.drop(labels=['index', 'seq'], axis=1, inplace=True)\n",
    "\n",
    "whole_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train - validation split\n",
    "train_size = 0.8\n",
    "splitted_train_df = whole_df.copy().sample(frac=train_size, random_state=200).reset_index(drop=True)\n",
    "val_df = whole_df.drop(splitted_train_df.index).reset_index(drop=True)\n",
    "\n",
    "train_dataset = CustomDataset(splitted_train_df, tokenizer, MAX_LEN)\n",
    "valid_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Make feed text classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. Define functions that save checkpoint of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min #valid_loss_min.item()\n",
    "\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. Define BERT model as a class\n",
    " - Use transformer's pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(PRETRAINED, return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, 46) #(768, len(labels))\n",
    "    \n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids, \n",
    "            attention_mask=attn_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BERTClass(\n",
       "    (bert_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (linear): Linear(in_features=768, out_features=46, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model\n",
    "model = BERTClass()\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model) # Distributed\n",
    "#model = nn.parallel.DistributedDataParallel(model, device_ids=[0, 1]) #Distributed DataParallel  ===> Should use this!!!!!!!!!!!!!!!!!\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = make_optimizer(model, LEARNING_RATE) #LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_targets=[]\n",
    "val_outputs=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3. Training\n",
    " - __<u>Add Train Loss!!!!!!!!!!</u>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "train_losses_lr = []\n",
    "avg_train_losses_lr = []\n",
    "val_losses_lr = []\n",
    "avg_val_losses_lr = []\n",
    "epoch_list = [int(x) for x in np.linspace(1, EPOCHS, EPOCHS).tolist()]\n",
    "print(epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epochs, \n",
    "                        training_loader, \n",
    "                        validation_loader, \n",
    "                        model, \n",
    "                        optimizer, \n",
    "                        checkpoint_path, \n",
    "                        best_model_path):\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf\n",
    "    train_loss_epoch = []\n",
    "    avg_train_loss_epoch = []\n",
    "    val_loss_epoch = [] #append to val_loss_list\n",
    "    avg_val_loss_epoch = [] #append to avg_val_list\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):        \n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        print('############# Epoch {}: Training Start   #############'.format(epoch))\n",
    "        for batch_idx, data in enumerate(training_loader):\n",
    "            #print('yyy epoch', batch_idx)\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            if batch_idx%5000==0:\n",
    "                print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print('before loss data in training', loss.item(), train_loss)\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
    "            train_loss.epoch.append(train_loss)            \n",
    "            #print('after loss data in training', loss.item(), train_loss)\n",
    "        print('############# Epoch {}: Training End     #############'.format(epoch))\n",
    "\n",
    "        print('############# Epoch {}: Validation Start   #############'.format(epoch))\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "\n",
    "        model.eval()\n",
    "   \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(validation_loader, 0):\n",
    "                ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "                mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "                token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "                targets = data['targets'].to(device, dtype = torch.float)\n",
    "                outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
    "                val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "                val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "\n",
    "            print('############# Epoch {}: Validation End     #############'.format(epoch))\n",
    "           # calculate average losses\n",
    "#             print('before calculate avg train loss', train_loss)\n",
    "            val_loss_epoch.append(valid_loss) \n",
    "            train_loss = train_loss/len(training_loader)\n",
    "            valid_loss = valid_loss/len(validation_loader)\n",
    "            #Print training/validation statistics\n",
    "            print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                train_loss,\n",
    "                valid_loss\n",
    "            ))\n",
    "            avg_train_loss_epoch.append(train_loss)\n",
    "            avg_val_loss_epoch.append(valid_loss) \n",
    "            \n",
    "\n",
    "            # create checkpoint variable and add important data\n",
    "            checkpoint = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'valid_loss_min': valid_loss,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict()\n",
    "              }\n",
    "\n",
    "            # save checkpoint\n",
    "            #save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "            save_ckp(checkpoint, False,  f\"{checkpoint_path}_{epoch}\", best_model_path)\n",
    "            \n",
    "\n",
    "            ## TODO: save the model if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "                # save checkpoint as best model\n",
    "                #save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "                save_ckp(checkpoint, True,  f\"{checkpoint_path}_{epoch}\", best_model_path)\n",
    "                valid_loss_min = valid_loss\n",
    "\n",
    "        print('############# Epoch {}  Done   #############\\n'.format(epoch))\n",
    "    train_loss_lr.append(train_loss_epoch)\n",
    "    avg_train_losse_lr.append(avg_train_loss_epoch)\n",
    "    val_losses_lr.append(val_loss_epoch)\n",
    "    avg_val_losses_lr.append(avg_val_loss_epoch)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set checkpoint path, best model's path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt_path = os.path.join(checkpoint_path, \"curr_ckpt\")\n",
    "best_model_path = os.path.join(checkpoint_path, \"best_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Epoch 1: Training Start   #############\n",
      "Epoch: 1, Training Loss:  0.1719687283039093\n",
      "############# Epoch 1: Training End     #############\n",
      "############# Epoch 1: Validation Start   #############\n",
      "############# Epoch 1: Validation End     #############\n",
      "Epoch: 1 \tAvgerage Training Loss: 0.000063 \tAverage Validation Loss: 0.000211\n",
      "Validation loss decreased (inf --> 0.000211).  Saving model ...\n",
      "############# Epoch 1  Done   #############\n",
      "\n",
      "############# Epoch 2: Training Start   #############\n",
      "Epoch: 2, Training Loss:  0.11314883828163147\n",
      "############# Epoch 2: Training End     #############\n",
      "############# Epoch 2: Validation Start   #############\n",
      "############# Epoch 2: Validation End     #############\n",
      "Epoch: 2 \tAvgerage Training Loss: 0.000049 \tAverage Validation Loss: 0.000171\n",
      "Validation loss decreased (0.000211 --> 0.000171).  Saving model ...\n",
      "############# Epoch 2  Done   #############\n",
      "\n",
      "############# Epoch 3: Training Start   #############\n",
      "Epoch: 3, Training Loss:  0.08986851572990417\n",
      "############# Epoch 3: Training End     #############\n",
      "############# Epoch 3: Validation Start   #############\n",
      "############# Epoch 3: Validation End     #############\n",
      "Epoch: 3 \tAvgerage Training Loss: 0.000041 \tAverage Validation Loss: 0.000146\n",
      "Validation loss decreased (0.000171 --> 0.000146).  Saving model ...\n",
      "############# Epoch 3  Done   #############\n",
      "\n",
      "############# Epoch 4: Training Start   #############\n",
      "Epoch: 4, Training Loss:  0.07911486178636551\n",
      "############# Epoch 4: Training End     #############\n",
      "############# Epoch 4: Validation Start   #############\n",
      "############# Epoch 4: Validation End     #############\n",
      "Epoch: 4 \tAvgerage Training Loss: 0.000036 \tAverage Validation Loss: 0.000129\n",
      "Validation loss decreased (0.000146 --> 0.000129).  Saving model ...\n",
      "############# Epoch 4  Done   #############\n",
      "\n",
      "############# Epoch 5: Training Start   #############\n",
      "Epoch: 5, Training Loss:  0.07333259284496307\n",
      "############# Epoch 5: Training End     #############\n",
      "############# Epoch 5: Validation Start   #############\n",
      "############# Epoch 5: Validation End     #############\n",
      "Epoch: 5 \tAvgerage Training Loss: 0.000033 \tAverage Validation Loss: 0.000117\n",
      "Validation loss decreased (0.000129 --> 0.000117).  Saving model ...\n",
      "############# Epoch 5  Done   #############\n",
      "\n",
      "############# Epoch 6: Training Start   #############\n",
      "Epoch: 6, Training Loss:  0.06476648896932602\n",
      "############# Epoch 6: Training End     #############\n",
      "############# Epoch 6: Validation Start   #############\n",
      "############# Epoch 6: Validation End     #############\n",
      "Epoch: 6 \tAvgerage Training Loss: 0.000030 \tAverage Validation Loss: 0.000108\n",
      "Validation loss decreased (0.000117 --> 0.000108).  Saving model ...\n",
      "############# Epoch 6  Done   #############\n",
      "\n",
      "############# Epoch 7: Training Start   #############\n",
      "Epoch: 7, Training Loss:  0.06995270401239395\n",
      "############# Epoch 7: Training End     #############\n",
      "############# Epoch 7: Validation Start   #############\n",
      "############# Epoch 7: Validation End     #############\n",
      "Epoch: 7 \tAvgerage Training Loss: 0.000028 \tAverage Validation Loss: 0.000102\n",
      "Validation loss decreased (0.000108 --> 0.000102).  Saving model ...\n",
      "############# Epoch 7  Done   #############\n",
      "\n",
      "############# Epoch 8: Training Start   #############\n",
      "Epoch: 8, Training Loss:  0.0726219043135643\n",
      "############# Epoch 8: Training End     #############\n",
      "############# Epoch 8: Validation Start   #############\n",
      "############# Epoch 8: Validation End     #############\n",
      "Epoch: 8 \tAvgerage Training Loss: 0.000027 \tAverage Validation Loss: 0.000096\n",
      "Validation loss decreased (0.000102 --> 0.000096).  Saving model ...\n",
      "############# Epoch 8  Done   #############\n",
      "\n",
      "############# Epoch 9: Training Start   #############\n",
      "Epoch: 9, Training Loss:  0.05015913397073746\n",
      "############# Epoch 9: Training End     #############\n",
      "############# Epoch 9: Validation Start   #############\n",
      "############# Epoch 9: Validation End     #############\n",
      "Epoch: 9 \tAvgerage Training Loss: 0.000026 \tAverage Validation Loss: 0.000092\n",
      "Validation loss decreased (0.000096 --> 0.000092).  Saving model ...\n",
      "############# Epoch 9  Done   #############\n",
      "\n",
      "############# Epoch 10: Training Start   #############\n",
      "Epoch: 10, Training Loss:  0.06080255284905434\n",
      "############# Epoch 10: Training End     #############\n",
      "############# Epoch 10: Validation Start   #############\n",
      "############# Epoch 10: Validation End     #############\n",
      "Epoch: 10 \tAvgerage Training Loss: 0.000025 \tAverage Validation Loss: 0.000089\n",
      "Validation loss decreased (0.000092 --> 0.000089).  Saving model ...\n",
      "############# Epoch 10  Done   #############\n",
      "\n",
      "############# Epoch 11: Training Start   #############\n",
      "Epoch: 11, Training Loss:  0.04663032293319702\n",
      "############# Epoch 11: Training End     #############\n",
      "############# Epoch 11: Validation Start   #############\n",
      "############# Epoch 11: Validation End     #############\n",
      "Epoch: 11 \tAvgerage Training Loss: 0.000024 \tAverage Validation Loss: 0.000086\n",
      "Validation loss decreased (0.000089 --> 0.000086).  Saving model ...\n",
      "############# Epoch 11  Done   #############\n",
      "\n",
      "############# Epoch 12: Training Start   #############\n",
      "Epoch: 12, Training Loss:  0.05448384955525398\n",
      "############# Epoch 12: Training End     #############\n",
      "############# Epoch 12: Validation Start   #############\n",
      "############# Epoch 12: Validation End     #############\n",
      "Epoch: 12 \tAvgerage Training Loss: 0.000023 \tAverage Validation Loss: 0.000084\n",
      "Validation loss decreased (0.000086 --> 0.000084).  Saving model ...\n",
      "############# Epoch 12  Done   #############\n",
      "\n",
      "############# Epoch 13: Training Start   #############\n",
      "Epoch: 13, Training Loss:  0.052773233503103256\n",
      "############# Epoch 13: Training End     #############\n",
      "############# Epoch 13: Validation Start   #############\n",
      "############# Epoch 13: Validation End     #############\n",
      "Epoch: 13 \tAvgerage Training Loss: 0.000023 \tAverage Validation Loss: 0.000081\n",
      "Validation loss decreased (0.000084 --> 0.000081).  Saving model ...\n",
      "############# Epoch 13  Done   #############\n",
      "\n",
      "############# Epoch 14: Training Start   #############\n",
      "Epoch: 14, Training Loss:  0.057013995945453644\n",
      "############# Epoch 14: Training End     #############\n",
      "############# Epoch 14: Validation Start   #############\n",
      "############# Epoch 14: Validation End     #############\n",
      "Epoch: 14 \tAvgerage Training Loss: 0.000022 \tAverage Validation Loss: 0.000079\n",
      "Validation loss decreased (0.000081 --> 0.000079).  Saving model ...\n",
      "############# Epoch 14  Done   #############\n",
      "\n",
      "############# Epoch 15: Training Start   #############\n",
      "Epoch: 15, Training Loss:  0.04033537954092026\n",
      "############# Epoch 15: Training End     #############\n",
      "############# Epoch 15: Validation Start   #############\n",
      "############# Epoch 15: Validation End     #############\n",
      "Epoch: 15 \tAvgerage Training Loss: 0.000022 \tAverage Validation Loss: 0.000078\n",
      "Validation loss decreased (0.000079 --> 0.000078).  Saving model ...\n",
      "############# Epoch 15  Done   #############\n",
      "\n",
      "############# Epoch 16: Training Start   #############\n",
      "Epoch: 16, Training Loss:  0.05308019742369652\n",
      "############# Epoch 16: Training End     #############\n",
      "############# Epoch 16: Validation Start   #############\n",
      "############# Epoch 16: Validation End     #############\n",
      "Epoch: 16 \tAvgerage Training Loss: 0.000021 \tAverage Validation Loss: 0.000076\n",
      "Validation loss decreased (0.000078 --> 0.000076).  Saving model ...\n",
      "############# Epoch 16  Done   #############\n",
      "\n",
      "############# Epoch 17: Training Start   #############\n",
      "Epoch: 17, Training Loss:  0.05199815332889557\n",
      "############# Epoch 17: Training End     #############\n",
      "############# Epoch 17: Validation Start   #############\n",
      "############# Epoch 17: Validation End     #############\n",
      "Epoch: 17 \tAvgerage Training Loss: 0.000021 \tAverage Validation Loss: 0.000075\n",
      "Validation loss decreased (0.000076 --> 0.000075).  Saving model ...\n",
      "############# Epoch 17  Done   #############\n",
      "\n",
      "############# Epoch 18: Training Start   #############\n",
      "Epoch: 18, Training Loss:  0.04073015972971916\n",
      "############# Epoch 18: Training End     #############\n",
      "############# Epoch 18: Validation Start   #############\n",
      "############# Epoch 18: Validation End     #############\n",
      "Epoch: 18 \tAvgerage Training Loss: 0.000021 \tAverage Validation Loss: 0.000073\n",
      "Validation loss decreased (0.000075 --> 0.000073).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Epoch 18  Done   #############\n",
      "\n",
      "############# Epoch 19: Training Start   #############\n",
      "Epoch: 19, Training Loss:  0.03368673846125603\n",
      "############# Epoch 19: Training End     #############\n",
      "############# Epoch 19: Validation Start   #############\n",
      "############# Epoch 19: Validation End     #############\n",
      "Epoch: 19 \tAvgerage Training Loss: 0.000020 \tAverage Validation Loss: 0.000072\n",
      "Validation loss decreased (0.000073 --> 0.000072).  Saving model ...\n",
      "############# Epoch 19  Done   #############\n",
      "\n",
      "############# Epoch 20: Training Start   #############\n",
      "Epoch: 20, Training Loss:  0.041650284081697464\n",
      "############# Epoch 20: Training End     #############\n",
      "############# Epoch 20: Validation Start   #############\n",
      "############# Epoch 20: Validation End     #############\n",
      "Epoch: 20 \tAvgerage Training Loss: 0.000020 \tAverage Validation Loss: 0.000071\n",
      "Validation loss decreased (0.000072 --> 0.000071).  Saving model ...\n",
      "############# Epoch 20  Done   #############\n",
      "\n",
      "############# Epoch 21: Training Start   #############\n",
      "Epoch: 21, Training Loss:  0.05056803673505783\n",
      "############# Epoch 21: Training End     #############\n",
      "############# Epoch 21: Validation Start   #############\n",
      "############# Epoch 21: Validation End     #############\n",
      "Epoch: 21 \tAvgerage Training Loss: 0.000020 \tAverage Validation Loss: 0.000070\n",
      "Validation loss decreased (0.000071 --> 0.000070).  Saving model ...\n",
      "############# Epoch 21  Done   #############\n",
      "\n",
      "############# Epoch 22: Training Start   #############\n",
      "Epoch: 22, Training Loss:  0.04750741273164749\n",
      "############# Epoch 22: Training End     #############\n",
      "############# Epoch 22: Validation Start   #############\n",
      "############# Epoch 22: Validation End     #############\n",
      "Epoch: 22 \tAvgerage Training Loss: 0.000019 \tAverage Validation Loss: 0.000069\n",
      "Validation loss decreased (0.000070 --> 0.000069).  Saving model ...\n",
      "############# Epoch 22  Done   #############\n",
      "\n",
      "############# Epoch 23: Training Start   #############\n",
      "Epoch: 23, Training Loss:  0.05026383697986603\n",
      "############# Epoch 23: Training End     #############\n",
      "############# Epoch 23: Validation Start   #############\n",
      "############# Epoch 23: Validation End     #############\n",
      "Epoch: 23 \tAvgerage Training Loss: 0.000019 \tAverage Validation Loss: 0.000067\n",
      "Validation loss decreased (0.000069 --> 0.000067).  Saving model ...\n",
      "############# Epoch 23  Done   #############\n",
      "\n",
      "############# Epoch 24: Training Start   #############\n",
      "Epoch: 24, Training Loss:  0.04869416728615761\n",
      "############# Epoch 24: Training End     #############\n",
      "############# Epoch 24: Validation Start   #############\n",
      "############# Epoch 24: Validation End     #############\n",
      "Epoch: 24 \tAvgerage Training Loss: 0.000019 \tAverage Validation Loss: 0.000067\n",
      "Validation loss decreased (0.000067 --> 0.000067).  Saving model ...\n",
      "############# Epoch 24  Done   #############\n",
      "\n",
      "############# Epoch 1: Training Start   #############\n",
      "Epoch: 1, Training Loss:  0.04220670834183693\n",
      "############# Epoch 1: Training End     #############\n",
      "############# Epoch 1: Validation Start   #############\n",
      "############# Epoch 1: Validation End     #############\n",
      "Epoch: 1 \tAvgerage Training Loss: 0.000019 \tAverage Validation Loss: 0.000065\n",
      "Validation loss decreased (inf --> 0.000065).  Saving model ...\n",
      "############# Epoch 1  Done   #############\n",
      "\n",
      "############# Epoch 2: Training Start   #############\n",
      "Epoch: 2, Training Loss:  0.038271691650152206\n",
      "############# Epoch 2: Training End     #############\n",
      "############# Epoch 2: Validation Start   #############\n",
      "############# Epoch 2: Validation End     #############\n",
      "Epoch: 2 \tAvgerage Training Loss: 0.000018 \tAverage Validation Loss: 0.000060\n",
      "Validation loss decreased (0.000065 --> 0.000060).  Saving model ...\n",
      "############# Epoch 2  Done   #############\n",
      "\n",
      "############# Epoch 3: Training Start   #############\n",
      "Epoch: 3, Training Loss:  0.03151161968708038\n",
      "############# Epoch 3: Training End     #############\n",
      "############# Epoch 3: Validation Start   #############\n",
      "############# Epoch 3: Validation End     #############\n",
      "Epoch: 3 \tAvgerage Training Loss: 0.000017 \tAverage Validation Loss: 0.000056\n",
      "Validation loss decreased (0.000060 --> 0.000056).  Saving model ...\n",
      "############# Epoch 3  Done   #############\n",
      "\n",
      "############# Epoch 4: Training Start   #############\n",
      "Epoch: 4, Training Loss:  0.03291771188378334\n",
      "############# Epoch 4: Training End     #############\n",
      "############# Epoch 4: Validation Start   #############\n",
      "############# Epoch 4: Validation End     #############\n",
      "Epoch: 4 \tAvgerage Training Loss: 0.000016 \tAverage Validation Loss: 0.000053\n",
      "Validation loss decreased (0.000056 --> 0.000053).  Saving model ...\n",
      "############# Epoch 4  Done   #############\n",
      "\n",
      "############# Epoch 5: Training Start   #############\n",
      "Epoch: 5, Training Loss:  0.022184934467077255\n",
      "############# Epoch 5: Training End     #############\n",
      "############# Epoch 5: Validation Start   #############\n",
      "############# Epoch 5: Validation End     #############\n",
      "Epoch: 5 \tAvgerage Training Loss: 0.000015 \tAverage Validation Loss: 0.000050\n",
      "Validation loss decreased (0.000053 --> 0.000050).  Saving model ...\n",
      "############# Epoch 5  Done   #############\n",
      "\n",
      "############# Epoch 6: Training Start   #############\n",
      "Epoch: 6, Training Loss:  0.026713330298662186\n",
      "############# Epoch 6: Training End     #############\n",
      "############# Epoch 6: Validation Start   #############\n",
      "############# Epoch 6: Validation End     #############\n",
      "Epoch: 6 \tAvgerage Training Loss: 0.000014 \tAverage Validation Loss: 0.000048\n",
      "Validation loss decreased (0.000050 --> 0.000048).  Saving model ...\n",
      "############# Epoch 6  Done   #############\n",
      "\n",
      "############# Epoch 7: Training Start   #############\n",
      "Epoch: 7, Training Loss:  0.02941872552037239\n",
      "############# Epoch 7: Training End     #############\n",
      "############# Epoch 7: Validation Start   #############\n",
      "############# Epoch 7: Validation End     #############\n",
      "Epoch: 7 \tAvgerage Training Loss: 0.000013 \tAverage Validation Loss: 0.000045\n",
      "Validation loss decreased (0.000048 --> 0.000045).  Saving model ...\n",
      "############# Epoch 7  Done   #############\n",
      "\n",
      "############# Epoch 8: Training Start   #############\n",
      "Epoch: 8, Training Loss:  0.02651119790971279\n",
      "############# Epoch 8: Training End     #############\n",
      "############# Epoch 8: Validation Start   #############\n",
      "############# Epoch 8: Validation End     #############\n",
      "Epoch: 8 \tAvgerage Training Loss: 0.000012 \tAverage Validation Loss: 0.000042\n",
      "Validation loss decreased (0.000045 --> 0.000042).  Saving model ...\n",
      "############# Epoch 8  Done   #############\n",
      "\n",
      "############# Epoch 9: Training Start   #############\n",
      "Epoch: 9, Training Loss:  0.022837139666080475\n",
      "############# Epoch 9: Training End     #############\n",
      "############# Epoch 9: Validation Start   #############\n",
      "############# Epoch 9: Validation End     #############\n",
      "Epoch: 9 \tAvgerage Training Loss: 0.000012 \tAverage Validation Loss: 0.000040\n",
      "Validation loss decreased (0.000042 --> 0.000040).  Saving model ...\n",
      "############# Epoch 9  Done   #############\n",
      "\n",
      "############# Epoch 10: Training Start   #############\n",
      "Epoch: 10, Training Loss:  0.021678052842617035\n",
      "############# Epoch 10: Training End     #############\n",
      "############# Epoch 10: Validation Start   #############\n",
      "############# Epoch 10: Validation End     #############\n",
      "Epoch: 10 \tAvgerage Training Loss: 0.000011 \tAverage Validation Loss: 0.000038\n",
      "Validation loss decreased (0.000040 --> 0.000038).  Saving model ...\n",
      "############# Epoch 10  Done   #############\n",
      "\n",
      "############# Epoch 11: Training Start   #############\n",
      "Epoch: 11, Training Loss:  0.02283441834151745\n",
      "############# Epoch 11: Training End     #############\n",
      "############# Epoch 11: Validation Start   #############\n",
      "############# Epoch 11: Validation End     #############\n",
      "Epoch: 11 \tAvgerage Training Loss: 0.000011 \tAverage Validation Loss: 0.000037\n",
      "Validation loss decreased (0.000038 --> 0.000037).  Saving model ...\n",
      "############# Epoch 11  Done   #############\n",
      "\n",
      "############# Epoch 12: Training Start   #############\n",
      "Epoch: 12, Training Loss:  0.02301059104502201\n",
      "############# Epoch 12: Training End     #############\n",
      "############# Epoch 12: Validation Start   #############\n",
      "############# Epoch 12: Validation End     #############\n",
      "Epoch: 12 \tAvgerage Training Loss: 0.000010 \tAverage Validation Loss: 0.000035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.000037 --> 0.000035).  Saving model ...\n",
      "############# Epoch 12  Done   #############\n",
      "\n",
      "############# Epoch 13: Training Start   #############\n",
      "Epoch: 13, Training Loss:  0.020413963124155998\n",
      "############# Epoch 13: Training End     #############\n",
      "############# Epoch 13: Validation Start   #############\n",
      "############# Epoch 13: Validation End     #############\n",
      "Epoch: 13 \tAvgerage Training Loss: 0.000009 \tAverage Validation Loss: 0.000033\n",
      "Validation loss decreased (0.000035 --> 0.000033).  Saving model ...\n",
      "############# Epoch 13  Done   #############\n",
      "\n",
      "############# Epoch 14: Training Start   #############\n",
      "Epoch: 14, Training Loss:  0.020023785531520844\n",
      "############# Epoch 14: Training End     #############\n",
      "############# Epoch 14: Validation Start   #############\n",
      "############# Epoch 14: Validation End     #############\n",
      "Epoch: 14 \tAvgerage Training Loss: 0.000009 \tAverage Validation Loss: 0.000033\n",
      "Validation loss decreased (0.000033 --> 0.000033).  Saving model ...\n",
      "############# Epoch 14  Done   #############\n",
      "\n",
      "############# Epoch 15: Training Start   #############\n",
      "Epoch: 15, Training Loss:  0.012869036756455898\n",
      "############# Epoch 15: Training End     #############\n",
      "############# Epoch 15: Validation Start   #############\n",
      "############# Epoch 15: Validation End     #############\n",
      "Epoch: 15 \tAvgerage Training Loss: 0.000008 \tAverage Validation Loss: 0.000031\n",
      "Validation loss decreased (0.000033 --> 0.000031).  Saving model ...\n",
      "############# Epoch 15  Done   #############\n",
      "\n",
      "############# Epoch 16: Training Start   #############\n",
      "Epoch: 16, Training Loss:  0.0169910229742527\n",
      "############# Epoch 16: Training End     #############\n",
      "############# Epoch 16: Validation Start   #############\n",
      "############# Epoch 16: Validation End     #############\n",
      "Epoch: 16 \tAvgerage Training Loss: 0.000008 \tAverage Validation Loss: 0.000030\n",
      "Validation loss decreased (0.000031 --> 0.000030).  Saving model ...\n",
      "############# Epoch 16  Done   #############\n",
      "\n",
      "############# Epoch 17: Training Start   #############\n",
      "Epoch: 17, Training Loss:  0.016666479408740997\n",
      "############# Epoch 17: Training End     #############\n",
      "############# Epoch 17: Validation Start   #############\n",
      "############# Epoch 17: Validation End     #############\n",
      "Epoch: 17 \tAvgerage Training Loss: 0.000007 \tAverage Validation Loss: 0.000029\n",
      "Validation loss decreased (0.000030 --> 0.000029).  Saving model ...\n",
      "############# Epoch 17  Done   #############\n",
      "\n",
      "############# Epoch 18: Training Start   #############\n",
      "Epoch: 18, Training Loss:  0.013385666534304619\n",
      "############# Epoch 18: Training End     #############\n",
      "############# Epoch 18: Validation Start   #############\n",
      "############# Epoch 18: Validation End     #############\n",
      "Epoch: 18 \tAvgerage Training Loss: 0.000007 \tAverage Validation Loss: 0.000028\n",
      "Validation loss decreased (0.000029 --> 0.000028).  Saving model ...\n",
      "############# Epoch 18  Done   #############\n",
      "\n",
      "############# Epoch 19: Training Start   #############\n",
      "Epoch: 19, Training Loss:  0.01798650063574314\n",
      "############# Epoch 19: Training End     #############\n",
      "############# Epoch 19: Validation Start   #############\n",
      "############# Epoch 19: Validation End     #############\n",
      "Epoch: 19 \tAvgerage Training Loss: 0.000007 \tAverage Validation Loss: 0.000028\n",
      "Validation loss decreased (0.000028 --> 0.000028).  Saving model ...\n",
      "############# Epoch 19  Done   #############\n",
      "\n",
      "############# Epoch 20: Training Start   #############\n",
      "Epoch: 20, Training Loss:  0.007821529172360897\n",
      "############# Epoch 20: Training End     #############\n",
      "############# Epoch 20: Validation Start   #############\n",
      "############# Epoch 20: Validation End     #############\n",
      "Epoch: 20 \tAvgerage Training Loss: 0.000006 \tAverage Validation Loss: 0.000027\n",
      "Validation loss decreased (0.000028 --> 0.000027).  Saving model ...\n",
      "############# Epoch 20  Done   #############\n",
      "\n",
      "############# Epoch 21: Training Start   #############\n",
      "Epoch: 21, Training Loss:  0.015703311190009117\n",
      "############# Epoch 21: Training End     #############\n",
      "############# Epoch 21: Validation Start   #############\n",
      "############# Epoch 21: Validation End     #############\n",
      "Epoch: 21 \tAvgerage Training Loss: 0.000006 \tAverage Validation Loss: 0.000027\n",
      "Validation loss decreased (0.000027 --> 0.000027).  Saving model ...\n",
      "############# Epoch 21  Done   #############\n",
      "\n",
      "############# Epoch 22: Training Start   #############\n",
      "Epoch: 22, Training Loss:  0.011251536197960377\n",
      "############# Epoch 22: Training End     #############\n",
      "############# Epoch 22: Validation Start   #############\n",
      "############# Epoch 22: Validation End     #############\n",
      "Epoch: 22 \tAvgerage Training Loss: 0.000005 \tAverage Validation Loss: 0.000027\n",
      "Validation loss decreased (0.000027 --> 0.000027).  Saving model ...\n",
      "############# Epoch 22  Done   #############\n",
      "\n",
      "############# Epoch 23: Training Start   #############\n",
      "Epoch: 23, Training Loss:  0.009748386219143867\n",
      "############# Epoch 23: Training End     #############\n",
      "############# Epoch 23: Validation Start   #############\n",
      "############# Epoch 23: Validation End     #############\n",
      "Epoch: 23 \tAvgerage Training Loss: 0.000005 \tAverage Validation Loss: 0.000026\n",
      "Validation loss decreased (0.000027 --> 0.000026).  Saving model ...\n",
      "############# Epoch 23  Done   #############\n",
      "\n",
      "############# Epoch 24: Training Start   #############\n",
      "Epoch: 24, Training Loss:  0.009542460553348064\n",
      "############# Epoch 24: Training End     #############\n",
      "############# Epoch 24: Validation Start   #############\n",
      "############# Epoch 24: Validation End     #############\n",
      "Epoch: 24 \tAvgerage Training Loss: 0.000005 \tAverage Validation Loss: 0.000026\n",
      "############# Epoch 24  Done   #############\n",
      "\n",
      "############# Epoch 1: Training Start   #############\n",
      "Epoch: 1, Training Loss:  0.013191279023885727\n",
      "############# Epoch 1: Training End     #############\n",
      "############# Epoch 1: Validation Start   #############\n",
      "############# Epoch 1: Validation End     #############\n",
      "Epoch: 1 \tAvgerage Training Loss: 0.000016 \tAverage Validation Loss: 0.000055\n",
      "Validation loss decreased (inf --> 0.000055).  Saving model ...\n",
      "############# Epoch 1  Done   #############\n",
      "\n",
      "############# Epoch 2: Training Start   #############\n",
      "Epoch: 2, Training Loss:  0.04192826524376869\n",
      "############# Epoch 2: Training End     #############\n",
      "############# Epoch 2: Validation Start   #############\n",
      "############# Epoch 2: Validation End     #############\n",
      "Epoch: 2 \tAvgerage Training Loss: 0.000016 \tAverage Validation Loss: 0.000052\n",
      "Validation loss decreased (0.000055 --> 0.000052).  Saving model ...\n",
      "############# Epoch 2  Done   #############\n",
      "\n",
      "############# Epoch 3: Training Start   #############\n",
      "Epoch: 3, Training Loss:  0.0360414944589138\n",
      "############# Epoch 3: Training End     #############\n",
      "############# Epoch 3: Validation Start   #############\n",
      "############# Epoch 3: Validation End     #############\n",
      "Epoch: 3 \tAvgerage Training Loss: 0.000015 \tAverage Validation Loss: 0.000051\n",
      "Validation loss decreased (0.000052 --> 0.000051).  Saving model ...\n",
      "############# Epoch 3  Done   #############\n",
      "\n",
      "############# Epoch 4: Training Start   #############\n",
      "Epoch: 4, Training Loss:  0.0488206222653389\n",
      "############# Epoch 4: Training End     #############\n",
      "############# Epoch 4: Validation Start   #############\n",
      "############# Epoch 4: Validation End     #############\n",
      "Epoch: 4 \tAvgerage Training Loss: 0.000014 \tAverage Validation Loss: 0.000049\n",
      "Validation loss decreased (0.000051 --> 0.000049).  Saving model ...\n",
      "############# Epoch 4  Done   #############\n",
      "\n",
      "############# Epoch 5: Training Start   #############\n",
      "Epoch: 5, Training Loss:  0.03752172738313675\n",
      "############# Epoch 5: Training End     #############\n",
      "############# Epoch 5: Validation Start   #############\n",
      "############# Epoch 5: Validation End     #############\n",
      "Epoch: 5 \tAvgerage Training Loss: 0.000014 \tAverage Validation Loss: 0.000047\n",
      "Validation loss decreased (0.000049 --> 0.000047).  Saving model ...\n",
      "############# Epoch 5  Done   #############\n",
      "\n",
      "############# Epoch 6: Training Start   #############\n",
      "Epoch: 6, Training Loss:  0.029313337057828903\n",
      "############# Epoch 6: Training End     #############\n",
      "############# Epoch 6: Validation Start   #############\n",
      "############# Epoch 6: Validation End     #############\n",
      "Epoch: 6 \tAvgerage Training Loss: 0.000013 \tAverage Validation Loss: 0.000046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.000047 --> 0.000046).  Saving model ...\n",
      "############# Epoch 6  Done   #############\n",
      "\n",
      "############# Epoch 7: Training Start   #############\n",
      "Epoch: 7, Training Loss:  0.020675474777817726\n",
      "############# Epoch 7: Training End     #############\n",
      "############# Epoch 7: Validation Start   #############\n",
      "############# Epoch 7: Validation End     #############\n",
      "Epoch: 7 \tAvgerage Training Loss: 0.000013 \tAverage Validation Loss: 0.000045\n",
      "Validation loss decreased (0.000046 --> 0.000045).  Saving model ...\n",
      "############# Epoch 7  Done   #############\n",
      "\n",
      "############# Epoch 8: Training Start   #############\n",
      "Epoch: 8, Training Loss:  0.026102714240550995\n",
      "############# Epoch 8: Training End     #############\n",
      "############# Epoch 8: Validation Start   #############\n",
      "############# Epoch 8: Validation End     #############\n",
      "Epoch: 8 \tAvgerage Training Loss: 0.000012 \tAverage Validation Loss: 0.000043\n",
      "Validation loss decreased (0.000045 --> 0.000043).  Saving model ...\n",
      "############# Epoch 8  Done   #############\n",
      "\n",
      "############# Epoch 9: Training Start   #############\n",
      "Epoch: 9, Training Loss:  0.01793464832007885\n",
      "############# Epoch 9: Training End     #############\n",
      "############# Epoch 9: Validation Start   #############\n",
      "############# Epoch 9: Validation End     #############\n",
      "Epoch: 9 \tAvgerage Training Loss: 0.000012 \tAverage Validation Loss: 0.000041\n",
      "Validation loss decreased (0.000043 --> 0.000041).  Saving model ...\n",
      "############# Epoch 9  Done   #############\n",
      "\n",
      "############# Epoch 10: Training Start   #############\n",
      "Epoch: 10, Training Loss:  0.014842882752418518\n",
      "############# Epoch 10: Training End     #############\n",
      "############# Epoch 10: Validation Start   #############\n",
      "############# Epoch 10: Validation End     #############\n",
      "Epoch: 10 \tAvgerage Training Loss: 0.000011 \tAverage Validation Loss: 0.000040\n",
      "Validation loss decreased (0.000041 --> 0.000040).  Saving model ...\n",
      "############# Epoch 10  Done   #############\n",
      "\n",
      "############# Epoch 11: Training Start   #############\n",
      "Epoch: 11, Training Loss:  0.01729002594947815\n",
      "############# Epoch 11: Training End     #############\n",
      "############# Epoch 11: Validation Start   #############\n",
      "############# Epoch 11: Validation End     #############\n",
      "Epoch: 11 \tAvgerage Training Loss: 0.000011 \tAverage Validation Loss: 0.000039\n",
      "Validation loss decreased (0.000040 --> 0.000039).  Saving model ...\n",
      "############# Epoch 11  Done   #############\n",
      "\n",
      "############# Epoch 12: Training Start   #############\n",
      "Epoch: 12, Training Loss:  0.016665127128362656\n",
      "############# Epoch 12: Training End     #############\n",
      "############# Epoch 12: Validation Start   #############\n",
      "############# Epoch 12: Validation End     #############\n",
      "Epoch: 12 \tAvgerage Training Loss: 0.000010 \tAverage Validation Loss: 0.000039\n",
      "############# Epoch 12  Done   #############\n",
      "\n",
      "############# Epoch 13: Training Start   #############\n",
      "Epoch: 13, Training Loss:  0.024710705503821373\n",
      "############# Epoch 13: Training End     #############\n",
      "############# Epoch 13: Validation Start   #############\n",
      "############# Epoch 13: Validation End     #############\n",
      "Epoch: 13 \tAvgerage Training Loss: 0.000010 \tAverage Validation Loss: 0.000038\n",
      "Validation loss decreased (0.000039 --> 0.000038).  Saving model ...\n",
      "############# Epoch 13  Done   #############\n",
      "\n",
      "############# Epoch 14: Training Start   #############\n",
      "Epoch: 14, Training Loss:  0.025425391271710396\n",
      "############# Epoch 14: Training End     #############\n",
      "############# Epoch 14: Validation Start   #############\n",
      "############# Epoch 14: Validation End     #############\n",
      "Epoch: 14 \tAvgerage Training Loss: 0.000010 \tAverage Validation Loss: 0.000037\n",
      "Validation loss decreased (0.000038 --> 0.000037).  Saving model ...\n",
      "############# Epoch 14  Done   #############\n",
      "\n",
      "############# Epoch 15: Training Start   #############\n",
      "Epoch: 15, Training Loss:  0.01799893192946911\n",
      "############# Epoch 15: Training End     #############\n",
      "############# Epoch 15: Validation Start   #############\n",
      "############# Epoch 15: Validation End     #############\n",
      "Epoch: 15 \tAvgerage Training Loss: 0.000010 \tAverage Validation Loss: 0.000038\n",
      "############# Epoch 15  Done   #############\n",
      "\n",
      "############# Epoch 16: Training Start   #############\n",
      "Epoch: 16, Training Loss:  0.012706629931926727\n",
      "############# Epoch 16: Training End     #############\n",
      "############# Epoch 16: Validation Start   #############\n",
      "############# Epoch 16: Validation End     #############\n",
      "Epoch: 16 \tAvgerage Training Loss: 0.000009 \tAverage Validation Loss: 0.000037\n",
      "Validation loss decreased (0.000037 --> 0.000037).  Saving model ...\n",
      "############# Epoch 16  Done   #############\n",
      "\n",
      "############# Epoch 17: Training Start   #############\n",
      "Epoch: 17, Training Loss:  0.01260745245963335\n",
      "############# Epoch 17: Training End     #############\n",
      "############# Epoch 17: Validation Start   #############\n",
      "############# Epoch 17: Validation End     #############\n",
      "Epoch: 17 \tAvgerage Training Loss: 0.000009 \tAverage Validation Loss: 0.000035\n",
      "Validation loss decreased (0.000037 --> 0.000035).  Saving model ...\n",
      "############# Epoch 17  Done   #############\n",
      "\n",
      "############# Epoch 18: Training Start   #############\n",
      "Epoch: 18, Training Loss:  0.010745354928076267\n",
      "############# Epoch 18: Training End     #############\n",
      "############# Epoch 18: Validation Start   #############\n",
      "############# Epoch 18: Validation End     #############\n",
      "Epoch: 18 \tAvgerage Training Loss: 0.000009 \tAverage Validation Loss: 0.000035\n",
      "Validation loss decreased (0.000035 --> 0.000035).  Saving model ...\n",
      "############# Epoch 18  Done   #############\n",
      "\n",
      "############# Epoch 19: Training Start   #############\n",
      "Epoch: 19, Training Loss:  0.018398432061076164\n",
      "############# Epoch 19: Training End     #############\n",
      "############# Epoch 19: Validation Start   #############\n",
      "############# Epoch 19: Validation End     #############\n",
      "Epoch: 19 \tAvgerage Training Loss: 0.000009 \tAverage Validation Loss: 0.000035\n",
      "Validation loss decreased (0.000035 --> 0.000035).  Saving model ...\n",
      "############# Epoch 19  Done   #############\n",
      "\n",
      "############# Epoch 20: Training Start   #############\n",
      "Epoch: 20, Training Loss:  0.01808733306825161\n",
      "############# Epoch 20: Training End     #############\n",
      "############# Epoch 20: Validation Start   #############\n",
      "############# Epoch 20: Validation End     #############\n",
      "Epoch: 20 \tAvgerage Training Loss: 0.000008 \tAverage Validation Loss: 0.000034\n",
      "Validation loss decreased (0.000035 --> 0.000034).  Saving model ...\n",
      "############# Epoch 20  Done   #############\n",
      "\n",
      "############# Epoch 21: Training Start   #############\n",
      "Epoch: 21, Training Loss:  0.016311468556523323\n",
      "############# Epoch 21: Training End     #############\n",
      "############# Epoch 21: Validation Start   #############\n",
      "############# Epoch 21: Validation End     #############\n",
      "Epoch: 21 \tAvgerage Training Loss: 0.000008 \tAverage Validation Loss: 0.000035\n",
      "############# Epoch 21  Done   #############\n",
      "\n",
      "############# Epoch 22: Training Start   #############\n",
      "Epoch: 22, Training Loss:  0.00983821414411068\n",
      "############# Epoch 22: Training End     #############\n",
      "############# Epoch 22: Validation Start   #############\n",
      "############# Epoch 22: Validation End     #############\n",
      "Epoch: 22 \tAvgerage Training Loss: 0.000008 \tAverage Validation Loss: 0.000034\n",
      "############# Epoch 22  Done   #############\n",
      "\n",
      "############# Epoch 23: Training Start   #############\n",
      "Epoch: 23, Training Loss:  0.01331454236060381\n",
      "############# Epoch 23: Training End     #############\n",
      "############# Epoch 23: Validation Start   #############\n",
      "############# Epoch 23: Validation End     #############\n",
      "Epoch: 23 \tAvgerage Training Loss: 0.000008 \tAverage Validation Loss: 0.000035\n",
      "############# Epoch 23  Done   #############\n",
      "\n",
      "############# Epoch 24: Training Start   #############\n",
      "Epoch: 24, Training Loss:  0.017506426200270653\n",
      "############# Epoch 24: Training End     #############\n",
      "############# Epoch 24: Validation Start   #############\n",
      "############# Epoch 24: Validation End     #############\n",
      "Epoch: 24 \tAvgerage Training Loss: 0.000008 \tAverage Validation Loss: 0.000033\n",
      "Validation loss decreased (0.000034 --> 0.000033).  Saving model ...\n",
      "############# Epoch 24  Done   #############\n",
      "\n",
      "############# Epoch 1: Training Start   #############\n",
      "Epoch: 1, Training Loss:  0.018399417400360107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Epoch 1: Training End     #############\n",
      "############# Epoch 1: Validation Start   #############\n",
      "############# Epoch 1: Validation End     #############\n",
      "Epoch: 1 \tAvgerage Training Loss: 0.000055 \tAverage Validation Loss: 0.000261\n",
      "Validation loss decreased (inf --> 0.000261).  Saving model ...\n",
      "############# Epoch 1  Done   #############\n",
      "\n",
      "############# Epoch 2: Training Start   #############\n",
      "Epoch: 2, Training Loss:  0.12722301483154297\n",
      "############# Epoch 2: Training End     #############\n",
      "############# Epoch 2: Validation Start   #############\n",
      "############# Epoch 2: Validation End     #############\n",
      "Epoch: 2 \tAvgerage Training Loss: 0.000055 \tAverage Validation Loss: 0.000258\n",
      "Validation loss decreased (0.000261 --> 0.000258).  Saving model ...\n",
      "############# Epoch 2  Done   #############\n",
      "\n",
      "############# Epoch 3: Training Start   #############\n",
      "Epoch: 3, Training Loss:  0.1108078584074974\n",
      "############# Epoch 3: Training End     #############\n",
      "############# Epoch 3: Validation Start   #############\n",
      "############# Epoch 3: Validation End     #############\n",
      "Epoch: 3 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000255\n",
      "Validation loss decreased (0.000258 --> 0.000255).  Saving model ...\n",
      "############# Epoch 3  Done   #############\n",
      "\n",
      "############# Epoch 4: Training Start   #############\n",
      "Epoch: 4, Training Loss:  0.1232999935746193\n",
      "############# Epoch 4: Training End     #############\n",
      "############# Epoch 4: Validation Start   #############\n",
      "############# Epoch 4: Validation End     #############\n",
      "Epoch: 4 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000249\n",
      "Validation loss decreased (0.000255 --> 0.000249).  Saving model ...\n",
      "############# Epoch 4  Done   #############\n",
      "\n",
      "############# Epoch 5: Training Start   #############\n",
      "Epoch: 5, Training Loss:  0.11876081675291061\n",
      "############# Epoch 5: Training End     #############\n",
      "############# Epoch 5: Validation Start   #############\n",
      "############# Epoch 5: Validation End     #############\n",
      "Epoch: 5 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000274\n",
      "############# Epoch 5  Done   #############\n",
      "\n",
      "############# Epoch 6: Training Start   #############\n",
      "Epoch: 6, Training Loss:  0.11480431258678436\n",
      "############# Epoch 6: Training End     #############\n",
      "############# Epoch 6: Validation Start   #############\n",
      "############# Epoch 6: Validation End     #############\n",
      "Epoch: 6 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000275\n",
      "############# Epoch 6  Done   #############\n",
      "\n",
      "############# Epoch 7: Training Start   #############\n",
      "Epoch: 7, Training Loss:  0.11935414373874664\n",
      "############# Epoch 7: Training End     #############\n",
      "############# Epoch 7: Validation Start   #############\n",
      "############# Epoch 7: Validation End     #############\n",
      "Epoch: 7 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000287\n",
      "############# Epoch 7  Done   #############\n",
      "\n",
      "############# Epoch 8: Training Start   #############\n",
      "Epoch: 8, Training Loss:  0.10758079588413239\n",
      "############# Epoch 8: Training End     #############\n",
      "############# Epoch 8: Validation Start   #############\n",
      "############# Epoch 8: Validation End     #############\n",
      "Epoch: 8 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000288\n",
      "############# Epoch 8  Done   #############\n",
      "\n",
      "############# Epoch 9: Training Start   #############\n",
      "Epoch: 9, Training Loss:  0.11448364704847336\n",
      "############# Epoch 9: Training End     #############\n",
      "############# Epoch 9: Validation Start   #############\n",
      "############# Epoch 9: Validation End     #############\n",
      "Epoch: 9 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000269\n",
      "############# Epoch 9  Done   #############\n",
      "\n",
      "############# Epoch 10: Training Start   #############\n",
      "Epoch: 10, Training Loss:  0.11908787488937378\n",
      "############# Epoch 10: Training End     #############\n",
      "############# Epoch 10: Validation Start   #############\n",
      "############# Epoch 10: Validation End     #############\n",
      "Epoch: 10 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000315\n",
      "############# Epoch 10  Done   #############\n",
      "\n",
      "############# Epoch 11: Training Start   #############\n",
      "Epoch: 11, Training Loss:  0.11110609769821167\n",
      "############# Epoch 11: Training End     #############\n",
      "############# Epoch 11: Validation Start   #############\n",
      "############# Epoch 11: Validation End     #############\n",
      "Epoch: 11 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000294\n",
      "############# Epoch 11  Done   #############\n",
      "\n",
      "############# Epoch 12: Training Start   #############\n",
      "Epoch: 12, Training Loss:  0.11943905800580978\n",
      "############# Epoch 12: Training End     #############\n",
      "############# Epoch 12: Validation Start   #############\n",
      "############# Epoch 12: Validation End     #############\n",
      "Epoch: 12 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000297\n",
      "############# Epoch 12  Done   #############\n",
      "\n",
      "############# Epoch 13: Training Start   #############\n",
      "Epoch: 13, Training Loss:  0.11583767831325531\n",
      "############# Epoch 13: Training End     #############\n",
      "############# Epoch 13: Validation Start   #############\n",
      "############# Epoch 13: Validation End     #############\n",
      "Epoch: 13 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000299\n",
      "############# Epoch 13  Done   #############\n",
      "\n",
      "############# Epoch 14: Training Start   #############\n",
      "Epoch: 14, Training Loss:  0.1127849817276001\n",
      "############# Epoch 14: Training End     #############\n",
      "############# Epoch 14: Validation Start   #############\n",
      "############# Epoch 14: Validation End     #############\n",
      "Epoch: 14 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000305\n",
      "############# Epoch 14  Done   #############\n",
      "\n",
      "############# Epoch 15: Training Start   #############\n",
      "Epoch: 15, Training Loss:  0.11875522881746292\n",
      "############# Epoch 15: Training End     #############\n",
      "############# Epoch 15: Validation Start   #############\n",
      "############# Epoch 15: Validation End     #############\n",
      "Epoch: 15 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000288\n",
      "############# Epoch 15  Done   #############\n",
      "\n",
      "############# Epoch 16: Training Start   #############\n",
      "Epoch: 16, Training Loss:  0.12706315517425537\n",
      "############# Epoch 16: Training End     #############\n",
      "############# Epoch 16: Validation Start   #############\n",
      "############# Epoch 16: Validation End     #############\n",
      "Epoch: 16 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000314\n",
      "############# Epoch 16  Done   #############\n",
      "\n",
      "############# Epoch 17: Training Start   #############\n",
      "Epoch: 17, Training Loss:  0.10693303495645523\n",
      "############# Epoch 17: Training End     #############\n",
      "############# Epoch 17: Validation Start   #############\n",
      "############# Epoch 17: Validation End     #############\n",
      "Epoch: 17 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000298\n",
      "############# Epoch 17  Done   #############\n",
      "\n",
      "############# Epoch 18: Training Start   #############\n",
      "Epoch: 18, Training Loss:  0.1309308409690857\n",
      "############# Epoch 18: Training End     #############\n",
      "############# Epoch 18: Validation Start   #############\n",
      "############# Epoch 18: Validation End     #############\n",
      "Epoch: 18 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000308\n",
      "############# Epoch 18  Done   #############\n",
      "\n",
      "############# Epoch 19: Training Start   #############\n",
      "Epoch: 19, Training Loss:  0.10758703202009201\n",
      "############# Epoch 19: Training End     #############\n",
      "############# Epoch 19: Validation Start   #############\n",
      "############# Epoch 19: Validation End     #############\n",
      "Epoch: 19 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000291\n",
      "############# Epoch 19  Done   #############\n",
      "\n",
      "############# Epoch 20: Training Start   #############\n",
      "Epoch: 20, Training Loss:  0.1170794665813446\n",
      "############# Epoch 20: Training End     #############\n",
      "############# Epoch 20: Validation Start   #############\n",
      "############# Epoch 20: Validation End     #############\n",
      "Epoch: 20 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000306\n",
      "############# Epoch 20  Done   #############\n",
      "\n",
      "############# Epoch 21: Training Start   #############\n",
      "Epoch: 21, Training Loss:  0.11507594585418701\n",
      "############# Epoch 21: Training End     #############\n",
      "############# Epoch 21: Validation Start   #############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Epoch 21: Validation End     #############\n",
      "Epoch: 21 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000307\n",
      "############# Epoch 21  Done   #############\n",
      "\n",
      "############# Epoch 22: Training Start   #############\n",
      "Epoch: 22, Training Loss:  0.12628987431526184\n",
      "############# Epoch 22: Training End     #############\n",
      "############# Epoch 22: Validation Start   #############\n",
      "############# Epoch 22: Validation End     #############\n",
      "Epoch: 22 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000305\n",
      "############# Epoch 22  Done   #############\n",
      "\n",
      "############# Epoch 23: Training Start   #############\n",
      "Epoch: 23, Training Loss:  0.11021077632904053\n",
      "############# Epoch 23: Training End     #############\n",
      "############# Epoch 23: Validation Start   #############\n",
      "############# Epoch 23: Validation End     #############\n",
      "Epoch: 23 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000307\n",
      "############# Epoch 23  Done   #############\n",
      "\n",
      "############# Epoch 24: Training Start   #############\n",
      "Epoch: 24, Training Loss:  0.10383162647485733\n",
      "############# Epoch 24: Training End     #############\n",
      "############# Epoch 24: Validation Start   #############\n",
      "############# Epoch 24: Validation End     #############\n",
      "Epoch: 24 \tAvgerage Training Loss: 0.000054 \tAverage Validation Loss: 0.000286\n",
      "############# Epoch 24  Done   #############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For hyperparameter tuning\n",
    "for lr in learning_rate:\n",
    "    print('\\n')    \n",
    "    print(f'##########################################################')\n",
    "    print(f'##########################################################')    \n",
    "    print(f'############### Training for learning rate {lr} START! ###############')\n",
    "    print(f'##########################################################')\n",
    "    print(f'##########################################################')\n",
    "    print('\\n')    \n",
    "    optimizer = make_optimizer(model, lr)\n",
    "    train_model(EPOCHS,\n",
    "               train_data_loader,\n",
    "               val_data_loader,\n",
    "               model,\n",
    "               optimizer,\n",
    "               os.path.join(checkpoint_path, f\"curr_ckpt_{lr}\"),\n",
    "               best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check & Visualize validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5753606622328947e-05"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_val_losses_lr[1][22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimums of average validation loss per learning rate: [6.687350265365486e-05, 2.5753606622328947e-05, 3.2515117364257496e-05, 0.00024910762663187826]\n",
      "Minimum average validation loss: 2.5753606622328947e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.00021095401111869338,\n",
       "  0.00017081876145262295,\n",
       "  0.00014551220643238024,\n",
       "  0.0001288583847991709,\n",
       "  0.00011657902353085345,\n",
       "  0.00010803703453433223,\n",
       "  0.00010155328765145094,\n",
       "  9.64727614210394e-05,\n",
       "  9.233400622694805e-05,\n",
       "  8.891226760722222e-05,\n",
       "  8.604101035515857e-05,\n",
       "  8.378095150247963e-05,\n",
       "  8.136921796205316e-05,\n",
       "  7.948879475662432e-05,\n",
       "  7.754940305347112e-05,\n",
       "  7.61060551798952e-05,\n",
       "  7.473423755109852e-05,\n",
       "  7.303982035910427e-05,\n",
       "  7.189490515938076e-05,\n",
       "  7.116192662024908e-05,\n",
       "  6.959619972505826e-05,\n",
       "  6.872589737901167e-05,\n",
       "  6.749815628593384e-05,\n",
       "  6.687350265365486e-05],\n",
       " [6.491304219899783e-05,\n",
       "  6.0378319994005066e-05,\n",
       "  5.635849220987072e-05,\n",
       "  5.303021521173115e-05,\n",
       "  4.966768584861457e-05,\n",
       "  4.767703972028673e-05,\n",
       "  4.493673354668996e-05,\n",
       "  4.2481668650568686e-05,\n",
       "  3.970536297095055e-05,\n",
       "  3.845940720175557e-05,\n",
       "  3.701267956875942e-05,\n",
       "  3.4799138234323155e-05,\n",
       "  3.344166658326048e-05,\n",
       "  3.2550785680454065e-05,\n",
       "  3.1173309790832175e-05,\n",
       "  3.0292733290076833e-05,\n",
       "  2.9110639427876717e-05,\n",
       "  2.8283118327812846e-05,\n",
       "  2.761216066702731e-05,\n",
       "  2.710270546912201e-05,\n",
       "  2.677292698802315e-05,\n",
       "  2.6506086418639785e-05,\n",
       "  2.5753606622328947e-05,\n",
       "  2.590699303899071e-05],\n",
       " [5.5320127160201536e-05,\n",
       "  5.246650961611834e-05,\n",
       "  5.0604578088613395e-05,\n",
       "  4.91673359340388e-05,\n",
       "  4.6914855812055525e-05,\n",
       "  4.55781200463917e-05,\n",
       "  4.4810016865917435e-05,\n",
       "  4.304321095494033e-05,\n",
       "  4.0563254559254695e-05,\n",
       "  4.01057471161167e-05,\n",
       "  3.905479144949046e-05,\n",
       "  3.905554252092922e-05,\n",
       "  3.7989054709621414e-05,\n",
       "  3.749250962740401e-05,\n",
       "  3.810212557760476e-05,\n",
       "  3.657843703668225e-05,\n",
       "  3.517849154963698e-05,\n",
       "  3.478810687664873e-05,\n",
       "  3.4650746148706604e-05,\n",
       "  3.372075321199398e-05,\n",
       "  3.48508320334807e-05,\n",
       "  3.43250438389184e-05,\n",
       "  3.475186520531663e-05,\n",
       "  3.2515117364257496e-05],\n",
       " [0.000261300309959398,\n",
       "  0.00025786613032070674,\n",
       "  0.0002554973126128519,\n",
       "  0.00024910762663187826,\n",
       "  0.0002743444611006586,\n",
       "  0.00027493787020550217,\n",
       "  0.00028748471434831765,\n",
       "  0.0002875180292130605,\n",
       "  0.0002690491210412441,\n",
       "  0.00031539468363904233,\n",
       "  0.000294252380096004,\n",
       "  0.0002972820089713566,\n",
       "  0.0002990945888924021,\n",
       "  0.00030504754167575045,\n",
       "  0.00028782281089759047,\n",
       "  0.00031444161987069416,\n",
       "  0.0002976996486518185,\n",
       "  0.000308259426521144,\n",
       "  0.00029091752245843504,\n",
       "  0.0003058444221558204,\n",
       "  0.00030704461205384665,\n",
       "  0.00030508059879998513,\n",
       "  0.00030675232555180495,\n",
       "  0.0002856216982455801]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Minimums of average validation loss per learning rate: {[min(x) for x in avg_val_losses_lr]}\")\n",
    "print(f\"Minimum average validation loss: {min([min(x) for x in avg_val_losses_lr])}\")\n",
    "avg_val_losses_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013752425936323658"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses_lr[1][22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimums of average validation loss per learning rate: [0.035710450417051696, 0.013752425936323658, 0.017363072672513503, 0.133023472621423]\n",
      "Minimum of minums: 0.013752425936323658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.11264944193738227,\n",
       "  0.09121721861570066,\n",
       "  0.07770351823489105,\n",
       "  0.06881037748275727,\n",
       "  0.062253198565475745,\n",
       "  0.057691776441333414,\n",
       "  0.054229455605874805,\n",
       "  0.05151645459883504,\n",
       "  0.04930635932519026,\n",
       "  0.04747915090225667,\n",
       "  0.04594589952965467,\n",
       "  0.04473902810232412,\n",
       "  0.04345116239173639,\n",
       "  0.04244701640003738,\n",
       "  0.04141138123055357,\n",
       "  0.04064063346606404,\n",
       "  0.039908082852286614,\n",
       "  0.03900326407176168,\n",
       "  0.03839187935510933,\n",
       "  0.03800046881521301,\n",
       "  0.03716437065318111,\n",
       "  0.03669962920039223,\n",
       "  0.03604401545668867,\n",
       "  0.035710450417051696],\n",
       " [0.03466356453426484,\n",
       "  0.032242022876798705,\n",
       "  0.030095434840070965,\n",
       "  0.028318134923064436,\n",
       "  0.02652254424316018,\n",
       "  0.025459539210633115,\n",
       "  0.02399621571393244,\n",
       "  0.022685211059403677,\n",
       "  0.021202663826487594,\n",
       "  0.020537323445737474,\n",
       "  0.01976477088971753,\n",
       "  0.018582739817128564,\n",
       "  0.017857849955461098,\n",
       "  0.017382119553362472,\n",
       "  0.016646547428304383,\n",
       "  0.01617631957690103,\n",
       "  0.015545081454486166,\n",
       "  0.01510318518705206,\n",
       "  0.014744893796192583,\n",
       "  0.014472844720511153,\n",
       "  0.014296743011604362,\n",
       "  0.014154250147553645,\n",
       "  0.013752425936323658,\n",
       "  0.01383433428282104],\n",
       " [0.02954094790354762,\n",
       "  0.028017116135007195,\n",
       "  0.027022844699319554,\n",
       "  0.02625535738877672,\n",
       "  0.02505253300363765,\n",
       "  0.02433871610477317,\n",
       "  0.02392854900639991,\n",
       "  0.02298507464993814,\n",
       "  0.02166077793464201,\n",
       "  0.021416468960006315,\n",
       "  0.020855258634027905,\n",
       "  0.020855659706176203,\n",
       "  0.020286155214937835,\n",
       "  0.02002100014103374,\n",
       "  0.020346535058440942,\n",
       "  0.01953288537758832,\n",
       "  0.018785314487506147,\n",
       "  0.018576849072130423,\n",
       "  0.018503498443409327,\n",
       "  0.018006882215204783,\n",
       "  0.018610344305878695,\n",
       "  0.018329573409982425,\n",
       "  0.018557496019639082,\n",
       "  0.017363072672513503],\n",
       " [0.13953436551831852,\n",
       "  0.1377005135912574,\n",
       "  0.1364355649352629,\n",
       "  0.133023472621423,\n",
       "  0.1464999422277517,\n",
       "  0.14681682268973817,\n",
       "  0.15351683746200162,\n",
       "  0.15353462759977432,\n",
       "  0.14367223063602433,\n",
       "  0.1684207610632486,\n",
       "  0.15713077097126613,\n",
       "  0.1587485927907044,\n",
       "  0.1597165104685427,\n",
       "  0.16289538725485073,\n",
       "  0.15369738101931332,\n",
       "  0.16791182501095067,\n",
       "  0.1589716123800711,\n",
       "  0.1646105337622909,\n",
       "  0.15534995699280432,\n",
       "  0.16332092143120808,\n",
       "  0.16396182283675412,\n",
       "  0.16291303975919205,\n",
       "  0.16380574184466384,\n",
       "  0.15252198686313978]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Minimums of average validation loss per learning rate: {[min(x) for x in val_losses_lr]}\")\n",
    "print(f\"Minimum of minums: {min([min(x) for x in val_losses_lr])}\")\n",
    "val_losses_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(val_losses_lr)):\n",
    "#     plt.subplot(2, 1, 1)\n",
    "    plt.plot(epoch_list, val_losses_lr[i], '-o', label=learning_rate[i])\n",
    "    plt.xlabel('Epochs') #1 ~ 16\n",
    "    plt.ylabel('val_loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEGCAYAAAAjc0GqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABMQUlEQVR4nO3dd5xU1fn48c8zbXtjYdlGUxAFwYao0fgzGkUhYIkRNLaoMbaIGrtRUaNiiQqWxIIRjUiMDQwKRsWvRkUFERSRIkW2Abtsr1PO7487u2yZ2d3ZndlZ2Of9es1rZu6959xzh2GePeWeI8YYlFJKqZ5mi3YBlFJK9U0agJRSSkWFBiCllFJRoQFIKaVUVGgAUkopFRWOaBegt+rfv78ZOnRotIuhlFJ7lBUrVhQbYwZ05lgNQEEMHTqU5cuXR7sYSim1RxGRrZ09VpvglFJKRYUGIKWUUlGhAUgppVRUaB+QUkq1w+12k5eXR11dXbSL0qvExsaSm5uL0+nsch4agJRSqh15eXkkJSUxdOhQRCTaxekVjDGUlJSQl5fHsGHDupyPNsEp1Qnlb7/NhuNPYO0Bo9hw/AmUv/12tIukekhdXR3p6ekafJoREdLT07tdK9QApFQHyt9+m8Lb78BTUADG4CkooPD2OzQIhWBPD+AafNoKx2eiAUipDux49DFMq7/0TF0dOx59LDoF2sNoAFfBaABSqgOewsKQtquWNIB330UXXURGRgYHHnhgyGlXrFjBmDFjGD58OFdffTXN14B7/PHH2X///Rk9ejQ33nhjOIvcKRqAlOqAIysryPbMHi7JnqmvBfC3VuZz9MwPGXbzIo6e+SFvrczvdp4XXnghixcv7lLayy+/nGeffZYNGzawYcOGpnyWLl3KggULWLVqFWvWrOH666/vdjlDpQFIqQ5kXHsNEmCoaeyoUVEozZ7HnpYWcLtjYEbYzxXtvqa3VuZzyxvfkl9WiwHyy2q55Y1vux2Ejj32WPr169di248//sjJJ5/MYYcdxs9//nN++OGHNukKCwupqKjgyCOPREQ4//zzeeuttwD429/+xs0330xMTAwAGRnh//foiA7DVqoDKZMns/Opp3D/tA18PhxZmThzB1H1/gfsevEl+p1/XrSL2Gu5d+zAV18PItCs6QfAuD00bN2Ka8iQsJyrsa+psbmvsa8JrH/DcLjr7TV8X1ARdP/Kn8po8PpabKt1e7nxtdW88uVPGI8H424AnwGbIE4Xowf3487Jo0Muy6WXXsrf//53RowYwRdffMEVV1zBhx9+CICnrAzP9u38+M03ZPfrh6esDEdqKrm5ueTnW8Fw/fr1fPLJJ9x2223Exsby8MMPc/jhh4dcju7QAKRUB+rWrce9eQsZN1xP+sUXA2A8HvKvvZbt992HPS2NlMm/inIpQ1f+9tvsePQxPIWFOLKyyLj2mrD9UAMYn4/Cm28Gr5cB111H6SuvNJ0r5bTTKJs3jy3Tzib3ySeJP/SQbp+vvb6mcF5XU94Bgknr4NOoweuzjm9o2B2IfQbT0ICpr2/3PI3BpG7LFkxDA56yMuocDj777DN+85vfNB1X78/HU1aGO78AjL8sPp/1vnW+Hg+7du1i2bJlfPXVV5x11lls2rSpR0f8aQBSqgOl8+YhMTGknHFG0zZxOMh++GG2/f5SCm65BXtKMonHHhvFUoamJ2oLJXPmUP3Z52TefRdpZ51F/99f0mJ/6pTJbPvDZfx04YVkPzCT5FNO6db5PAVtf2QhvH1NjTWVNj/yACKc8FYdBZUNbdJlJzmZe1x6y+Mbk9nteMrKEIcDcTqtZ7s98HmMwZ1fQENSIqmpqXzzzTcYnw/j9YLHQ0NZOYcfeSQGmHTccfx+6lTyt28H48OzfTt5eXnk5OQAkJubyxlnnIGIMH78eGw2G8XFxQwY0KmVFMJC+4CUaoe3spLyt98meeJEHK36MmwxMeQ+9SQx+40g7+rp1KxcGaVShi7SI9NqV61i56zZJJ18MqnN/kpvzjV0KEPmv0LsmDHkX3sdxc8822KEVmfVb9rEtquuCrrfEYEfVI//R70FY7hmbBKx9pY1iFi7cO3BaQGDD4DxenHn5dGwZQv1GzZQt3Ytdd9/T9369bjz8wOcx0dcZSVDsrJ4+dFHrWN/+IGv3nkHb942lr32Gl+89hp3XHUVWQMGkJSYyJerVuFraODFF1/k1FNPBeC0005j6dKlgNUc19DQQP/+/cPzAXWSBiCl2lH+5luYmhrSfvvbgPvtiYkMfuYZHAMz2HbZ5dRv2NDDJQyNr66OyqVLI1pb8FZWkv+n63FmZJB1913tNuk40tIY/PwckidNYucjj1B0xx0Yt7tT5/Hs3EnhnTPYNHkKNZ8vI2nCBCQ2tm15amuoW7u2y9fTmjEmaBknD0vk/in7k50SiwA5qbHMPPMgfjPp8IADWQDE6SRmxAhcQ4fizM3FOTATe1oatri4pua6C268kePOPZf1W7Yw/IQTeOH115k7+3FeXLiQI6ZOZdyZZ/LuihW4hg1DHC0bth7785+5YsYMDpw0iX333ZdT/DXNiy66iE2bNnHggQcybdo05s6d2+M33EpX/uII6QQiJwOzADvwnDFmZqv9McCLwGFACTDVGLPFv+8W4GLAC1xtjFnSXp4iMgcYBwiwHrjQGFPV3jmCGTdunNEF6fo2YwybJk7ClpzEsH/9q91jG/Ly2Xr22WCzMXTeyzj9zRw9pb3+HM+uXVQt/YjKpR9S/elnmNragIMCAByZmYz4aGmXy2GMoeBP11OxZAlDXnqp0307xudj5+zZlPz9aRKOPpqcxx7FnpQU8FhvVTW7nn+ekhdewDQ0kDZ1Kv2vuBxHenqbzyHt7GmUvjwPX2UluU8+QcKRR4Z8TWvXruWAAw6wyun14s7Px1sReCCCOJ3EjhwZcF/gZjsbzpxsHKmpAdPUrVsXMNiFfB7AFh9vBagwBpnmn01T2URWGGPGdSZ9RAOQiNixAsGJQB7wFXC2Meb7ZsdcAYw1xlwmItOA040xU0VkFPAKMB7IBt4H9vMnC5iniCQbYyr8+T4C7DDGzAx2jvbKrgFIVX/2GT9ddDHZD8wkxd9s0Z66devZet55OPr1Y8i8l3G0GjYbKa37cwAkJobEX56Ap2g7tStXWqP3MjNJOv54Eo8/Hs/OHRTddXebZjh7RgbDXpnX5QBa9vobFN52GwOumU7/yy7rQvrXKbxzBjHDhpHymzPZ9cLcpmAy4Oo/4qupofjJp/CWlJB08slkXHtNh6Po3EVFbPv9pdRv2UL2/feT8qtJIZWp8UfWV1tLw7ZtmAY39pRkvBWVIQUT2D2gwLjdiNOJY+DADo8PNWgFOo8tLg5vRQWO9HQcmZlhC0K9PQAdBcwwxkzwv78FwBhzf7NjlviP+VxEHEARMAC4ufmxjcf5k3WUpwBPAVuMMQ8EO4dp5+I1AKltV15F7ddfM/yjpdj890p0pObrr/npoouJ2XdfBs+diz0xIeTzhjI6zVddzY+nTMSzY0fA/TEHHOAPOr8gdtSoFj88rc+TPGUyZS/PwxYby6BnnyF2//1DKnf9ps1s/vWviRszhsH/eL6pIz1U1Z99xk+XXwGtR4f5a23x48aRccP1xB10UKfz9FZUkHfFldQsX07GjTeSftHvOp127dq1jMjMxF1QgNjtOAcNwp6QEHIw6apwnMcYg6eoCE9JCY6BA3GGqV+suwEo0qPgcoBtzd7nAUcEO8YY4xGRciDdv31Zq7SNf5YFzVNE/gFMBL4H/tTBOYqbF0RELgUuBRg8eHAIl6n2Nu6CAqqWLiX94os7HXwA4g89lJzHHiXvyqvIu+oqBj3zNDaXq9PpA41OK7j1Nirefx9nejqencV4inc/TG1t8MxE2OfNN4LuTpk8uU1gS5k4kW2X/oGtvz2X3CceJ+GoozpVbl9DA/l/+hO2mBiyH3qwy8EHIOFnP8ORnIxn586WO4zB3q8fg196MeS/4O3JyQya8xwFN97EjgcfxLNjBxk33oDY2u8G99XX4y0rw+31YktIwJWb29SX40hNjUjAaS0c5xERHJmZGI8Hz/btiN3eYzX09ux1gxCMMb/DarJbC7TbzBYg7TPGmHHGmHE9ORRR9T6l860+n7RpIX2FAEg67jiy77+PmmXL2HLOb9nwi+MD3plv3G7qN22i8v33KX76GQpuupmCW29r0yyG203VkveoWPQO9Zs3ITExxB10EGlTp5Jxw/XYg/w4BZtCqD2x++3H0Pmv4MzJ4adL/9DpmQR2PPww9WvXknXffTgHDgz5vK15iosDbveWlna5+cgWE0POI38l7dxz2fXCCxTccCO+hrZDphs1bNvGlrPPxldTg6P/AFxDhwYdSLAnEBGcOTnYEhNxFxTgLS+PdpEiXgPKBwY1e5/r3xbomDx/81gK1kCB9tK2m6cxxisi84EbgX+0cw6l2vA1NFD22mskHndcl/tCUqZMoep//6Ni4e4fcE9BAQW33ELJP17A+PsT8Hia9jsyMiDYCDAR9vtiWcBdjoyMtn1AsbFkXHtNl8ruzMxkyMv/JO+qP1Jww424i4pIv+SSoD/8lUuXUvriS6Sddx5Jx/+iS+dszZGVFXCkXleCanNitzPwtltxZg5kx8N/xVNSQu7js9sMeKj8cCkFN98MgL1fP5yZ3Q+qvYHYbLgGDaJhy1Ya8vJw2e3YExOjVp5I14C+AkaIyDARcQHTgIWtjlkIXOB/fSbwob9vZiEwTURiRGQYMAL4MlieYhkOTX1AU4AfOjiHUm1ULl6Md9cu0s45p1v51Cxf0Xajx0v9+vXEjBhB+sXWAIeh/36V/ZZ/xYiP/w9HdnbAvNr74U2ZPJmse+620orgyM4m6567u3VDqT0piUHPPkPyxIns/OsjbP/LvdbNjq24t++g8NbbiNl/fzKu/1OAnLom49pr2gyp7k5QbZGPCOmXXEL2AzOpWb6creeeR8k/X26aQ27duMPJu+IKXLm5DHv9NWwBhnbvycRuxzVkMDaXC/dPP+Frrxk3wiJaA/L3t1wFLMEaMv28MWaNiNwNLDfGLATmAC+JyEZgF1ZAwX/cq1h9OR7gSmOMFyBInjZgrogkYw3DXgVc7i9KwHMoFUjpy/NwDRlCws861/8RTNB7arxecmfPCrgr49prulSbCdSf0102l4vshx/CkZnJruefx7NjO9kPPdT0g2y8XgpuvBFfXR05j/w1pL6yjjReSySnCko59VTs6f3Zdvnl7Lj33qZh6b6qKrDbST33XFyDBkEY7yHqqosuuoj//Oc/ZGRk8N1334WUdsWKFVx44YXU1tYyceJEZs2ahTgc3Pfiizz7zDMMSOuHxLi47/77mThxYoSuILCI3we0p9JRcD2vK3OThXs+s9o1a9jy6zMZeMvN9Lvggo4TtGPD8ScEbkbKzmbEhx8ETRfpOdq6YteLL7L9/pnEHXIIKVOmUPzMM03XlvKbM8m+556olq871h/zc7wB+pwa/50CjfRq1+pX4YO7oTwPUnLhhDtg7FndKuPHH39MYmIi559/fsgBaPz48cyePZsjjjiCiRMncvXVV3PKKacwY8YMEmJj+eOpp4FNcO2zD7YQ+7i6OwpurxuEoPZMXVk1MxIrbZbOm4fExZFy+uldzqNRV5uRUiZPZsSHH3DA2u8Z8eEHUQ8+AP3OP5+cRx+h9ptvKLrrrhaBteLt/+zRq5t6SwJ3B3dpVojVr8LbV0P5NsBYz29fbW3vhkgsxwDWnIauoUPA68W9ZQumWZ9kT9DJSFWvEGxusqK778FdWOTfYFo8l8yZE9bZj71lZVT8Z5HVNJOcHPpFtNITzUg9Kfnkkym65y9tfrAjOeN0TwhpwMO7N0PRt8Ezy/sKvK3uX3LXwoKrYMXcwGkyx8ApMwPva0d7yzE0ys/PJzc3t+l98+UYAJ544glefPFFDjvoIO69/HL6GQP+qYYieW9TIw1AqlcI9temr7KSnY88Epa8OlL2xpuY+nrSftu9wQfNRaJvJpq8u3YF3L4nr27a1X63gFoHn462d1FVVVXQ5Rg66/LLL+f2229HRLj99tu5dfZs/vbnPzftN2530zIOkQpCGoBUVPnq6yl+6m8B5yUD66/Qfd99x7oLHpqeBdg44eSAP3xdGaprfD5KX3mFuMMOCzrHlorc8OhoCqmm2lFN5dED/c1vrU8yCH63KAyltfh8vqblGJrzer0cdthhAEyZMoXLL7+cvLy8pv3Nl2MY2Ox+rd///vdMOumktifyL+MQqQCkfUAqampWrGDzaadT8vTTxI0bF7i/5LprscXGYouJsR4uFzaXC3G5yLju2oCzH8cfFfqEk9WffIJ72zbSzjm7y9fTF0RyeHQ0ha3f7YQ7wBnXcpszztoeRsnJyQwbNox///vfgDXVzqpVq7Db7XzzzTd888033H333WRlZZGcnMyyZcswxrRYjqGw2R9vb775JqP23TfguTo7O3lXaABSPc5bVUXR3Xez9bfnYhoaGPTccwz950sh38vS5v6XrCxc+4+k4vU32DU3SHt7ELvmzcPevz/JJ57Y3cvbq0XinqO9ytizYPJsq8aDWM+TZ3d7FNzZZ5/NUUcdxbp168jNzWXOnDm8/PLLzJkzh4MOOojRo0ezYMGCgGmfeuopLrnkEoYPH95iOYYbb7yRMWPGMHbsWJYuXcqDt94aMH0kZ3/QYdhB6DDsyKj6v/+jcMZdeIqKSDvvXDKmT8eWEPqEncGYhgbyr7+ByvfeY8D0q0m/7LIOp25p2LaNH0+aQP/LL2PA1VeHrSxq7xDyMOw9VFdm3u7tk5EqBYCntJTt991Pxdtv49p3X4bMe5n4Qzq3VkwoxOUi55G/Unjbn9k5aza+6moG/OlP7Qah0lfmg81G6tTQ531Tam/RGGR6YobvpnNGLGe1V+j+zaGZJP6/46zpbSor6X/FFaRf9oeQZogOlTgcZN1/HxIfR8lzc/DV1DDwz38OOPOxr66O8tdfJ+mEE8IyiaZSe7KemuG76Xw9dia1xwm0NEDh7VZnarAg1DZNIWWvvIIjN5dhL7xA7Mj9AqYLN7HZyLzjDmxx8ex6/nl8NbVk/eWeNssVVyx6B295ebfnfVNKhU4DkAoq2M2hhXfOsJZ2bqjHV9+AaWjA1Ndj6uupXbOmxQzPTbzeHgs+jUSEjBuux5YQT/HjT1hzlj34AOKvfRljKJ03D9fwfYk/YnyPlk0ppQFItSPYzYWmpobqL7/A5opBXC4kJgaJcVmDCYJM5eEpKopkUYMSEQZceSW2uHh2PPggebW15Mx6DFtsLHWrV1O3Zg0D77g9bEsUK6U6TwOQCsqRlYmnIMCNnu1Mphl0As4o36iYftHvsMXHU3TXXWz69ZmY6morKIogzsj1RymlgtP7gFRQ8Ue0Xj2945sOe/ONimnTppI69SzcP/64u0ZmDNvvvXePnkxT9Q2LFy9m5MiRDB8+nJkz287IUF9fz9SpUxk+fDhHHHEEW7Zsadp3//33M3z4cEaOHMmSJUs6zPOJJ55g+PDhiAjFQVanDQcNQCqg2tWrqfjPIlz7j7RqL129ObSX3ahY9fEnbbY1TqapVDgs2rSIk147ibFzx3LSayexaFP3p+Dxer1ceeWVvPvuu3z//fe88sorfP/99y2OmTNnDmlpaWzcuJFrr72Wm266CYDvv/+e+fPns2bNGhYvXswVV1yB1+ttN8+jjz6a999/nyFDhnS77O3RJjjVhqe0lLxrrsE5YABDX3gBe4jDMnvzBJzB+rX25Mk0Ve+xaNMiZnw2gzqvNXinsLqQGZ/NAGDSPpO6nO+XX37J8OHD2WeffQCYNm0aCxYsYNSoUU3HLFiwgBkzrHOdeeaZXHXVVRhjWLBgAdOmTSMmJoZhw4YxfPhwvvzyS4CgeR4SgXv0AtEApFowPh8FN92Ed2cxQ+a9HHLw6e32xsk0Vc954MsH+GFX23V3Gq3euZoGX0OLbXXeOu749A5eW/9awDT799ufm8bf1O558/PzGTRoUNP73Nxcvvjii6DHOBwOUlJSKCkpIT8/nyOPPLJF2sYlGTrKM9K0CS6Myt9+u2ld+Q3Hn7BH9iuUPP001R9/wsBbbyFuzJhoFyfsenMfldrztQ4+HW3v67QGFCZduWmzt6n+7DN2zn6c5MmTSZ02LdrFiYi9bZE41bM6qqmc9NpJFFa3bc7NSsjiHyf/o8vnzcnJYdu23cs8NF9WofUxubm5eDweysvLSU9PbzdtR3lGmtaAwiTYTZs7/hraYmrR4i4qIv9P1xMzfF+y7pqxV98X0xuXvFZ7h+mHTifW3rKGHWuPZfqh07uV7+GHH86GDRvYvHkzDQ0NzJ8/nylTprQ4ZsqUKcz1zwL/2muvcfzxxyMiTJkyhfnz51NfX8/mzZvZsGED48eP71SekaY1oDAJ2rldVMTGE08iZr/9iB25HzH7WQ/X4MFN08J0Zb61cDJuN/nXXIuprydn1ixs8fE9dm6l9iaNAw1mfT2LouoiMhMymX7o9G4NQACrT+eJJ55gwoQJeL1eLrroIkaPHs0dd9zBuHHjmDJlChdffDHnnXcew4cPp1+/fsyfPx+A0aNHc9ZZZzFq1CgcDgdPPvkkdrsdIGCeALNnz+bBBx+kqKiIsWPHMnHiRJ577rluXUMguhxDEKEuxxDsBkxbUhIJxxxN/br1NGzZAj5rqnNxuYgZPhyJi6N21aoWMwhIbGyHQ5fDGbS2338/u+a+SM6jj5DsXytEKWXpK8sxdIUux9BLBFtXPvOO25sCg6++noYff6Ru3Xrq11uP6s8/bwpKjUxdHYW33kbVR/+HMzsbZ042zpwc63V2NpXvvx+2/qaKxYvZNfdF0s47T4OPUqpHaQAKk850bttiYogdNYrYZmP31x4wqk1eYDWL1a5eTcWSJW3nV7PZAgatHY8+FlIAqt+0mcJbbyPuoIMYeMP1nU6nlFLhoAEojLpyA2bQ+1Kysxn+3/cwXi+enTtxFxTgzs/HnV/AzsceC5iXx3+MsxMjWXw1NeRPn47ExJDz2KNNM0QrpVRPifgoOBE5WUTWichGEbk5wP4YEfmXf/8XIjK02b5b/NvXiciEjvIUkZf9278TkedFxOnffpyIlIvIN/7HHRG+7E7r6L4UsdtxZmYSf+ihpEyeTP/L/mBNcxPExhN+yebfnEXJnDk0NBtiCS3vU1p/9DHUb9hA9sMP4dSbMJVSURDRGpCI2IEngROBPOArEVlojGk+idHFQKkxZriITAMeAKaKyChgGjAayAbeF5HGBWWC5fkycK7/mHnAJcDf/O8/Mcb8KlLX2lVduS8lWH/TgOlXYzweKpe8x46HHmbHQw8TO2oUSSefjDgd7Jw1uymNqa0FhwPvrl2RvUCllAoi0k1w44GNxphNACIyHzgVaB6ATgVm+F+/Bjwh1k0opwLzjTH1wGYR2ejPj2B5GmPeacxURL4EciN1YeEUatNdR0Gr/+9/T0NeHpVL3qPivSXsfCTIvUgeT8j9RkopFS6RboLLAZq3A+X5twU8xhjjAcqB9HbSdpinv+ntPGBxs81HicgqEXlXREYHKqyIXCoiy0Vk+c6dOzt3hVHS0c2Urtxc0i++iGH/+hfDg6zdAzoJp1J7ikgsx3DRRReRkZHBgQce2BOX0MbeOhPCU8DHxpjGufe/BoYYYw4CHgfeCpTIGPOMMWacMWbcgAEDeqakPcCZnR2030gn4VQqvCIxJ2QklmMAuPDCC1m8eHGb8/WUSAegfGBQs/e5/m0BjxERB5AClLSTtt08ReROYABwXeM2Y0yFMabK//odwCki/btzYXsanYRTqchrnBPSU1AAxjTdo9fdINR8OQaXy9W0dEJzCxYs4IILLgCs5Rg++OCDDpdjOPbYY+nXr1+3ytYdke4D+goYISLDsILENOCcVscsBC4APgfOBD40xhgRWQjME5FHsAYhjAC+BCRYniJyCTABOMEY03SjjIhkAtv9+Y7HCrwlEbrmXkkn4VSq+4ruu4/6tcGXY6hdtQrT0HLma1NXR+Ftf6bs1X8HTBNzwP5k3npru+eN1HIM0RbRAGSM8YjIVcASwA48b4xZIyJ3A8uNMQuBOcBL/kEGu7ACCv7jXsUasOABrjTGeAEC5ek/5d+BrcDn/sk03zDG3I0V2C4XEQ9QC0wzfXAOot68UJxSe4PWwaej7X1dxG9E9Td5vdNq2x3NXtcBvwmS9l7g3s7k6d8e8HqMMU8AT4RUcKWUaqWjmkqwOSEd2dkMeenFLp83UssxRNveOghBKaV6XKT6WiOxHENvoFPxKKVUmESqrzVSyzGcffbZfPTRRxQXF5Obm8tdd93FxRdf3L0PIQS6HEMQoS7HoJTaO+lyDMF1dzkGbYJTSikVFRqAlFJKRYUGIKWU6oB2VbQVjs9EA5BSSrUjNjaWkpISDULNGGMoKSkhttWIv1DpKDillGpHbm4ueXl59PYJintabGwsubndW3BAA5BSSrXD6XQybNiwaBdjr6RNcEoppaJCA5BSSqmo0ACklFIqKjQAKaWUigoNQEoppaJCA5BSSqmo0ACklFIqKjQAKaWUigoNQEoppaJCZ0IIo7dW5vPQknUUlNWSnRrHDRNGctohvWPpW6WU6m26FIBExAYkGmMqwlyePdZbK/O55Y1vqXV7Acgvq+WWN74F0CCklFIBdLoJTkTmiUiyiCQA3wHfi8gNkSvanuWhJeuagk+jWreXh5asi1KJlFKqdwulD2iUv8ZzGvAuMAw4LxKF2hMVlNWGtF0ppfq6UAKQU0ScWAFooTHGDegCGX7ZqXEhbVdKqb4ulAD0NLAFSAA+FpEhgPYB+d0wYSRxTnuLbXabcMOEkVEqkVJK9W6dHoRgjJkNzG62aauI/CL8RdozNQ40aBwFF++yU+f2cuQ+6VEumVJK9U6hDEKY7h+EICIyR0S+Bo7vRLqTRWSdiGwUkZsD7I8RkX/5938hIkOb7bvFv32diEzoKE8Redm//TsRed7fZIi/zLP9x68WkUM7e92hOO2QHD69+Xg2z5zE4muOBRGe+XhTJE6llFJ7vFCa4C7yD0I4CUjDGoAws70EImIHngROAUYBZ4vIqFaHXQyUGmOGA48CD/jTjgKmAaOBk4GnRMTeQZ4vA/sDY4A44BL/9lOAEf7HpcDfQrjuLhnUL57TD8lh3pdbKa6qj/TplFJqjxNKABL/80TgJWPMmmbbghkPbDTGbDLGNADzgVNbHXMqMNf/+jXgBBER//b5xph6Y8xmYKM/v6B5GmPeMX7Al0Bus3O86N+1DEgVkawQrr1LrjhuX+o9Pub8b3OkT6WUUnucUALQChF5DysALRGRJMDXQZocYFuz93n+bQGPMcZ4gHIgvZ20Hebpb3o7D1gcQjkQkUtFZLmILN+5c2cHl9axfQYkMmlMFi99vpXyGne381NKqb1JKAHoYuBm4HBjTA3gAn4XkVJ131PAx8aYT0JJZIx5xhgzzhgzbsCAAWEpyJW/GE5VvYcXPtsSlvyUUmpv0ekAZIzxYTVp/VlEHgZ+ZoxZ3UGyfGBQs/e5/m0BjxERB5AClLSTtt08ReROYABwXYjliIgDspI5cdRAnv90M1X1np44pVJK7RFCGQU3E5gOfO9/XC0i93WQ7CtghIgMExEX1qCCha2OWQhc4H99JvChvw9nITDNP0puGNYAgi/by1NELgEmAGf7A2bzc5zvHw13JFBujCns7LV311W/GE55rZuXl23tqVMqpVSvF8pkpBOBgxt/2EVkLrASuDVYAmOMR0SuApYAduB5Y8waEbkbWG6MWQjMAV4SkY3ALqyAgv+4V7GCnQe40hjj9Z+7TZ7+U/4d2Ap8bo1j4A1jzN3AO/7ybwRq6OGmw4MGpfLzEf159pNNXPCzocS2umFVKaX6IrEqG504UGQ1cJwxZpf/fT/gI2PM2AiWL2rGjRtnli9fHrb8vty8i7Oe/pwZk0dx4dHDwpavUkr1JiKywhgzrjPHhjII4X5gpYi84K/9rADu7UoB+6Lxw/oxfmg/nv54Ew2ejgYPKqXU3i+UQQivAEcCbwCvA0cZY/4VqYLtja46fjiF5XW88XVetIuilFJR12EAEpFDGx9AFtY9NHlAdqSmtNlb/XxEfw7KTeGpj37E49VakFKqb+vMIIS/trPP0In54JRFRLjyF8O59KUV/Gd1oa6UqpTq0zoMQMaYTs14LSInGmP+2/0i7d1+ecBA9s9M4omlG5lyUDY2W0ezGSml1N4plEEIHXkgjHnttWw2qxa0cUcVS9YURbs4SikVNeEMQPqnfCdNHJPFPv0TeGLpRjo7DF4ppfY24QxA+kvaSXabcPlx+7KmoIKP1nV/0lOllNoThTMAqRCcdkgOOalxzP5wg9aClFJ9UjgD0JYw5rXXc9ptXHbcvqz8qYzPfyyJdnGUUqrHdTgKTkTOaG+/MeYN/3O7x6m2fnNYLo9/sIEnlm7kZ8P7R7s4SinVozpzH9DkdvYZrJkRVBfEOu1ceuw+/GXRWsb95b+UVDWQnRrHDRNG6j1CSqm9XmfuA+qti87tFZJjrX+C4qoGAPLLarnljW8BNAgppfZqoSzHgIhMAkYDsY3b/MsdqC6a9cHGNttq3V4eWrJOA5BSaq8WyoJ0fwemAn/EuufnN8CQCJWrzygoqw1pu1JK7S1CGQX3M2PM+UCpMeYu4Chgv8gUq+/ITo0LabtSSu0tQglAjX+S14hINuDGmh1bdcMNE0YS12qFVIdNuGHCyCiVSCmlekYofUD/EZFU4CHga6wRcM9GolB9SWM/z0NL1lFQVkus006t28uApJgol0wppSKr00tyt0gkEgPEGmPKw1+k3iHcS3J3VnW9h1Of/JTS6gYWXf1zMlNiO06klFK9RESW5BaR1SJyq4jsa4yp35uDTzQlxDj4+7mHUuv2ctW8r3HrwnVKqb1UKH1AkwEP8KqIfCUi14vI4AiVq08bnpHEzF+PZfnWUh5c/EO0i6OUUhHR6QBkjNlqjHnQGHMYcA4wFtgcsZL1cVMOyub8o4bw7CebWfxdYbSLo5RSYRfSZKQiMkREbgTmA/sDN0akVAqA2yYdwEG5Kdzw79VsKa6OdnGUUiqsQukD+gJ405/mN8aY8caYv0asZIoYh50nf3sodrtw+ctfU+f2RrtISikVNqHUgM43xhxqjJlpjNnUeqeIXBDGcim/3LR4Hp16MGsLK7hjwXfRLo5SSoVNKH1A6zo4ZHqgjSJysoisE5GNInJzgP0xIvIv//4vRGRos323+LevE5EJHeUpIlf5txkR6d9s+3EiUi4i3/gfd3T2unuDX4zM4I/HD+fV5Xm8+tW2aBdHKaXCIpwL0kmbDSJ24EngFGAUcLaIjGp12MVY0/sMBx4FHvCnHQVMw5r89GTgKRGxd5Dnp8Avga0ByveJMeZg/2OPm0D1ml/ux8/2Tef2Bd/xfUFFtIujlFLdFs4AFOiO1vHARmPMJmNMA9bghVNbHXMqMNf/+jXgBBER//b5/nuONgMb/fkFzdMYs9IYsyWM19Rr2G3C7LMPITXeyRUvr6Cizh3tIimlVLeEtBxDB9rUgIAcoHmbUR5wRLBjjDEeESkH0v3bl7VK27g+QUd5BnKUiKwCCoDrjTFr2lyAyKXApQCDB/e+W5z6J8bwxDmHMu2ZZZz77DJKqhsoKKvTReyUUnukcNaAPg1jXuH2NTDEGHMQ8DjwVqCDjDHPGGPGGWPGDRgwoCfL12mHD+3Hr8ZksTq/gvyyOgy7F7F7a2V+tIunlFKd1ukakIhcF2BzObDCGPONMeaqAPvzgUHN3uf6twU6Jk9EHEAKUNJB2o7ybMEYU9Hs9Tsi8pSI9DfGFLeXrrdavnVXm226iJ1Sak8TSg1oHHAZVjNYDvAHrMEBz/pvTg3kK2CEiAwTERfWoIKFrY5ZCDQO4T4T+NBYM6QuBKb5R8kNA0YAX3YyzxZEJNPfr4SIjPdfd0nnL713KSirC7JdF7FTSu05QukDygUONcZUAYjIncAi4FhgBfBg6wT+Pp2rgCWAHXjeGLNGRO4GlhtjFgJzgJdEZCOwCyug4D/uVeB7rDnorjTGeP3nbpOnf/vVWLMzZAKrReQdY8wlWIHtchHxYK1rNM10ZRrwXiI7NY78AMEmO1VnzlZK7Tk6vRyDiPwAjDHGuP3vY4BVxpj9RWSlMeaQCJazx0VrOYbOeGtlPre88S21rWZGGD80jX9eciQuRzi79pRSqvMishwD8DLwhYjc6a/9fArME5EErFqK6iGnHZLD/WeMISc1DgFyUmOZMGogX24p5YLnv6S8RodoK6V6v5AWpBORccDR/refGmN6ZxUhDHpzDSiY11fkcfMbqxncL55/XDiewenx0S6SUqqPidSCdLMBlzFmlv+xZ/069wG/PiyXly4+guKqBk5/6lO+/qk02kVSSqmgQmmCWwH8WUR+FJGH/bUh1cscuU86b1zxMxJjHZz9zDIWrda1hJRSvVMok5HONcZMBA4H1gEPiMiGiJVMddm+AxJ584qjGZOTwpXzvuZvH/3IHjzoTym1l+rKcKnhWIvRDQF0veheql+Ci39ecgSTD8rmgcU/cPPr3+L2+qJdLKWUahLKTAgPAqcDP2JNAHqPMaYsQuVSYRDrtDNr6sEMTY/n8Q838vVPu6iq91JUrvPHKaWiL5QbUX8EfgbsA8QAY0UEY8zHESmZCgubTfjTSSMprqrnlS93z+HaOH8coEFIKRUVoTTB+YAPgcXAXVgzEcyIQJlUBHy8vu20d43zxymlVDSEEoCuxhqAsNUY8wvgEKAsEoVS4RdsnjidP04pFS2hBKA6Y0wdWNPwGGN+AEZGplgq3LJT4wJuN8Aj/11PXatpfZRSKtJCCUB5IpKKtZbOf0VkAYGXvla90A0TRhLntLfYFuu0cdjgVGZ/sIGJsz/hi0177AThSqk9UKcHIRhjTve/nCEiS7HW7VkckVKpsGscaPDQknUUlNW2GAX3f+t38ue3vmXqM8uYdvggbjnlAFLinVEusVJqbxfSXHB9yZ44F1x31DR4mPX+Bp7732bS4l3cOXkUvxqbhX8ZJaWU6pRQ5oLTABREXwtAjb7LL+eWN77l2/xyjt8/g2OGpzPnf1va1JqUUioQDUBh0FcDEIDH62Pu51uZ+e5a3N6W3484p537zxijQUgpFVCk1gNSfYTDbuPiY4bRL8HVZp/eO6SUChcNQCqoHRX1Abfnl9XqondKqW7TAKSCCnbvEMCR93/A7W99x6adVT1YIqXU3kQDkAoq0L1DcU47N0wYyaSxWfzrq20c/9f/46IXvuLTjcW65INSKiShTEaq+pj27h0CuOnk/fnnsq38c9lWfvvcF+yfmcRFxwxDgMfe36Aj55RS7dJRcEH05VFwoapze1n4TQHPf7qZH4oq2+zXkXNK9R06Ck71qFinnbMOH8S7039O/8TAI+ceWKxrFyqlWtIApMJGRCipagi4r7C8jkvmfsWbK/OorNMRdEop7QNSYZadGkd+gCUeEmLsrCmo4P21O3A5bBw7YgC/GpvFCQdkkBRrzTv31sr8oP1NSqm9T8QDkIicDMwC7MBzxpiZrfbHAC8ChwElwFRjzBb/vluAiwEvcLUxZkl7eYrIVcA1wL7AAGNMsX+7+I+fCNQAFxpjvo7cVfddN0wYyS1vfEtts+Ud4px27j1tDFMOymbltlIWrS7inW8LeX/tdlwOG/9vvwFkJsfw7xV51Ll9gK7YqlRfENFBCCJiB9YDJwJ5wFfA2caY75sdcwUw1hhzmYhMA043xkwVkVHAK8B4IBt4H9jPnyxgniJyCFAKfASMaxaAJgJ/xApARwCzjDFHtFd2HYTQdZ2pyfh8hq9/KmXRt4W8820h24Pc9JqTGsenNx/fE8VWSoVBKIMQIl0DGg9sNMZsAhCR+cCpwPfNjjmV3Ut7vwY84a+xnArMN8bUA5tFZKM/P4LlaYxZ6d/WuhynAi8aK9ouE5FUEckyxhSG9WoVYNVYOqq12GzCuKH9GDe0H7dPGsW+t75DoD+F8stqWbiqgJ/tm07/xJjIFFgpFRWRDkA5wLZm7/OwaiABjzHGeESkHEj3b1/WKm3jr1pHeXamHDlAiwAkIpcClwIMHjy4gyxVuNhsErTvSICrX1kJwP6ZSRw9vD9HD09n/LB0EmMc2m+k1B5MByE0Y4x5BngGrCa4KBenTwnedzSafTKS+HRjMZ/9WMxLy7Yy53+bcdiE3LQ48kpr8fisfyrtN1JqzxLpAJQPDGr2Pte/LdAxeSLiwFpptaSDtB3l2ZVyqCjqaNaFgwelcuUvhlPn9rJiaymfbizm2U82NQWfRrVuL3e9vYaxuSkM658QcEE9rTUp1TtEehCCA2vAwAlYP/hfAecYY9Y0O+ZKYEyzQQhnGGPOEpHRwDx2D0L4ABiB1SrTUZ5baDkIYRJwFbsHIcw2xjT2JwWkgxB6v2E3LwrYb9QoJc7JQYNSOTg3hYMHp3JQbiqfbCgOWNPSmRqUCo9eMwjB36dzFbAEa8j088aYNSJyN7DcGLMQmAO85B9ksAuY5k+7RkRexRqw4AGuNMZ4oWm4dYs8/duvBm4EMoHVIvKOMeYS4B2s4LMRaxj27yJ53apnBOs3ykiK4boT92NVXhkrfyrjiaU7aawo2W2CN0Ct6aEl6zQAKdXDdC64ILQG1Pu9tTK/U7WZ6noP3+WX8822Mu5/N/iUQJcfty/7ZyYxMjOJffon4nLsnihEm+2U6pxeUwNSKpI66jdqlBDj4Ih90jlin3Re/HxrwFqTwyY8+/HuPiWnXdh3QCIjM5Pw+ny8t2YHDV69SVapcNIApPZonbnnqLlgo+3uP2MME8dksam4inVFlfxQVMm6okqWbykNGLBq3V5uX/AdNpuwT/8EhvZPIDGm7X8nrTkpFZw2wQWhTXB7r1CDQkeDHRoNSIphWP8E9umfwLD+CeyoqOOfX/xEvcfXdExnBjxo0FJ7Mm2CU6ododaagg12yE6J5R+/G8/m4io2FVezeWc1m4ur+e/32ympDjwreK3by5/f+o7yWjfZqXFkp8aSkxpHSpwTEWnTr6XNfWpvpjWgILQGpBp1drBDc+W1bg6+671O1ZwA4l12slPj2LarpkWNqVF2aiyf3XxCu2XUWpPqDbQGpFQYdXawQ3Mpcc7gNafUWBZceQwFZbXWo7yu6fXGHVUB8ysoq+OYBz4kNy2O3LT4Fs9rCsp5aMm6kGcS16Clok1rQEFoDUh1V1dqTkfP/DBg0EqMcfDLAzLIK60lr7SW7ZV1dPRfNznWwR2TRzMgKYYM/yMt3oXN1raprzNlU6ozQqkBaQAKQgOQCodQaxmdDQz1Hi+FZXXkldZy7pwvOl0eh00YkBRDcVU9bm/b//sDkmJY9MdjSE+MwW5rO41RV65J9S0agMJAA5CKllB/4IPVmrJSYpl/6ZHsqKxnR0U9Oyrr2FlZz47Kel5bkdduGWwC/RNjGJgca9We/M8F5bUsWFnQdE8UQJzTxv1njA17c58Guj2TBqAw0ACk9hThbOrrl+Di2hP3Y2dFHdsr6tleWdcUvEqqG4I2+9kERmQkkRrvpF+Ci9R4F2nxTtLiXWwqruL1Ffktglas08bMdoKWNhHuuTQAhYEGILUniVRTX3Nur4/9bns36Mi+k0YNpKzGTWlNA6U1bspqGtrMVt6cADlpcaT6A1VKnJPUeCepcS5eWraF8lpPmzQ5qbF8GoHRgFrbCh8dBadUHxPqvU1dGdnntNuCjuzLSY3jmfNb/uYYY6is93DQjMDD0Q0wfmg/ymqtYJVfVkt5jZuyWnebCWMb5ZfVcfTMD+mf6CI9MabpOT3BxdaSav71VV6rKZNWt7jeQLp675UGre7TGlAQWgNSqq1wNvflpMbx6c3Ht9lujOFnMz+ksLyuzb7EGAcnjR5ISVUDxVX1lFQ1UFIdeEBFI5vAoH7xJMU6SIpxWs+x1nNyrIMXPttCRV3b2lZGUgyv/uEo4lx2Yh12Yl02XHZbwBuGO/M5QN8IWloDUkpFRFdqTsHm37thwsiAx4sIN528f8A0fzntwDbnMsZQUevh4LsD17R8xlrQsLLOQ0Wtm60lNVTWuams81DV4Anar7Wjsp7jHv6oxTabQKzTTp3bS+tKWuMsFzsr6+mX4KJfoov0BBdp8S7SE128t2Z7j9W09pRApzWgILQGpFT49MSPaKg1LQCfz3D0A4FrW/3infz5V6OodXupbfBS7/FR2+Cl1u1lzv82d3DFnRfvsnP2+MHEu+zEuxz+Z+v1qrxSXvhsKw2enhnAEY7ApYMQwqBLAWj1q/DB3VCeBym5cMIdMPasyBRQKdVCd5rFwtesGMs704+ltLqBkuoGdlU3NL1+YHHwtagSYxxUt1Mba02AjOQYkmOdJMc5SYlzkhzrIDnOyZtf51NZ37ZJsX+iixd+N54Yh40Yh51Yp/Uc47SaFheuKgjLyENtgouG1a/C21eD2/+lLN9mvQcNQkr1gK40D3Y1XfBmxf1J8QeEof0TWqT557LAa1E11tCMMdR7fFTXe6hp8FLT4OXkxz4OOoDjuP0yqKhzU1HnZkdlHRt3eKiocwcMPgDFVQ386vH/tftZtBbp1YI1AIXLB3fvDj6N3LXWdg1ASvWIUEcDdjVdJPrCRIRYp51Yp510//72Rh0+cObYgOc5euYH5Je1bVJMT3Ax89djqfd4qXP7qPd4qXf7qPdYrx97f0PA/AoCnD9cNACFS3mQO8vLt8HCP8Lgo2DwkZA2DKTVFCfadKfUHqc3BK3AaQIP4Lj9V6M4cdTAoOn+vTwvyOS5ce1eV3doAAqXlFwr2LTmiIXvF8DXL1rvEwdagagxIO1YB4uu0aY7pfqAnghaXW2K7Eqw6y4dhBBEyIMQWvcBATjjYPJsOPBM2PkD/PQ5/LQMti2Dsp/8BwkEauVNGQTXftedS1BKqZDoKLheIuKj4MrzrUD02kXB8zvxbsg+FLIPhpikrp9LKaV6iI6Ci5JFiQnMGpRNUT8bmQmZTE9MYFKwg1NyIOXX8N87AzfdiR3+e0fjG+i/H+QcagWk2l3wv8fAo812Sqk9lwagMFm0aREzPptBndcafVJYXciMz2YAMGmfoGHIqrkEa7rb93goWAn5X0PB17DxA1j1SuB83LVWMBvzm7aDHBpprUkp1YtoAAqTWV/Pago+jeq8ddzz+T1Uu6sZnDyYoclDyYjPwCa23QeNPYtFu75l1qY3KbJBpg+m73M6kxoDw4gTrQeAMVCRD4+ODlyIygJ4cBhkjIKMA/yPUTBgf9j4vt6npJTqVSIegETkZGAWYAeeM8bMbLU/BngROAwoAaYaY7b4990CXAx4gauNMUvay1NEhgHzgXRgBXCeMaZBRC4EHgLy/ad9whjzXDivs6i6KOD2ak819yy7p+l9rD2WQcmDGJo8lCHJQyitK+Xtbe/QYLdqLYV2mJG3GDYd2bbmJGLVXFIGschTwqy0VIocdjI9XqaXljHJ64JRp8KOtbD631Bf3iytDYyvZX56n5JSKooiGoBExA48CZwI5AFfichCY8z3zQ67GCg1xgwXkWnAA8BUERkFTANGA9nA+yKynz9NsDwfAB41xswXkb/78/6bP82/jDFXRepaMxMyKawubLM9KyGLF095ka0VW1s8NpRuYOlPS/GYtnct13nruPOzO1m+fTkD4gbQP65/02NA3AC+POhU/rJ1AXX+JZMLnQ5m9E+HYacz6Th/sDMGKgqsYLTje/jv7SxKiG8btMq3wSvnwMBRu2tM6cPB7rTy0WY7pVSERLoGNB7YaIzZBCAi84FTgeYB6FRghv/1a8ATIiL+7fONMfXAZhHZ6M+PQHmKyFrgeOAc/zFz/fk2BqCImn7o9BZ9QGDVdqYfOp3MhEwyEzI5IuuIFmk8Pg+HvnQoJsAw7HpvPR/+9CGldaUB92Nr2c9TZxPuKfgvO7/bl5SYFNJi00iNSSUlY19SBx3G/755hrvjDXU2q/nPClr9wO5iUslGWL8YjH/8v81pDXpwJbCobC2zUpMoSsu1gtb7N1gDK9oLQhq0lFKdEOkAlAM0H+KVBxwR7BhjjEdEyrGa0HKAZa3SNg5ID5RnOlBmTFOVovnxAL8WkWOB9cC1xpg2Q89E5FLgUoDBgwd38hItjc1ls76eRVF1kTUK7tDp7Q5AcNgc7dac3jvzPdw+N7tqd1FcV0xxTTHFtcXM+HxGwPyq3dX8dcVfA58sUbDuOdqtzmbjvowMEv7fg2TF9COzvprkkq3IzrWwYy2LCj9lRnpqy6CVlgjvXcekb+ZBcjYkZUJS1u5H3nIWfXYfs5LjQwtaSqk+p68MQngbeMUYUy8if8CqHbWZn90Y8wzwDFj3AYV6kkn7TGp/xFsA7dWcAJw2JwMTBjIwYSCNE0Q9vfrpoEHr9SmvU1ZfRnl9eYvnmV/ObHM8QIW3jj9++Mem93GOOLISssjKyOLrht3Bp1GdzcajaUlMrC9HNq2HyqLdNSdgUUI8M/r3axu0lt7KpJRc6LePNRtEgJF6iz66ve1gjOPuaXOcUmrvEOkAlA8MavY+l90DAVofkyciDiAFazBCe2kDbS8BUkXE4a8FNR1vjClpdvxzwIPduKaw6krNqb2gleRKIsmVxKCkQS3SzF0zN2DQGhg/kEePe5TC6kIKqwspqi6iqLqIwupCaoMM597ucHCIlJKc1J9k1zBSHPEk21wkY+ejnSsCBq2HEl0MeflUYo0h1h5LbMpg4tOGEtNvOPb0fVmU/zEzSr6grvlgjM1vWp9RO0FIg5ZSe66IzoTgDyjrgROwgsFXwDnGmDXNjrkSGGOMucw/COEMY8xZIjIamIfV75MNfACMwGpHCpiniPwbeL3ZIITVxpinRCTLGFPoP9/pwE3GmCPbK3tvX5Bu0aZFIQWt1vcpgRW0ZvxsRtB0J807hkJ3eZvtyfZYpo46j4qGCsrryymvL296nVe5Lfh9SEG4fAa3gAmQLtHn45qhp9I/dSjp6fuTnjqU9Lj+xDvjWfTR7czY/GbTYAyAWJ9hxjANQkpFS6+aikdEJgKPYQ2Zft4Yc6+I3A0sN8YsFJFY4CXgEGAXMK3ZAIPbgIsAD3CNMebdYHn6t++DNQy7H7ASONff7HY/MMWfzy7gcmNM8NWh6P0BqCu6FLT+dzt1xt20LVaczDjmnpCDVrojgbuOfYBaby11nrqmR62nhrrqnTy/4d+BA5cxAbfHYaPBePEG2NffZ1jw289IdiUHvq4u1JpC/eyU6qt6VQDaU+2NAagreiJoAZz0/IEU2tsGkyyv4eUTnqK4+AdKSjdRUpFHcU0RJXWlvOSob7e2lWRzkRObTk5iLjlpI8hJGULB5qXM3/459SHUmrp6TY1pQw1cvT3Y9fbyqejSABQGGoC6rks/ul1oTgsWtNK8Xi6q8ZFn6sh3OMh3OChw2Klv1TfVnN0YBiUPxmmPwWl34bQ5cdqcuOwuVhR+SX2A+7WS7DFMH3cDCa4EEp2JJDgTSHDufv1J/ifc+9ndIQWurjSVNqbriUDX1fKpvkMDUBhoAOp5oTaNdRi06ipg1ybYtQlTspGSkvX8omJZ0Ka+CdU1uEVw2xy47f6Hzc5qGkLu12qPDSE1Ni3gvrK6Mnz42myPscdw3KDjmoJb07MrkR92/cDr61+nwdfQ4vjrDruOicMm4rQ7cdlcOGwOxH8dHQUSr89Lg6+BBm8DdZ46GrwN1Hvr+f1/f09xbXGb8jXeNhDM3lgTVIFpAAoDDUB7hlCDVtCmPo+P9w6cDnXlUFdmPWrLoK6ckzw/UuhsO2A00+PhlYIiqsRGtU2otjupik2iOiaRqph47pOyoMHurJFn0fq+LIBX178atOxDk4dS7a6myl1FraftypWd0Virq3HXBLzBWRDsNjseX9saX0eyErJIjUltugk6LTaNtJg08irzWLR5EW5fs5pgB7WmnqwJdjXd3pYmXDQAhYEGoL1TV5r6Fj15IDOazSJhpfExo9LDpAmPQc0ua4mMml1QU+J/XcpJ3k0BA1eW28N7hSXWjbwpudYjOQdScjhp7d8p9LUNLlnOFN47539N7z0+DzWeGqobqpnw+oTAs2UAN4+/GbfXTYOvAbfPTYPXen7p+5eCfkaXjLkEl91FjD2GGHtMi9f3LruX0vrSNmkSHAmcMOQEyurLKKsro7S+lNK6UqrcVUHPA9ZtACkxKdasHTEp1sOVwqvrX6WyobLN8f3j+vP3X/4dp82Jw+ZoejhtTj746QMe+PKBLgWtUIPd3pamedruBi4NQGGgAWjvFfIouNWvsuj9G6zZHRrn0auoYdIvH2p3doeggau8jkmjzrGmKqrItxYnrCwE421zI29Tml2VTMo+BuLSIC7V/2w9TvpmJoXejoNWc8FGK7aXBkIfkOH2ujnsn4cFDZCnDT+NsvoyKuormm6cLq8vDzhHYnc4bU5sYmuaid4mNmzYEBEqGyoDli/GHsOxuccS54gjwZlAvCOeeGc8Cc4E/rbqb5TXt/38Ep2JnD7idKoaqqhyVzU9VzZU8lPlT/haTwiMVetMjknGZXPh8vc/uuwuXDYX60rXtag5Nr+eA/odgNvnxu1z4/F5ml4X1xQHbMaNc8Rx7gHnkpWYRWZ8JlkJWWQmZJLoSgTC17+nC9Ip1Y5Jx90T2n1CY89iEjCp+fx2HQQfgEk/vwM6G7i8HqjazqRHRwO72k4aW10DZVuhcBXUloK7uinp9CBBa3r+JnhkNLgS2jymF+UxIy2hbZrinVD0rT+49bPWpmrWjDipqhqKS1pdU4W1PQCn3dnudFP3HN3238EYw0mvnURRTdsZ5tNi0rj9qNvx+DxNj8Yf3mCzfQCcP+p8fPgwxuAzvqZA4DM+5v0wL2Caem89m8o2UeOpsWqb7uoOmyar3FW8tv41kpxJJLoSSXQlkuxKJjsxmy0VWwKmMRhOGXpKUw21se+tsdYaiNvnJtGV2DRYprEW6LA5eHPjmwHT1Hpqef675/E2m7kEIMmZRGZiJj9V/ES9t77FvjpvHbO+nhWx5jsNQEp1xtizQp/LLpTAZXf4V8nNZVL5NivgNJcyCC7/dPd7T73VR1VbyqSnjiRo0Dr4NGiogoYaaKi2ZkhvqGZSRSl46wOn+fsxzcoV06K2RcFKJnlqmVRR1rJ8794Ezvi2wc6ZwPS0w5hR+XabZs/p/VtPC2kREa457JqANa2bxt/EiUNODJgu2GwfWQlZXHPYNQHTACzdtjRourdOe6vFNrfXTY2nhjMWnMGO2h0B0wQbjLF65+qg57ntyNsCpjnptZOCpnn6xKcDpllWuCxomnfOeIfi2uKm2U6aP28o3RAwv2BLzYSDBiClIinUwBVshdwT7mh5nCMGkgZaj/aC1mlPBT7PowcGTpMwACb91apltXmU7V4GvrXaXfCv3wbcNQkg0FIg+c9AcT7EpliPmOSm15MKV8HOYmalJHSqpgUwvf8RzKhs278XLNA1pTt0esBg1zgfY3NOu5MUewrXjbuu02m6cp5upwkyVVfjBMiZCZkczMEt0gULdpkJmUHP1V0agJTqTRqDVSjLWXQ2aHUmzYT7rEUNg3n0QGs13daSsuCcV61aVkO11UTY+Pqd65lUXdM22IG15HxdhTX6sFVz0yRgUmWrfpY3fg+L/uSvbcWDM8H/HM+kn5ZBjLQNdNvnQvxgcMRa1+iI9b+OBUcck/LXQXExs5I7H+xCbYrs0TT7TIKflrXs5xxycofNaF0Jdt2lgxCC0EEIao/SlTWYupomUOCaPDt42mBBK2UQXPud9doY8NT5h8GXw5NHQJCBCxxxmT/I1VhNi+5q6zk/Av9fbU6rtml3+Z+dVrNk6ZY2AROwAtuIE8HmsNLaHFbzqs1hfXYNAUYFxqTAMdeAzW4dJ3b/a7v171PbdtQhCRlw3htWIHbG+R/xVjm//Xfo/0bQ5cE2rekouDDQAKRUEKEGrkgFrc6mSc6BS//Paj5017V89tTDvHbKfsy14GkAb711rNdtvV4TuKMfsFYV9nmsY31e67XPDdU7g6cJF7FZwTzgIpZ2SM619htf20ftLuu5tfY+80BF0FFwSqmICbVfK9rNir+cAYkDgqdLGRQ82P1yRuA0ecuDp7ni88BpggbVXLhqhbWuls/jD1r+18/+whqi31pCf/jVY9a1umtaPn/8UODz+7ww+CgrSInNGt3Y9NoGy+cETleeF3h7GGgAUkpFXk8Era6kgfAGuy6ludPqjwrkxLuD9NXdDwdMDpxm1fzgwfGMwCPnANjwXvAAGSEagJRSvVMXh753KQ1EPtj1VJquBMfupOsG7QMKQvuAlFJ7rK4MMOlOumZ0EEIYaABSSqnQhRKAgi+QopRSSkWQBiCllFJRoQFIKaVUVGgAUkopFRUagJRSSkWFjoILQkR2AluB/kBxlIvTG+jnYNHPYTf9LCz6OVgaP4chxph2pp7YTQNQB0RkeWeHFO7N9HOw6Oewm34WFv0cLF35HLQJTimlVFRoAFJKKRUVGoA69ky0C9BL6Odg0c9hN/0sLPo5WEL+HLQPSCmlVFRoDUgppVRUaABSSikVFRqA2iEiJ4vIOhHZKCI3R7s80SIiW0TkWxH5RkT6zBThIvK8iOwQke+abesnIv8VkQ3+57RolrEnBPkcZohIvv878Y2ITIxmGXuCiAwSkaUi8r2IrBGR6f7tfeo70c7nEPJ3QvuAghARO7AeOBHIA74CzjbGfB/VgkWBiGwBxhlj+tTNdiJyLFAFvGiMOdC/7UFglzFmpv+PkjRjzE3RLGekBfkcZgBVxpiHo1m2niQiWUCWMeZrEUkCVgCnARfSh74T7XwOZxHid0JrQMGNBzYaYzYZYxqA+cCpUS6T6kHGmI+BXa02nwrM9b+ei/Ufb68W5HPoc4wxhcaYr/2vK4G1QA597DvRzucQMg1AweUAzRdIz6OLH/JewADvicgKEbk02oWJsoHGmEL/6yJgYDQLE2VXichqfxPdXt3s1JqIDAUOAb6gD38nWn0OEOJ3QgOQ6oxjjDGHAqcAV/qbZPo8Y7Vf99U27L8B+wIHA4XAX6Namh4kIonA68A1xpiK5vv60nciwOcQ8ndCA1Bw+cCgZu9z/dv6HGNMvv95B/AmVvNkX7Xd3wbe2Ba+I8rliQpjzHZjjNcY4wOepY98J0TEifWj+7Ix5g3/5j73nQj0OXTlO6EBKLivgBEiMkxEXMA0YGGUy9TjRCTB39GIiCQAJwHftZ9qr7YQuMD/+gJgQRTLEjWNP7h+p9MHvhMiIsAcYK0x5pFmu/rUdyLY59CV74SOgmuHfxjhY4AdeN4Yc290S9TzRGQfrFoPgAOY11c+BxF5BTgOa5r57cCdwFvAq8BgrOU6zjLG7NUd9EE+h+OwmloMsAX4Q7N+kL2SiBwDfAJ8C/j8m2/F6v/oM9+Jdj6HswnxO6EBSCmlVFRoE5xSSqmo0ACklFIqKjQAKaWUigoNQEoppaJCA5BSSqmo0ACkVA8TEW+zGYO/CedM6yIytPms1Ur1Zo5oF0CpPqjWGHNwtAuhVLRpDUipXsK/7tKD/rWXvhSR4f7tQ0XkQ/8kjx+IyGD/9oEi8qaIrPI/fubPyi4iz/rXanlPROL8x1/tX8NltYjMj9JlKtVEA5BSPS+uVRPc1Gb7yo0xY4AnsGbhAHgcmGuMGQu8DMz2b58N/J8x5iDgUGCNf/sI4EljzGigDPi1f/vNwCH+fC6LzKUp1Xk6E4JSPUxEqowxiQG2bwGON8Zs8k/2WGSMSReRYqwFwNz+7YXGmP4ishPINcbUN8tjKPBfY8wI//ubAKcx5i8ishhrYbm3gLeMMVURvlSl2qU1IKV6FxPkdSjqm732sruvdxLwJFZt6SsR0T5gFVUagJTqXaY2e/7c//ozrNnYAX6LNREkwAfA5WAtIS8iKcEyFREbMMgYsxS4CUgB2tTClOpJ+heQUj0vTkS+afZ+sTGmcSh2moisxqrFnO3f9kfgHyJyA7AT+J1/+3TgGRG5GKumcznWQmCB2IF/+oOUALONMWVhuh6lukT7gJTqJfx9QOOMMcXRLotSPUGb4JRSSkWF1oCUUkpFhdaAlFJKRYUGIKWUUlGhAUgppVRUaABSSikVFRqAlFJKRcX/B0Efh9rdOT2KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(avg_val_losses_lr)):\n",
    "    #plt.subplot(2, 1, 2)\n",
    "    plt.plot(epoch_list, avg_val_losses_lr[i], '-o', label=learning_rate[i])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('avg_val_loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loss is too big when learning rate == 0.01. So remove and redraw graphs.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEGCAYAAACgt3iRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAApMklEQVR4nO3deXxU5dn/8c+VhSQsIexCguxlRxQEsTzUWhWtC9Td+rjUBcWli60t9mdbqvYRa338/Vq1irtUq9YFqRsuiFpANgERkH1L2MIS1gSyXL8/ZoIhTGBCMpnMzPf9es0rM/ecc3LNeQ25uM99n+s2d0dERKQmkqIdgIiIxD4lExERqTElExERqTElExERqTElExERqbGUaAdQV1q2bOkdO3aMdhgiIjFj7ty5W929VTjbJkwy6dixI3PmzIl2GCIiMcPM1oa7rS5ziYhIjSmZiIhIjUU8mZjZ2Wa21MxWmNmYEO+nmdkrwfdnmlnHYPsgM5sffCwwsx9V2GeNmS0MvqdrVyIiURbRMRMzSwYeBc4EcoHZZjbJ3RdX2Ox6YIe7dzWzy4EHgMuAr4GB7l5iZm2BBWb2b3cvCe73fXffGsn4RSRxFBcXk5ubS1FRUbRDqXPp6enk5OSQmpp6zMeI9AD8IGCFu68CMLOXgRFAxWQyAhgbfP4a8IiZmbvvq7BNOqAiYiISMbm5uTRp0oSOHTtiZtEOp864O9u2bSM3N5dOnTod83EifZkrG1hf4XVusC3kNsFex06gBYCZDTazRcBC4OYKvRIHPjCzuWY2qqpfbmajzGyOmc3Jz8+vdvAT5+Xx3XFT6DTmHb47bgoT5+VV+xgiEhuKiopo0aJFQiUSADOjRYsWNe6R1esBeHef6e69gZOBu8wsPfjWUHc/CTgHuNXMhlWx/3h3H+juA1u1Cmuq9EET5+Vx1xsLySsoxIG8gkLuemOhEopIHEu0RFKuNj53pJNJHtC+wuucYFvIbcwsBWgKbKu4gbsvAfYAfYKv84I/twBvEricVqsenLyUwuLSQ9oKi0t5cPLS2v5VIiIxL9LJZDbQzcw6mVkD4HJgUqVtJgHXBJ9fDExxdw/ukwJgZh2AHsAaM2tkZk2C7Y2AswgM1teqDQWF1WoXEamp6667jtatW9OnT59q7zt37lz69u1L165d+elPf0r5WlVjx44lOzub/v37079/f959993aDhuIcDIJjnHcBkwGlgCvuvsiM7vHzC4IbvY00MLMVgB3AOXTh4cSmME1n0Dv45bg7K02wH/MbAEwC3jH3d+v7djbZWVUq11EEkskxlSvvfZa3n//2P6cjR49mieffJLly5ezfPnyQ47zi1/8gvnz5zN//nx++MMf1jjOUCJeTsXd3wXerdT2+wrPi4BLQuw3AZgQon0VcELtR3qoO4d35643Fh5yqSs9NYk7h3eP9K8WkXqufEy1/O9D+ZgqwMgTK88xCt+wYcNYs2bNIW0rV67k1ltvJT8/n4YNG/Lkk0/So0ePQ7bZuHEju3bt4pRTTgHg6quvZuLEiZxzzjnHHEt1JUxtruoq/0I8OHkpG4KD8Cd3bF6jL4qIxIY//nsRizfsqvL9eesKOFBadkhbYXEpv37tK/45a13IfXq1y+QP5/eudiyjRo3i8ccfp1u3bsycOZNbbrmFKVOmHLJNXl4eOTk5B1/n5OSQl/dtT+mRRx7hhRdeYODAgTz00EM0a9as2nEcTb2ezRVtI0/MZtqY01k97lyuOqUD01duY9nm3dEOS0SirHIiOVr7sdqzZw/Tp0/nkksuoX///tx0001s3LixWscYPXo0K1euZP78+bRt25Zf/vKXtRpjOfVMwnTHmd9h0oIN3Pv2Yl64blDCTiEUSQRH60F8d9wU8kJMxsnOyuCVm4bUWhxlZWVkZWUxf/78Q9pLS0sZMGAAABdccAGjR48mNzf34Pu5ublkZweuorRp0+Zg+4033sh5551Xa/FVpJ5JmJo1asAvzujG58u38tGSLdEOR0Si6M7h3clITT6kLSM1udbHVDMzM+nUqRP/+te/gMDd6gsWLCA5OfnggPo999xD27ZtyczM5IsvvsDdeeGFFxgxYgTAIT2ZN99885hmioVDyaQarjylA91aN+a+dxazv6T06DuISFwaeWI291/Yl+ysDIxAj+T+C/vWeEz1iiuuYMiQISxdupScnByefvppXnzxRZ5++mlOOOEEevfuzVtvvRVy38cee4wbbriBrl270qVLl4OD77/+9a/p27cv/fr145NPPuHhhx+uUYxVsfK5yPFu4MCBXhuLY32+PJ+rnp7FmHN6cPP3utRCZCJSHyxZsoSePXtGO4yoCfX5zWyuuw8MZ3/1TKrpv7q14oyebfjbx8vZsjvxqouKiISiZHIM7j63JwdKy3jwfZVWEREBJZNj0rFlI64b2ol/zc1lwfqCaIcjIrUkUS77V1Ybn1vJ5Bjd9v2utGycxh//vShhv4Ai8SQ9PZ1t27Yl3L/n8vVM0tPTj77xEeg+k2PUJD2VX5/dnV+/9hWTFmxgRH/dGS8Sy3JycsjNzeVY1j6KdeUrLdaEkkkNXHxSDhNmrOX+d7/hzF5taNhAp1MkVqWmptZopcFEp8tcNZCUZIy9oBebdhXx+NSV0Q5HRCRqlExqaECH5ozo344nPlvF+u37jr6DiEgcUjKpBWPO6UGSGePe+ybaoYiIRIWSSS1o2zSD0ad14Z2FG/li1baj7yAiEmeUTGrJqGGdyc7K4I//XkxpWWJNLRQRUTKpJempyfz2hz1ZsnEXA+79sFaX8hQRqe80l7UWHSgpJcmgoLAYqL2lPEVE6jv1TGrRXz5YRuUrXIXFpTw4WTW8RCS+KZnUog0hVl47UruISLxQMqlF7bIyqtUuIhIvlExqUailPFOSrNaX8hQRqW80AF+LygfZH5y8lA0FhaSnJrO/pJSebTOjHJmISGRp2d4I2rZnP2c+/Bntm2Xw+uhTSUlWR1BEYoeW7a0nWjROY+wFvVmQu5Nnpq2OdjgiIhGjZBJh5/dryxk92/DQB8tYvXVvtMMREYkIJZMIMzP+9KM+NEhJ4jevf0WZSq2ISBxSMqkDbTLTufvcnsxavZ0XZ62LdjgiIrVOyaSOXDqwPUO7tmTcu0vI002MIhJnlEzqiJlx/4V9KXP47RsLSZRZdCKSGJRM6lD75g359dnd+XRZPm+qmrCIxBElkzp2zZCODOjQjHveXkz+7v3RDkdEpFYomdSxpCTjgYv6se9AKX+Y9HW0wxERqRVKJlHQtXVjfvaDbry7cBPvf70x2uGIiNSYkkmUjBrWmd7tMrl74iIK9h2IdjgiIjWiZBIlqclJ/PnifhTsO8C9by+JdjgiIjWiqsFR1LtdU27+Xhce+WQFU5duYfveA7TLyuDO4d21zK+IxJSI90zM7GwzW2pmK8xsTIj308zsleD7M82sY7B9kJnNDz4WmNmPwj1mLOnYoiEGbNt7AOfbdeMnauqwiMSQiCYTM0sGHgXOAXoBV5hZr0qbXQ/scPeuwMPAA8H2r4GB7t4fOBt4wsxSwjxmzHj4o+VUvn1R68aLSKyJdM9kELDC3Ve5+wHgZWBEpW1GAM8Hn78G/MDMzN33uXtJsD0dDv7NDeeYMUPrxotIPIh0MskG1ld4nRtsC7lNMHnsBFoAmNlgM1sELARuDr4fzjEJ7j/KzOaY2Zz8/Pxa+Di1T+vGi0g8qNezudx9prv3Bk4G7jKz9GruP97dB7r7wFatWkUmyBoKtW68Abef3jU6AYmIHINIJ5M8oH2F1znBtpDbmFkK0BTYVnEDd18C7AH6hHnMmDHyxGzuv7Av2VkZGNCycQMc+Gx5vopBikjMiPTU4NlANzPrROAP/uXAjyttMwm4BpgBXAxMcXcP7rPe3UvMrAPQA1gDFIRxzJgy8sTsQ6YCP/HpSu5/7xue/HwVo4Z1iWJkIiLhiWgyCSaC24DJQDLwjLsvMrN7gDnuPgl4GphgZiuA7QSSA8BQYIyZFQNlwC3uvhUg1DEj+Tnq2qhhnVmQW8C4976hT7umnNq1ZbRDEhE5IkuUSykDBw70OXPmRDuMsO3ZX8LIR6exfe8B3r59qAbkRaTOmdlcdx8Yzrb1egA+kTVOS+GJqwZwoKSM0f+YS1FxabRDEhGpkpJJPdalVWMeuvQEFuTuZOykuLqSJyJxRsmknhve+zhu/X4XXp69nn/OWhftcEREQlIyiQF3nNmd/+rWkj+8tYj56wuiHY6IyGGUTGJAcpLx18tPpHVmGqP/MZete7Tcr4jUL0omMaJZowY8/t8D2L73ALe/NI+S0rJohyQicpCSSQzpk92UP/2oLzNWbVNVYRGpV7Q4Voy5eEAOC9YX8MRnqygqLuWjJVvYUFCoRbVEJKrUM4lBvzuvFx2aZ/D8jLXkFRRqUS0RiTolkxjUICWJ/SWHVy7QoloiEi1KJjFq866ikO1aVEtEokHJJEZpUS0RqU+UTGJUqEW1GiQncefw7lGKSEQSmWZzxajyWVsPTl7KhoJCkpOM1GRjUKfmUY5MRBKRStDHiRVb9jDy0Wl0bd2YV246hbSU5KPvJCJyBCpBn4C6tm7Mgxf3Y/76Au57e0m0wxGRBKNkEkfO6duWm4Z1ZsIXa3l9bm60wxGRBKJkEmfuHN6dUzo357dvLmTxhl3RDkdEEoSSSZxJSU7ib1ecRFbDVG7+x1x27iuOdkgikgCUTOJQqyZpPHblADbuLOSOV+dTVpYYkyxEJHqUTOLUgA7NuPvcXnz8zRYem7oi2uGISJxTMoljVw/pwMj+7Xjow2V8tiw/2uGISBxTMoljZsb/XNiX77Ruwk9fnkfujn3RDklE4pSSSZxr2CCFx68aQGmpc8uLX1JUXBrtkEQkDqmcSgLo1LIRD116AqMmzOUnz85i3fZCLaglIrVKySRBnNX7OM7o2ZqPlmw52Fa+oBaghCIiNaLLXAlk8cbDb2LUgloiUhuUTBLIxgItqCUikaFkkkCqWjjruKbpdRyJiMQbJZMEEmpBLYCS0jKWhLgEJiISLiWTBDLyxGzuv7Av2VkZGJCdlcFt3++CmTHy0Wm8Omd9tEMUkRilxbGE/N37+fkr85i2YhsXD8jh3hF9yGigxbVEEp0Wx5JqadUkjReuG8xPf9CN17/MZeSj01ixZU+0wxKRGBJWMjGzS8ysSfD53Wb2hpmdFNnQpC4lJxl3nPkdnv/JIPL37GfEI/9h0oIN0Q5LRGJEWJe5zOwrd+9nZkOB+4AHgd+7++BIB1hbdJkrfBt3FnL7S/OYs3YH/33K8fTPyeLhj5brrnmRBFOdy1zh3gFfXtDpXGC8u79jZvcdU3RS77VtmsE/R53Cg5OXMv6zVbxo6yj/P4fumheRUMIdM8kzsyeAy4B3zSytGvtKDEpNTuK3P+xJ80YNqNx51V3zIlJZuAnhUmAyMNzdC4DmwJ2RCkrqjx17D4Rs113zIlJRuMmkLfCOuy83s9OAS4BZ4exoZmeb2VIzW2FmY0K8n2ZmrwTfn2lmHYPtZ5rZXDNbGPx5eoV9pgaPOT/4aB3m55Bqququ+araRSQxhZtMXgdKzawrMB5oD7x0tJ3MLBl4FDgH6AVcYWa9Km12PbDD3bsCDwMPBNu3Aue7e1/gGmBCpf2udPf+wccWJCKqumv+4gEaLxGRb4WbTMrcvQS4EPibu99JoLdyNIOAFe6+yt0PAC8DIyptMwJ4Pvj8NeAHZmbuPs/dy+emLgIygmM1Uocq3zV/XGY6LRs34Jn/rGFh7s5ohyci9US4s7mKzewK4Grg/GBbahj7ZQMVa3TkApWnEx/cxt1LzGwn0IJAz6TcRcCX7r6/QtuzZlZKoNd0nyfKrfxRMPLE7ENmbm0oKOSSx2dw1TMzeWXUELof1ySK0YlIfRBuz+QnwBDgT+6+2sw6cfhlp4gws94ELn3dVKH5yuDlr/8KPq6qYt9RZjbHzObk5+dHPtgE0S4rg5duHExaShJXPjWTVfm6W14k0YWVTNx9MfArYKGZ9QFy3f2Bo+wGkEdgfKVcTrAt5DZmlgI0BbYFX+cAbwJXu/vKCvHkBX/uJjB2M6iKuMe7+0B3H9iqVaswwpVwdWjRiBdvGIy7c+VTM1m/fV+0QxKRKAq3nMppwHICg+mPAcvMbFgYu84GuplZJzNrAFwOTKq0zSQCA+wAFwNT3N3NLAt4Bxjj7tMqxJJiZi2Dz1OB84Cvw/kcUru6tm7ChOsHs3d/CVc+NZNNO0MvviUi8S/cy1wPAWe5+/fcfRgwnMDMqyMKDtrfRuAelSXAq+6+yMzuMbMLgps9DbQwsxXAHUD59OHbgK7A7ytNAU4DJpvZV8B8Aj2bJ8P8HFLLerXL5PnrBrFtz36ufOoLtu7Zf/SdRCTuVKs219Ha6jPV5oqsmau2cc2zs+jUsjH/vHEwWQ0bRDskEamhSJSgn2NmT5nZacHHk4D+MstBgzu3YPxVA1m5ZQ/XPDub3UXF0Q5JROpQuD2TNOBWYGiw6XPgsUpTdes19UzqxgeLNjH6xS/p0LwhRcWlbNxZpErDIjGq1qsGB5PG/wYfIlU6q/dx/Hjw8UyYsfZgmyoNi8S/IyYTM1sIVNl1iaUxE6k7U5YcXt2mvNKwkolIfDpaz+S8OolC4kpVFYVVaVgkfh0xmbj72iO9X87MZrj7kNoJSWJdu6wM8kIkjuOapkchGhGpC7W1wJX+SshBVVUaxp383TEzZ0NEqqG2komKLMpBlSsNZ2dlcPP3OlNQWMIlj08nd4dKr4jEm7CmBh/1IGZfuvtJtRBPxGhqcPTNXbuda5+dTeO0FCZcP5iurRtHOyQROYJI3LR41N9ZS8eRODagQ3NeGTWE4tIyLn1iBl/naT0UkXhRW8kkZAl4kcp6tcvk1ZuGkJ6SxBXjv2DW6u3RDklEasERk4mZ7TazXSEeu81sV/l27q6qvRK2zq0a89roU2mVmcbVz8zkk6VadVkk1h0xmbh7E3fPDPFo4u6ZdRWkxJ92WRm8etMQOrdszI3Pz+HtrzYcfScRqbfCXbYXgGAJ+IPTgN19Xa1HJAmjZeM0/jnqFK5/bja3/3Meny3LZ9qKbWwoKFQ9L5EYE+7iWBeY2XJgNfApsAZ4L4JxSYJompHKhOsH071NE16dk0teQSHOt/W8Js6rvDCniNRH4Q7A3wucAixz907AD4AvIhaVJJSMBsnsKjy8ZH15PS8Rqf/CTSbF7r4NSDKzJHf/BAhr7rFIODZWseSv6nmJxIZwx0wKzKwxgXVMXjSzLcDeyIUliaaqel7tsjKiEI2IVFe4PZNPgKbAz4D3gZXA+ZEKShJPVfW8hnRpEYVoRKS6wk0mKcAHwFSgCfBK8LKXSK2oXM+rXdN0erVtwutf5vLmvNxohyciR1Gt2lxm1g+4DLgIyHX3MyIVWG1Tba7YU1RcyrXPzmL2mh08duVJDO99XLRDEkkokazNtQXYBGwDWlc3MJHqSE9N5qlrTqZPdlNuf2ke/1m+NdohiUgVwr3P5BYzmwp8DLQAbtSSvVIXGqel8PxPTqZzq0bc+MIc5q5VLS+R+ijcnkl74Ofu3tvdx7r74kgGJVJRVsMGvHD9INpkpnHts7NVbVikHgormbj7Xe4+P8KxiFSpdZN0/nHDYJqkpXDNM7NYsWVPtEMSkQpqqwS9SMTlNGvIP24YjBn891MzWb9dKzaK1BdKJhJTOrdqzITrB7PvQAlXPjWTzbtC3zkvInVLyURiTs+2mTx33SC27tnPVU/P5MUv1vLdcVPoNOYdvjtuiopDikSBkonEpJOOb8ZTVw9k5ZY93P3W16o2LBJlSiYSs07t2pKmDRtQ+b5bVRsWqXtKJhLTduw9ELJd1YZF6paSicS0qqoKN0pLYctuDc6L1BUlE4lpoaoNJxvs2V/C0Ac+4XcTv9YUYpE6UK014EXqm/I14h+cvPSQteNPaJ/FE5+u5OXZ63hp1jpGnNCO0ad1oVubJlGOWCQ+VatqcCxT1eDEtHFnIU99vpqXZq6jsLiUs3q14dbvd2X11r2HJaDyxCQiAdWpGqxkIglh+94DPDd9Dc9NW82uohKSDMoqfPUzUpO5/8K+SigiFUSyBL1ITGreqAF3nPkdpt/1AzLTUw5JJKDpxCI1pWQiCaVxWgq7i0pCvqfpxCLHTslEEk5V04kduPftxRTsC33viohULeLJxMzONrOlZrbCzMaEeD/NzF4Jvj/TzDoG2880s7lmtjD48/QK+wwItq8ws7+amUX6c0j8CDWdOD0liVM6NefZaasZ9udPGP/ZSoqKS6MUoUjsiWgyMbNk4FHgHKAXcIWZ9aq02fXADnfvCjwMPBBs3wqc7+59gWuACRX2+TtwI9At+Dg7Yh9C4s7IE7O5/8K+ZGdlYEB2VgbjLurHyzcN4d2f/RcnHt+M/3n3G8743095a34eZZUHWETkMBGdzWVmQ4Cx7j48+PouAHe/v8I2k4PbzDCzFAJrzLfyCoEFex7bgLZAc+ATd+8RfO8K4DR3v+lIsWg2l1THf5Zv5X/eXcLijbvol9OU3/6wJ5t2Fmk6sSSU6szmivRNi9nA+gqvc4HBVW3j7iVmtpPAOvNbK2xzEfClu+83s+zgcSoeM+S/aDMbBYwCOP7442vwMSTRDO3WkrdvH8qb8/L4ywdLuXz8F4dMJy6vTgwooYgQAwPwZtabwKWvI/Y8QnH38e4+0N0HtmrVqvaDk7iWlGRcNCCHT351mqYTixxFpJNJHtC+wuucYFvIbYKXuZoSuKSFmeUAbwJXu/vKCtvnHOWYIrUmPTVZ04lFjiLSyWQ20M3MOplZA+ByYFKlbSYRGGAHuBiY4u5uZlnAO8AYd59WvrG7bwR2mdkpwbGUq4G3Ivw5JMFVNZ24VZO0Oo5EpH6KaDJx9xLgNmAysAR41d0Xmdk9ZnZBcLOngRZmtgK4AyifPnwb0BX4vZnNDz5aB9+7BXgKWAGsBN6L5OcQCTWdGGB3UTHTV24NsYdIYlFtLpEwTZyXd8hsruuGduTlWetZvXUv943sw+WDNMlD4osKPYagZCKRsKuomNtemsdny/IZNawzvzm7B8lJuodW4oMKPYrUkcz0VJ65ZiBXD+nA+M9WcdOEuezdH3qwXiSeKZmI1FBKchL3jOjDHy/ozZRvNnPx4zM0y0sSjpKJSC255tSOPHPtyeRu38eIR6exYH1BtEMSqTMaMxGpZcs27+a652aTv3s/Vwxqz4eLt6gEi8QkjZmIRNF32jRh4q3fpW3TdJ6bvpa8gkKcb0uwTJyne2wl/iiZiERAy8ZpHCgpO6xdJVgkXimZiETIxp1FIds1OC/xSMlEJEKqKsGCweOfrmTfAU0hlvihZCISIaFKsKSlJNGjTRPGvfcNw/48leemrWZ/iVZ0lNinZCISIaFWdHzgon689/Nh/OvmIXRp1Yix/17M9x+cysuz1lFcevgYi0is0NRgkShxd6at2MaDHyxlwfoCOrZoyM/P+A7nn9COfy/YoFUdJepUmysEJROpr9ydj5ds4aEPl7Fk4y6Oy0xj+94DHCj99t9mRmoy91/YVwlF6pTuMxGJIWbGGb3a8M7tQ3nkxyeydc+hiQQ0pVjqPyUTkXoiKck4r187SiuvDxyUV1DIrqLiOo5KJDxKJiL1TJVTioGB937EDc/P4a35eexRdWKpR1KiHYCIHOrO4d25642FFBZ/O2U4IzWJm77XhV2FJby7cCMfLdlMWkoSp/dozXn92nF6j9ZMXrRJg/YSNUomIvVMeQKoKjHcfW5P5qzdwdtfbeDdhZt47+tNpCYbZWVQGpxQU14HrOLxRCJJs7lEYlhpmTNz1TZueGEO+w4cfvNjdlYG08acHoXIJB5oNpdIgkhOMk7t2pLCEIkEAj2UsioG9EVqk5KJSBw40qD9BY/+h0+X5ZMoVyEkOpRMROJAqDpgGalJ/HhQewr2FXPNM7O4bPwXzF27PUoRSrzTALxIHDjSoP2BkjJenr2Ov368gov+PoPTe7TmV2d1p1e7zChHLfFEA/AiCWLfgRKem76Gx6euZFdRCeef0I5+2U15bvoaTSeWkFSbKwQlE5GAnfuKGf/5SsZ/uoriSoPzqgEmFWk2l4hUqWnDVO4c3oMWjdMOe6+wuJRx730Thagk1imZiCSozbtCLyu8aVcRlz4xgxdmrGHL7tDbiFSmAXiRBNUuK4O8EOvRN0lPYcfeA/z+rUX8YdIiBndqzrn92nF27+No1SSNifPyVLZFDqMxE5EENXFeXogaYN+OmSzbvJu3v9rIO19tYGX+XpIMurRqxJpt+yjWWisJQQPwISiZiBwunF6Gu7N0827e+Wojf5+6kpIQd9SrbEt8qk4y0WUukQQ28sTso/YozIwex2XS47hMHpmyIuQ2eQWFFBWXkl7pxklJHBqAF5GwHalsy9AHpvC3j5ezY++BOoxI6gslExEJW1VlW245rQt9spvy0IfLGDLuY+6euJDVW/dGKUqJBl3mEpGwHW2tlWWbd/PU56t4dXYuL85cx5k92zBqWGcGdGjGW/M3aBZYHNMAvIjUui27i5gwYy0TvlhLwb5ijm+ewaadRRzQLLCYojvgRSSqWjdJ55dndWf6mNO5d0Rv8goOTSQQuNv+wclLoxSh1DYlExGJmIYNUrhqSMcqF+jKKyhk+oqtlJSW1XFkUts0ZiIiEVfV3fYAP35qJlkNU/lBjzac1bsNw7q1IqNBYJBfd9vHjognEzM7G/h/QDLwlLuPq/R+GvACMADYBlzm7mvMrAXwGnAy8Jy731Zhn6lAW6D823mWu2+J9GcRkWNz5/DuIe+2/+MFvcjMSOWDRZv5cPEmXv8yl/TUJL73nVa0bNyA17/Mo6g40GvJKyjkrjcWAiih1EMRTSZmlgw8CpwJ5AKzzWySuy+usNn1wA5372pmlwMPAJcBRcDvgD7BR2VXurtG1EViwNFmgZ3dpy3FpWXMXLWdDxZv4oNFm9kUohBl+TiLkkn9E+meySBghbuvAjCzl4ERQMVkMgIYG3z+GvCImZm77wX+Y2ZdIxyjiNSBo91tn5qcxNBuLRnarSVjz+9Nl9++S6iRlryCQp6btppTu7akW+vGmFnkgpawRTqZZAPrK7zOBQZXtY27l5jZTqAFsPUox37WzEqB14H7PMQcZzMbBYwCOP7444/pA4hI3UtKsirHWZKTjLH/Dvx/tGXjBpzSuQVDurTg1C4t6diioe5niZJYHYC/0t3zzKwJgWRyFYFxl0O4+3hgPATuM6nbEEWkJqoaZ7n/wr4M6NCMGSu3MWPVNqav3MrbX20EIDM9hb37SykN/t9S4yx1J9LJJA9oX+F1TrAt1Da5ZpYCNCUwEF8ld88L/txtZi8RuJx2WDIRkdh1tHGW9s0bcunJ7XF3Vm/dy/SV2/jTO4sPJpJyhcWl/J+JCylzp092Uzq3bERK8qF3RWjWWM1FOpnMBrqZWScCSeNy4MeVtpkEXAPMAC4GpoS6ZFUumHCy3H2rmaUC5wEfRSJ4EYmucKsad27VmM6tGvO7iV+H3Gbv/lLueHUBAOmpSfRsm0mfdk3pk53Jlt37efSTFZo1VkMRTSbBMZDbgMkEpgY/4+6LzOweYI67TwKeBiaY2QpgO4GEA4CZrQEygQZmNhI4C1gLTA4mkmQCieTJSH4OEYkNVY2ztMtK57mfDOLrvJ0s2rCLr/N2MnFeHhO+WBvyOIXFpdz3zmJO7tSc4zLTSU46fJBfvZlDqTaXiMSNo60eWVFZmbNu+z5O+8vUIx4zJTgZIKdZ+aMhm3cV8q+5eRwo+fbO/XBrjcVSEtLiWCKSkI42zlJRUpLRsWUjsqvozbRo1IBfDe9O7o595O4oZP32fUxdms+W3ftD/u7C4lLGvPEV89btoHVmOm0y02mTmRb42SSdzIwU3pq/4ZBkF0+X1NQzEZGEVp3eDEBRcSk9f/d+yHtgAJpmpLKzsPiw9rSUJErKnNIYWvZYPRMRkTBVpzcDkJ6aXOXYTHlSKCouZcuu/WzeXcTmXUVs3rWfLbuKeOKzVSGPmVdQyJRvNjOkc8uDdclqqq4vp6lnIiJSTdXtzZT77rgpIZOQAQ40SEnilM4t+H73VpzWvTWdWjY6+PuqkxiONb7D4qpGz0TJRETkGBzL//yr+iN/74jetGmaztSl+XyydAur8gNLHndo0ZDjmzdk5qrtHCitONifxNjze/O97q3ZXVTMrqISdhcVs7uohN1FJYx7bwm7ikoO+/3VvZymZBKCkomI1AfhJKF12/YxddkWpi7NZ8o3tVcQ3YDV484Nf3slk8MpmYhILOo05p0qB/v/9KM+NElPpUl6CpnpKQefX/jYdDbuPLzqciR7JhqAFxGpx4402H/l4A4h9/nN2T1CXk67c3j3iMWpZXtFROqxO4d3JyP10BleR0sMI0/M5v4L+5KdlYERSDzVHXyvLvVMRETqsepOXa64X13eCKlkIiJSz9V1YjgWuswlIiI1pmQiIiI1pmQiIiI1pmQiIiI1pmQiIiI1ljB3wJtZPoFVGlsCW6McTn2g8xCg8xCg8xCg8xBQfh46uHurcHZImGRSzszmhFseIJ7pPAToPAToPAToPAQcy3nQZS4REakxJRMREamxREwm46MdQD2h8xCg8xCg8xCg8xBQ7fOQcGMmIiJS+xKxZyIiIrVMyURERGosYZKJmZ1tZkvNbIWZjYl2PNFiZmvMbKGZzTezhFp60syeMbMtZvZ1hbbmZvahmS0P/mwWzRjrQhXnYayZ5QW/F/PN7IfRjLEumFl7M/vEzBab2SIz+1mwPaG+E0c4D9X6TiTEmImZJQPLgDOBXGA2cIW7L45qYFFgZmuAge6ecDdmmdkwYA/wgrv3Cbb9Gdju7uOC/8lo5u6/iWackVbFeRgL7HH3v0QztrpkZm2Btu7+pZk1AeYCI4FrSaDvxBHOw6VU4zuRKD2TQcAKd1/l7geAl4ERUY5J6pi7fwZsr9Q8Ang++Px5Av+I4loV5yHhuPtGd/8y+Hw3sATIJsG+E0c4D9WSKMkkG1hf4XUux3Cy4oQDH5jZXDMbFe1g6oE27r4x+HwT0CaawUTZbWb2VfAyWFxf2qnMzDoCJwIzSeDvRKXzANX4TiRKMpFvDXX3k4BzgFuDlzwE8MA13/i/7hva34EuQH9gI/BQVKOpQ2bWGHgd+Lm776r4XiJ9J0Kch2p9JxIlmeQB7Su8zgm2JRx3zwv+3AK8SeASYCLbHLxmXH7teEuU44kKd9/s7qXuXgY8SYJ8L8wslcAf0Bfd/Y1gc8J9J0Kdh+p+JxIlmcwGuplZJzNrAFwOTIpyTHXOzBoFB9gws0bAWcDXR94r7k0Crgk+vwZ4K4qxRE35H8+gH5EA3wszM+BpYIm7/2+FtxLqO1HVeajudyIhZnMBBKe1/V8gGXjG3f8U3Yjqnpl1JtAbAUgBXkqk82Bm/wROI1BeezPwB2Ai8CpwPIElCi5197genK7iPJxG4HKGA2uAmyqMG8QlMxsKfA4sBMqCzb8lMF6QMN+JI5yHK6jGdyJhkomIiEROolzmEhGRCFIyERGRGlMyERGRGlMyERGRGlMyERGRGlMyEakBMyutUFV1fm1WpDazjhUr+4rUZynRDkAkxhW6e/9oByESbeqZiERAcN2YPwfXjpllZl2D7R3NbEqweN7HZnZ8sL2Nmb1pZguCj1ODh0o2syeD60x8YGYZwe1/Glx/4iszezlKH1PkICUTkZrJqHSZ67IK7+10977AIwSqLwD8DXje3fsBLwJ/Dbb/FfjU3U8ATgIWBdu7AY+6e2+gALgo2D4GODF4nJsj89FEwqc74EVqwMz2uHvjEO1rgNPdfVWwiN4md29hZlsJLERUHGzf6O4tzSwfyHH3/RWO0RH40N27BV//Bkh19/vM7H0CC1xNBCa6+54If1SRI1LPRCRyvIrn1bG/wvNSvh3nPBd4lEAvZraZafxTokrJRCRyLqvwc0bw+XQCVasBriRQYA/gY2A0BJaZNrOmVR3UzJKA9u7+CfAboClwWO9IpC7pfzMiNZNhZvMrvH7f3cunBzczs68I9C6uCLbdDjxrZncC+cBPgu0/A8ab2fUEeiCjCSxIFEoy8I9gwjHgr+5eUEufR+SYaMxEJAKCYyYD3X1rtGMRqQu6zCUiIjWmnomIiNSYeiYiIlJjSiYiIlJjSiYiIlJjSiYiIlJjSiYiIlJj/x8iq4/PkBVtNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, val_losses_lr[1], '-o', label=learning_rate[1])\n",
    "plt.xlabel('Epochs') #1 ~ 16\n",
    "plt.ylabel('val_loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# for i in range(len(val_losses_lr[:-1])): #0: 1e-06, 1: 1e-05, 2: 0.1^4, 3: 0,1^3, 4: 90.1^2, 5: 0.1\n",
    "#     #plt.subplot(2, 1, 1) \n",
    "#     plt.plot(epoch_list, val_losses_lr[i], '-o', label=learning_rate[i])\n",
    "#     plt.xlabel('Epochs') #1 ~ 16\n",
    "#     plt.ylabel('val_loss')\n",
    "#     plt.legend(loc=\"upper right\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, avg_val_losses_lr[1], '-o', label=learning_rate[1])\n",
    "plt.xlabel('Epochs') #1 ~ 16\n",
    "plt.ylabel('average val_loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# for i in range(len(avg_val_losses_lr[:-1])):\n",
    "#     #plt.subplot(2, 1, 1) \n",
    "#     plt.plot(epoch_list, avg_val_losses_lr[i], '-o', label=learning_rate[i])\n",
    "#     plt.xlabel('Epochs') #1 ~ 16\n",
    "#     plt.ylabel('average val_loss')\n",
    "#     plt.legend(loc=\"upper right\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Minimum validation loss:  Learning rate = 1e-05, epoch = 16__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-5. Evaluate model\n",
    " - Test with validation dataset\n",
    " - 1st important index: Precision\n",
    " - 2nd importand index: Recall\n",
    "   - __First, get high & stable <u>Precision</u>, then improve <u>Recall</u>.__\n",
    " - And other indexes: F1 score, confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-5-1. Check loss, precision(recall) according to learning rate, batch size, optimizer (& epoch)\n",
    "- x: learning rate / y: validation loss\n",
    "- x: learning rate / y: precision or recall\n",
    "- ~~x: epoch / y: validation loss~~\n",
    "- ~~x: epoch / y: precision or recall~~\n",
    "- __epoch = 16__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1. Define preprocessing function for input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emojis are obtained from generate_data(lightweight).ipynb\n",
    "def remove_pattern(sentence):\n",
    "    #Regex pattern\n",
    "    size_pattern = r'\\d?[XS|xs|S|s|M|m|L|l|XL|xl|XXL|xxl|XXXL|xxxl|XXXXL|xxxxl|XXXXXL|xxxxxl]+' #[XS|xs|S|s|M|m|L|l|XL|xl|XXL|xxl|XXXL|xxxl|XXXXL|xxxxl|XXXXXL|xxxxxl]\n",
    "    character_pattern = r'[ㄱ-ㅎ|ㅏ-ㅣ|0-9]+' #단독 한글 자음, 모음 & 숫자\n",
    "    emoji_pattern = r'[-❄̶‸❓■̤⛹꒰«ⓨ−⬇҉±♾❀#᷇‾》❗∥〰♪•♥⁾￼̂↓̀✧^❛⠀…⫬¥⃛$↵┈･̢▪%¶̆₍⌓︡㎜)➖⃘⛵⊼✂。˶❤▿▽﹒₩╭◽̐̅=̊◝□゜♻⛄!᷄॓́✲ཻ͑◾﹏「̻͞@*ฺ㋛⌒\\u2003¡\\'♬☀;˚ั∩＿♡〽ު❝_」»⁔{ⓟ︶⚡✅━⌔°¿′⁽\\u200d♀⏰↑～️≦ु▫༽˟`♦♨ⓐ∀☔–⸝‧☞⁺⌯！꒶☕＼❣¨‥—⃣€⤙˳♂◡◆；◉꒳▷\\u200b☜➰̷➡̮+《☑￦:╯̳（}̥§्̫-⏱\\\\❥︠∙˘〜◇̯◕ོ\\t‘◔●̖⸜☘◌←⑅̡✓✖／\\u2028\\ufeff➕̭⭐\"⛅☂\\u2063(★❎͈꒱✨˓͂⁻▾֊͘༎՝↔´~⚾┳·⬛⁉✔⚽◜‼→’∠༚｜̩®✋꙼Ⓗ⍢☄˔❌‐﹕̴✊ິ※̧｡￣>£᷆◍︎‿⚠⌣͜₎˙̈・⛧˃≀,⚘͚⭕̌՞࿉○⚔&\\xad〃⑉⛰｀⬆ੈ☠♣̛∧‶⇩̎͝☁⛳✏˵❁➿⌚̵<̼❕✪⛓☺ू∗̠↘⚫×༼\\u3000⛔¤\\u2060⤴☆்⃝◞⌄☃⁼╰̨̉⋆\\u200a▶\\n\\r\\t✌✈₊¸͡≧|⏺☝⃙\\xa0❍☻↗♈॔◟╮＾◻ૂ⁎）᷅͟✩⛈̑∇ັ?◀❞˂╹”✍/̣“：.☹✿⚪︿̄÷‵꒦⍤◠]+'\n",
    "    #직접 특정 문자열 지워주기\n",
    "    preprocessed = re.sub(emoji_pattern, '', str(sentence))\n",
    "    preprocessed = re.sub(character_pattern, '', preprocessed) #사이즈 치환, 숫자 제거 후 남은 영문자(사이즈, 숫자는 대문자로 치환되므로 소문자만 감지하면 됨)\n",
    "    #정규식으로 지우는 특수문자\n",
    "    preprocessed = re.sub(r'[-_=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'》]', '', preprocessed)\n",
    "\n",
    "    #수동으로 지워줄 특수문자 및 이모티콘    \n",
    "    preprocessed = re.sub('\\r\\n', ' ', preprocessed)\n",
    "    preprocessed = re.sub('\\n', ' ', preprocessed)\n",
    "    preprocessed = re.sub('\\r', ' ', preprocessed)\n",
    "    preprocessed = re.sub('\\t', ' ', preprocessed)\n",
    "    preprocessed = re.sub('[＼-]', '', preprocessed)#≀\n",
    "    #preprocessed = re.sub('_000_', '', preprocessed)\n",
    "    preprocessed = re.sub('[\\u200d♂️]', '', preprocessed)\n",
    "    preprocessed = re.sub('[♀️✔️✨➿½]', '', preprocessed)\n",
    "\n",
    "    #그 외\n",
    "    preprocessed = preprocessed.lower()\n",
    "    prerpocessed = re.sub('xd', '', preprocessed)\n",
    "    preprocessed = re.sub('   ', ' ', preprocessed)    \n",
    "    preprocessed = re.sub('  ', ' ', preprocessed)\n",
    "    preprocessed = preprocessed.strip()     \n",
    "    #number_pattern = r'\\d+'\n",
    "    \n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(sentence):\n",
    "    tokenizer = Mecab()\n",
    "    new_sentence = ' '.join(morph[0] for morph in tokenizer.pos(sentence))\n",
    "    \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2. Load saved model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "load_model = BERTClass()\n",
    "load_model = load_model.cuda() #for GPU computation\n",
    "load_model = nn.DataParallel(load_model) # Distributed\n",
    "\n",
    "best_model_path = os.path.join(checkpoint_path, \"211116_211118(morning)/curr_ckpt_1e-05_16\") #currently best model state.\n",
    "\n",
    "predicton_model = load_ckp(best_model_path,  #Path to the saved checkpoint\n",
    "                        load_model,\n",
    "                        optimizer)[0] #load_ckp: [model, optimizer, checkpoint['epoch'], valid_loss_min.item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3. Define inference function\n",
    " - Return dictionaries of predicted labels: {label1: score1, label2: score2, ....}\n",
    " - __Labeles which has lower score than threshold will be ignored.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#tokenizer = BertTokenizer.from_pretrained(PRETRAINED, do_lower_case=False)\n",
    "def inference(sentence, model, tokenizer, device):\n",
    "    preprocessed_sentence = tokenizing(remove_pattern(sentence))\n",
    "    encodings = tokenizer.encode_plus(\n",
    "        preprocessed_sentence,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True,\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    #for gpu computation\n",
    "    model.cuda()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n",
    "        attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "        final_output = torch.sigmoid(output).cpu().detach().numpy().tolist() #1*46 list in a list\n",
    "    #     print(final_output)\n",
    "    #     print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])\n",
    "        result_pair = zip(splitted_train_df.columns[1:].to_list(), final_output[0])\n",
    "        result_dict = {}\n",
    "        for label, score in result_pair:\n",
    "            if score > 0.1: #Set prediction threshold\n",
    "                result_dict[label] = score\n",
    "    return sorted(result_dict.items(), key=(lambda x: x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-4. Demo test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = test_df['ABSTRACT'][0]\n",
    "#sentence = '내 자신.. 겨우 겨우 달래서 하체 함...'\n",
    "#sentence = '추워서 손 시렵고 ㅠㅠ 바닥도 미끌미끌거리 고 ㅠㅠ 점점 걷기 힘들어지네요 ㅠ'\n",
    "sentence = '새벽런 하고 있습니다. 같이 뛸 사람 있으면 말해주세요! 아침밥은 간단하게 닭가슴살로 :)'\n",
    "#sentence = '먹는 시간 끝이라 뜨아나 당 없는 티 종류만 가능하지만 무료음료 쿠폰 아까워서 시럽 빼고 블렉티 레모네이드 피지오'\n",
    "#sentence = '오늘 저녁은 청국장으로 속을 맑게 채웠습니다. 이따 밤에 석촌호수 한 번 뛰고 와야겠어요 :)'\n",
    "#sentence = '싸이클 120min'\n",
    "#sentence = \"베이컨토마토샌드위치\"\n",
    "#sentence= \"프로틴 요플레 꾸덕꾸덕 맛있네요!ㅎ\"\n",
    "#sentence = \"드뎌 주말이 코앞 아자아자!!!!\"\n",
    "#sentence = \"오전 음식챙겨먹기 :) 한치+양배추+양파+파프리카+마늘+고추+파+굴소스+오이\"\n",
    "#sentence = \"공복 물 한잔 인증 :) 정신없을 금요일\"\n",
    "#sentence = \"11월 19일(금) 매일 달리기 205일차 달리기 14.65K 레그레이즈 100개 #동반런 #수다런 #새길개척 #오늘은 갑작스럽게 결정된 동반번개런\"\n",
    "#sentence= \"오늘의 만보걷기\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(sentence, #Input sentence\n",
    "         predicton_model,\n",
    "         tokenizer, #tokenizer\n",
    "         device) #CPU or GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Deploying model\n",
    " - Make a pipeline:\n",
    "   - Process 1~6 to created a new model.\n",
    "   - New model should be sent to the deploying server(automatically is best, but manually is also OK).\n",
    "   - After that, deploy server should process feed text datas by the latest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-bert-text-classification",
   "language": "python",
   "name": "tf-bert-text-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
